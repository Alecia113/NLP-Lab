{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPk2Z3dkI2E4QN99i3AnIPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alecia113/NLP-Lab/blob/main/lab3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWQeQDbaGUnC"
      },
      "source": [
        "# **Neural Network Example**å®æˆ˜äº†æœ‰ç‚¹\n",
        "#identifying animal species (features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE8KNEpMGmJt"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZF7WPOwGq7T"
      },
      "source": [
        "two features: two aspects \n",
        "1: animal have hair\n",
        "2: animal have feathers\n",
        "has hair [011000]\n",
        "has feather [001001]\n",
        "----input ^\n",
        "0-Oher 1-Manmmal 2-Bird [012002]\n",
        "---output/y ^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgKImD0lHmu2"
      },
      "source": [
        "# aim: predict animal == bird/ manmmal/others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThpMFoWwHx-l"
      },
      "source": [
        "'''\n",
        "åˆ›å»ºæ•°æ®one-hot\n",
        "Create our feature data\n",
        "[hair,feather]:0: X; 1:âœ…\n",
        "[1,0]: animal has hair + doesn't have feathers\n",
        "'''\n",
        "\n",
        "'''\n",
        "è½¬æ¢æ•°æ®ï¼›å˜å¼ é‡\n",
        "transform data --> torch data type (Pytorch)\n",
        "ã€ä¼ è¯´ä¸­çš„å¦‚ä½•è®©è€å¸ˆè¿›è¡Œæµ‹è¯•ã€‘\n",
        "# Uncomment the following line to print out if you want to see the details\n",
        "# print(x_data_torch)\n",
        "'''\n",
        "\n",
        "'''\n",
        "å¥½åƒæ˜¯å°†è¾“å‡ºçš„æ•°æ®ä¹Ÿå½•å…¥äº†æ•°ç»„ã€‚\n",
        "0-otherï¼› 1-mammal 2-bird\n",
        "#ç„¶åå†è½¬æ¢æˆå¼ é‡\n",
        "'''\n",
        "\n",
        "'''\n",
        "è®°å½•æ•°æ®ç‰¹å¾ï¼Œå’Œè¾“å‡ºç±»çš„æ•°é‡;;;å°±æ˜¯èµ‹å€¼\n",
        "'''\n",
        "#è¿™ä¸ªéƒ¨åˆ†æ›´åƒæ˜¯å‡†å¤‡æ•°æ®\n",
        "#print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLCQB_crIObM"
      },
      "source": [
        "#perpare for data\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])  #åˆ›å»ºæ•°æ®one-hot\n",
        "\n",
        "x_data_torch = torch.from_numpy(x_data).float() #è½¬ç±»å‹å˜å¼ é‡ï¼Œç›®å‰è¿˜æ˜¯æ•´æ•°\n",
        "\n",
        "y_data = np.array([0,1,2,0,0,2]) #output\n",
        "y_data_torch = torch.from_numpy(y_data) #output torch\n",
        "\n",
        "num_features = 2 # 2ä¸ªç‰¹å¾--hair, feather\n",
        "num_classes = 3 # 3 è¾“å‡ºç±» other,mammal,bird"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiTa6k1yNCPq"
      },
      "source": [
        "**No hidden layer --- manual ğŸ¤š parameter update (weight + bias)** EG\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Z_fdTrTAGV"
      },
      "source": [
        "'''\n",
        "è°ƒåŒ…\n",
        "nn\n",
        "å’ŒçŸ©é˜µå‡†ç¡®ç‡åˆ†æ•°\n",
        "'''\n",
        "'''\n",
        "initialize weight + bias manuallyğŸ¤š + setup gredient\n",
        "torch.randn returns --->tensor (random fill with) (from normal distribution with mean 0 + vaianceæ–¹å·® 1)\n",
        "[standard normal distribution æ ‡å‡†æ­£æ€åˆ†å¸ƒ]\n",
        "  # åŠŸèƒ½ï¼šä»æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰ä¸­æŠ½å–çš„ä¸€ç»„éšæœºæ•°ã€‚è¿”å›ä¸€ä¸ªå¼ é‡\n",
        "sizes (intâ€¦) - æ•´æ•°åºåˆ—ï¼Œå®šä¹‰è¾“å‡ºå¼ é‡çš„å½¢çŠ¶\n",
        "out (Tensor, optinal) - ç»“æœå¼ é‡\n",
        "\n",
        "è¯¥æ–¹æ³•èƒ½å¤Ÿå†³å®šè‡ªåŠ¨æ¢¯åº¦æœºåˆ¶æ˜¯å¦éœ€è¦ä¸ºå½“å‰è¿™ä¸ªå¼ é‡è®¡ç®—è®°å½•è¿ç®—æ“ä½œ.\n",
        "è¯¥æ–¹æ³•èƒ½å¯¹å½“å‰å¼ é‡çš„requires_gradå±æ€§è¿›è¡ŒåŸåœ°æ“ä½œ.è¿”å›è¿™ä¸ªå½“å‰å¼ é‡.\n",
        "\n",
        "'''\n",
        "# Learning Rate - determines the step size at each iteration while moving toward a minimum of a loss function\n",
        "\n",
        "# Epoch - A measure of the number of times all of the training vectors are used once to update the weights.\n",
        "#æ–¹æ³•è®­ç»ƒå‘é‡çš„æ¬¡æ•°ã€‚ï¼ˆè®­ç»ƒå‘é‡æ¥æ¯æ¬¡æ›´æ–°æƒé‡ï¼‰\n",
        "#å°è¯•2000çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆ\n",
        "\n",
        "'''\n",
        "for å¾ªç¯å¼€å§‹æ­£å‘ä¼ æ’­ forward propagation   calculation+ storage of intermediate variables(incl. outputs)\n",
        "from input layer --> output layer \n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "softmax change each value--->(0,1) + all values  +  add up(sum) = 1\n",
        "eg:  [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]\n",
        "(lå” å‰²é”æ³½æ¯ log_softmax )\n",
        "\n",
        "#å•Šå“ˆï¼ç®—æ³•ï¼›\n",
        "#ç®—æ³•å›¾è§£\n",
        "å…ˆè¿›è¡Œsoftmax ç„¶åè¿›è¡Œlogarithm softmax å¯¹æ•°\n",
        "softmaxï¼š exp(x_i) / exp(x).sum() and log_softmax: log(exp(x_i)) /exp(x).sum() ) #åªæ˜¯åˆ†å­åšlog\n",
        "log(softmax(x)) ä½†æ˜¯å®é™…åšèµ·æ¥ is different + efficient\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax\n",
        "    def log_softmax(input: Tensor, dim: Optional[int]=None, _stacklevel: \n",
        "      int=3, dtype: Optional[int]=None) ->Tensor\n",
        "'''\n",
        "\n",
        "#ç„¶åæŸå¤± å¼€å§‹è¦å¯¹æ¯”æƒ…å†µäº†ã€‚è®¡ç®—æ¶ˆælog å¯èƒ½æŸå¤±;[è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±]\n",
        "'''\n",
        "torch.nn.functional.nll_loss(input, target, weight=None, \n",
        "size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "\n",
        "ä¸€èˆ¬åªèµ‹å€¼å‰ä¸¤ä¸ªå¼ é‡å°±å¯ä»¥äº†\n",
        "'''\n",
        "\n",
        "'''\n",
        "å¼€å§‹åå‘ä¼ æ’­ï¼šback propagation è¿›è¡Œè®¡ç®—æ¢¯åº¦ã€‚ ä¼˜åŒ–WB ä½¿ç”¨å­¦ä¹ ç‡ -å­¦ä¹ ç‡*W/B çš„æ¢¯åº¦æ•°æ®  ç„¶åå†æ¸…é›¶\n",
        "torch.no_grad()\n",
        "https://blog.csdn.net/weixin_46559271/article/details/105658654?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629843016780357253890%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161629843016780357253890&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-105658654.first_rank_v2_pc_rank_v29&utm_term=torch.no_grad\n",
        "å½“ä½ åšåå‘ä¼ æ’­æ—¶ï¼Œä¸è¦ç´¯ç§¯æ¢¯åº¦ã€‚\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "argmaxå‡½æ•°ï¼štorch.argmax(input, dim=None, keepdim=False)è¿”å›æŒ‡å®šç»´åº¦æœ€å¤§å€¼çš„åºå·ï¼Œdimç»™å®šçš„å®šä¹‰æ˜¯ï¼šthe demention to reduce.ä¹Ÿå°±æ˜¯æŠŠdimè¿™ä¸ªç»´åº¦çš„ï¼Œå˜æˆè¿™ä¸ªç»´åº¦çš„æœ€å¤§å€¼çš„indexã€‚\n",
        "\n",
        "https://blog.csdn.net/weixin_42494287/article/details/92797061?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161630304416780269870820%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161630304416780269870820&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-92797061.first_rank_v2_pc_rank_v29&utm_term=torch.argmaxåšä»€ä¹ˆç”¨çš„\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayovWGA6Nbau",
        "outputId": "01f7f8df-1f82-40e2-d186-bc764460a236"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "W1 = torch.randn(num_features, num_classes, requires_grad=True)#torch.randn(2,3)\n",
        "B1 = torch.randn(num_classes, requires_grad=True) #3\n",
        "\n",
        "learning_rate = 0.01 \n",
        "\n",
        "number_of_epochs = 2000\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "\n",
        "  z =torch.add(torch.matmul(x_data_torch, W1),B1) # è¾“å…¥ä¸¤ä¸ªå•è¯å¼ é‡ï¼Œå’Œweight å’Œbiasã€ forward propagationï¼›ã€å…¶å®æ„Ÿè§‰è¿˜æ˜¯åœ¨æ•´åˆæ•°æ®ã€‘\n",
        "  \n",
        "  log_softmax = F.log_softmax(z,dim=1)  #nn.functional.log_softmax   ã€softmax--logã€‘\n",
        "\n",
        "  loss = F.nll_loss(log_softmax, y_data_torch)  # input target  ----lossã€ä¸€ä¸ªå¯¹æ•°æ¦‚ç‡å‘é‡å’Œä¸€ä¸ªç›®æ ‡æ ‡ç­¾ã€‘\n",
        "\n",
        "  loss.backward() #calculate gradient\n",
        "  with torch.no_grad():   #è¿›å…¥with è°ƒç”¨torch.no_grad è¿”å›ä¸€ä¸ªgradå¯¹è±¡ torch.no_grad() æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè¢«è¯¥è¯­å¥ wrap èµ·æ¥çš„éƒ¨åˆ†å°†ä¸ä¼štrack æ¢¯åº¦ã€‚\n",
        "      W1.data -= learning_rate*W1.grad.data   #gradient descent\n",
        "      B1.data -= learning_rate*B1.grad.data\n",
        "  W1.grad.data.zero_() #reset gradient\n",
        "  B1.grad.data.zero_()\n",
        "\n",
        "  if epoch % 200 == 199:\n",
        "    with torch.no_grad():        #é¢„æµ‹ä¸éœ€è¦æ¢¯åº¦çš„\n",
        "        pred_outputs = torch.add(torch.matmul(x_data_torch ,W1),B1)  #é‡æ–°å¼€å§‹åšä¹˜æ³•ï¼Œå›åˆ°äº†æœ€å¼€å§‹çš„æ—¶å€™ã€‚\n",
        "        predicted = torch.argmax(pred_outputs, 1)  #ä¸æ˜¯.outputs æ˜¯â€”â€”\n",
        "        train_acc = accuracy_score(predicted.numpy(), y_data)\n",
        "        print('Epoch:%d, loss: %.4f, train_acc:%.3f' %(epoch + 1, loss.item() , train_acc))\n",
        "\n",
        "#result\n",
        "print('Predicted :', predicted.numpy())\n",
        "print('Truth :', y_data)\n",
        "print('Accuracy : %.2f' %train_acc)\n",
        "\n",
        "\n",
        "#è®­ç»ƒå‡†ç¡®åº¦åœ¨å¢åŠ ï¼ŒæŸå¤±åœ¨é™ä½\n",
        "'''\n",
        "\n",
        "Epoch:200, loss: 1.8851, train_acc:0.167\n",
        "Epoch:400, loss: 1.1088, train_acc:0.833\n",
        "Epoch:600, loss: 0.7822, train_acc:0.833\n",
        "Epoch:800, loss: 0.6057, train_acc:1.000\n",
        "Epoch:1000, loss: 0.4985, train_acc:1.000\n",
        "Epoch:1200, loss: 0.4256, train_acc:1.000\n",
        "Epoch:1400, loss: 0.3718, train_acc:1.000\n",
        "Epoch:1600, loss: 0.3302, train_acc:1.000\n",
        "Epoch:1800, loss: 0.2968, train_acc:1.000\n",
        "Epoch:2000, loss: 0.2694, train_acc:1.000\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00[suji]\n",
        "\n",
        "æœ‰hidden\n",
        "\n",
        "Epoch: 200, loss: 0.9641, train_acc: 0.500\n",
        "Epoch: 400, loss: 0.8275, train_acc: 0.667\n",
        "Epoch: 600, loss: 0.7101, train_acc: 0.833\n",
        "Epoch: 800, loss: 0.6079, train_acc: 0.833\n",
        "Epoch: 1000, loss: 0.5234, train_acc: 0.833\n",
        "Epoch: 1200, loss: 0.4527, train_acc: 0.833\n",
        "Epoch: 1400, loss: 0.3903, train_acc: 0.833\n",
        "Epoch: 1600, loss: 0.3342, train_acc: 1.000\n",
        "Epoch: 1800, loss: 0.2883, train_acc: 1.000\n",
        "Epoch: 2000, loss: 0.2466, train_acc: 1.000\n",
        "Finished\n",
        "Predicted ï¼š [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00[suiji]\n",
        "\n",
        "æœ‰ä¼˜åŒ–æ²¡éšè—---è®­ç»ƒçš„å‡†ç¡®åº¦èƒ½ç›´æ¥è¾¾åˆ°1 æ¯æ¬¡\n",
        "200, loss: 1.039, train_acc: 1.000\n",
        "400, loss: 0.837, train_acc: 1.000\n",
        "600, loss: 0.702, train_acc: 1.000\n",
        "800, loss: 0.602, train_acc: 1.000\n",
        "1000, loss: 0.524, train_acc: 1.000\n",
        "1200, loss: 0.462, train_acc: 1.000\n",
        "1400, loss: 0.411, train_acc: 1.000\n",
        "1600, loss: 0.368, train_acc: 1.000\n",
        "1800, loss: 0.333, train_acc: 1.000\n",
        "2000, loss: 0.303, train_acc: 1.000\n",
        "Finished Training\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy :1.00\n",
        "\n",
        "\n",
        "ã€2000ï¼Œæœ‰éšè—å±‚çš„ä¼˜åŒ–ã€‘\n",
        "200, loss: 0.9377, train_acc: 0.8333\n",
        "400, loss: 0.7203, train_acc: 0.8333\n",
        "600, loss: 0.5153, train_acc: 0.8333\n",
        "800, loss: 0.3646, train_acc: 0.8333\n",
        "1000, loss: 0.2612, train_acc: 1.0000\n",
        "1200, loss: 0.1882, train_acc: 1.0000\n",
        "1400, loss: 0.1382, train_acc: 1.0000\n",
        "1600, loss: 0.1047, train_acc: 1.0000\n",
        "1800, loss: 0.0822, train_acc: 1.0000\n",
        "2000, loss: 0.0664, train_acc: 1.0000\n",
        "Finished Training\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:200, loss: 1.8851, train_acc:0.167\n",
            "Epoch:400, loss: 1.1088, train_acc:0.833\n",
            "Epoch:600, loss: 0.7822, train_acc:0.833\n",
            "Epoch:800, loss: 0.6057, train_acc:1.000\n",
            "Epoch:1000, loss: 0.4985, train_acc:1.000\n",
            "Epoch:1200, loss: 0.4256, train_acc:1.000\n",
            "Epoch:1400, loss: 0.3718, train_acc:1.000\n",
            "Epoch:1600, loss: 0.3302, train_acc:1.000\n",
            "Epoch:1800, loss: 0.2968, train_acc:1.000\n",
            "Epoch:2000, loss: 0.2694, train_acc:1.000\n",
            "Predicted : [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy : 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLj1ptKARpdk"
      },
      "source": [
        "# æ¢äº†é¡ºåºï¼š Hidden layer + manual parameter update  æœ‰H + ğŸ¤š"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzE3AFkzkw2b"
      },
      "source": [
        "'''\n",
        "in hidden layer neurons numbers\n",
        "å®šä¹‰éšè—å±‚çš„ç¥ç»å…ƒ \n",
        "\n",
        "input features, output neurons(in hidden layer)(numbers)--W1\n",
        "\n",
        "B1=== let Bias(hidden layer) output candidates numbers.  (neurons in hidden layer 5)\n",
        "\n",
        "wout input ï¼ˆneurons numbers [hidden], output(classes))\n",
        "\n",
        "'''\n",
        "#å®šä¹‰ç¥ç»å…ƒæ„å»ºWB ä»å•è¯åˆ°éšè—å±‚ç¥ç»å…ƒã€‚   b è®©bè¾“å‡ºæ—¥å¿—æ•°é‡ï¼ˆç¥ç»å…ƒï¼‰ã€è¿™åœ°æ–¹ä¸ç†è§£ã€‘ \n",
        "#w out ä»ä¸­é—´åˆ°è¾¹ä¸Šï¼Œè¾“å‡ºå¤§ç±»ã€‚   Bout = è®¾ç½®bias ä¸ºè¾“å‡ºå€™é€‰æ•°ã€‚å³3ï¼ˆç±»æ•°ï¼‰\n",
        "#è®¾ç½®å­¦ä¹ ç‡ å’Œ å‘¨æœŸ\n",
        "'''\n",
        "ç„¶åå¼€å§‹è¿›è¡Œå†…éƒ¨çš„ã€‚ä»æ·»åŠ ã€‚\n",
        "F.relu æ¿€æ´»å‡½æ•°ã€‚ç„¶åè¿›è¡Œæ¿€æ´»å‡½æ•°\n",
        "ç„¶åè¿›è¡Œsoftmax log ç„¶å import torch.nn.functional as F\n",
        "fitå‡½æ•°ä¸­é‡‡ç”¨æŸå¤±å‡½æ•°F.nll_loss()\n",
        "NLLLoss çš„ è¾“å…¥ æ˜¯ä¸€ä¸ªå¯¹æ•°æ¦‚ç‡å‘é‡å’Œä¸€ä¸ªç›®æ ‡æ ‡ç­¾. å®ƒä¸ä¼šä¸ºæˆ‘ä»¬è®¡ç®—å¯¹æ•°æ¦‚ç‡. é€‚åˆç½‘ç»œçš„æœ€åä¸€å±‚æ˜¯log_softmax\n",
        "----^è¿˜åœ¨å‡†å¤‡æ•°æ®\n",
        "'''\n",
        "#æ¿€æ´»å‡½æ•°å‡†å¤‡è¾“å‡ºçš„åšåˆ†æçš„æ•°æ®ï¼›ï¼›ï¼›å¯¹æ•°softmax\n",
        "#æŸå¤±lossï¼Œ   åå‘ä¼ æ’­æŸå¤±\n",
        "#åå‘ä¼ æ’­æŸå¤±\n",
        "#ç„¶åå­¦ä¹ ç‡è®­ç»ƒæ•°æ®ï¼Œï¼ˆè°ƒå­¦ä¹ ç‡ï¼‰ æ¯æ¬¡å¤„ç†å®Œéƒ½è¦æ¸…é™¤æ•°æ®zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT9335p2RVLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7699d2-9d6b-49af-d4b4-dc0119d59e5c"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "n_hidden_1 = 5 #éšè—å±‚ä¸­çš„ç¥ç»å…ƒ\n",
        "\n",
        "W1 = torch.randn(num_features, n_hidden_1, requires_grad=True) #è¾“å…¥ç‰¹å¾ï¼Œè¾“å‡ºï¼ˆéšè—ä¾§ç¥ç»å…ƒæ•°é‡ï¼‰\n",
        "B1 = torch.randn(n_hidden_1, requires_grad=True) # è®©éšè—å±‚ï¼›åç§»è¾“å‡º å€™é€‰æ—¥æœŸçš„æ•°é‡ã€‚å³5 éšè—å±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡\n",
        "# w1 ï¼ˆ â€¦â€¦num_featuresï¼Œ num_classesï¼Œ requï¼‰\n",
        "#Bout = æ²¡éšè—çš„b\n",
        "Wout = torch.rand(n_hidden_1, num_classes, requires_grad=True)#è¾“å…¥ç¥ç»å…ƒæ•°ï¼Œè¾“å‡ºç±»\n",
        "\n",
        "Bout = torch.randn(num_classes, requires_grad=True)  #è¾“å‡ºç±»3\n",
        "\n",
        "learning_rate=0.01 #æ²¡å˜\n",
        "no_of_epochs = 2000 # nob\n",
        "\n",
        "for epoch in range(no_of_epochs):\n",
        "  z1 = torch.add(torch.matmul(x_data_torch, W1), B1) # no å˜\n",
        "  Zout = torch.add(torch.matmul(F.relu(z1), Wout), Bout) #  æ¿€æ´»å‡½æ•°çš„åŠ å’Œ\n",
        "\n",
        "  log_softmax = F.log_softmax(Zout,dim=1) #noå¤§å˜\n",
        "  loss = F.nll_loss(log_softmax, y_data_torch) #noå¤§å˜\n",
        "\n",
        "  loss.backward()#nb\n",
        "  with torch.no_grad():#nb\n",
        "    W1.data -= learning_rate*W1.grad.data#nb\n",
        "    B1.data -= learning_rate*B1.grad.data#nb\n",
        "    \n",
        "    Wout.data -= learning_rate*Wout.grad.data  #bian\n",
        "    Bout.data -= learning_rate*Bout.grad.data  #b\n",
        "\n",
        "  W1.grad.data.zero_()#nb\n",
        "  B1.grad.data.zero_()#nb\n",
        "  Wout.grad.data.zero_()#b\n",
        "  Bout.grad.data.zero_()#b\n",
        "\n",
        "\n",
        "  if epoch % 200 == 199:#nd\n",
        "    with torch.no_grad():#nd\n",
        "      z1 = torch.add(torch.matmul(x_data_torch ,W1),B1) #nd\n",
        "      Zout = torch.add(torch.matmul(F.relu(z1),Wout),Bout)#d\n",
        "      predicted = torch.argmax(Zout,1)#lued\n",
        "      train_acc = accuracy_score(predicted.numpy(),y_data)#nd\n",
        "      print('Epoch: %d, loss: %.4f, train_acc: %.3f' %(epoch +1, loss.item() , train_acc))\n",
        "#nd\n",
        "print(\"Finished\") #åˆ†éš”\n",
        "\n",
        "#result\n",
        "print('Predicted ï¼š', predicted.numpy()) #Predicted ï¼š [0 1 2 0 0 2]\n",
        "print('Truth :', y_data)#Trure ï¼š [0 1 2 0 0 2]\n",
        "print('Accuracy : %.2f' %train_acc) #Accuracy :\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 200, loss: 0.9641, train_acc: 0.500\n",
            "Epoch: 400, loss: 0.8275, train_acc: 0.667\n",
            "Epoch: 600, loss: 0.7101, train_acc: 0.833\n",
            "Epoch: 800, loss: 0.6079, train_acc: 0.833\n",
            "Epoch: 1000, loss: 0.5234, train_acc: 0.833\n",
            "Epoch: 1200, loss: 0.4527, train_acc: 0.833\n",
            "Epoch: 1400, loss: 0.3903, train_acc: 0.833\n",
            "Epoch: 1600, loss: 0.3342, train_acc: 1.000\n",
            "Epoch: 1800, loss: 0.2883, train_acc: 1.000\n",
            "Epoch: 2000, loss: 0.2466, train_acc: 1.000\n",
            "Finished\n",
            "Predicted ï¼š [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy : 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-BmDmmE3aUI"
      },
      "source": [
        "# **No hidden layer --- Optimiser** ä¼˜åŒ–å™¨æ²¡æœ‰éšè—å±‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glRGSA-O4kU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0d55400-133f-49b7-bb5f-1f9756613f69"
      },
      "source": [
        "#è°ƒåŒ…å¤šè°ƒäº†ä¸ªä¼˜åŒ–å™¨\n",
        "'''\n",
        "build model (a neural networkï¼‰ âœ…  --- initializing ï¼ˆparameters manually) X\n",
        "torch.nn.Linear è¿™ä¸ªæ˜¯åšä»€ä¹ˆçš„ï¼š linear transformation (input data) ---- y=Ax+b\n",
        "è¿™é‡Œæ˜¯Açš„è½¬ç½®è²Œä¼¼AT\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "\n",
        "correspond  \n",
        " è‹±  [ËŒkÉ’rÉ™ËˆspÉ’nd]   ç¾  [ËŒkÉ”ËrÉ™ËˆspÉ‘Ënd]\n",
        "\n",
        "vi. ç¬¦åˆï¼Œä¸€è‡´ï¼›ç›¸åº”ï¼›é€šä¿¡\n",
        "\n",
        "#perpare for data\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])  #åˆ›å»ºæ•°æ®one-hot\n",
        "\n",
        "x_data_torch = torch.from_numpy(x_data).float() #è½¬ç±»å‹å˜å¼ é‡ï¼Œç›®å‰è¿˜æ˜¯æ•´æ•°\n",
        "\n",
        "y_data = np.array([0,1,2,0,0,2]) #output\n",
        "y_data_torch = torch.from_numpy(y_data) #output torch\n",
        "\n",
        "num_features = 2 # 2ä¸ªç‰¹å¾--hair, feather\n",
        "num_classes = 3 # 3 è¾“å‡ºç±» other,mammal,bird\n",
        "\n",
        "'''\n",
        "#å®šä¹‰å¤§ç±»ã€‚ç„¶åå¤§ç±»çš„inintä¸­æ˜¯ä½¿ç”¨nnçº¿æ€§å›å½’ç„¶ååšäº†ä¸ªçº¿æ€§åŒ–ã€‚ ï¼ˆå‘å‰ä¼ æ’­ï¼‰ ç„¶åå†åšäº†ä¸ªå‘å‰ä¼ æ’­çš„å‡½æ•°ï¼Œå®šä¹‰äº†å˜é‡xã€‚ã€å¯èƒ½æ˜¯è¾“å…¥çš„one-hot\n",
        "# åˆå§‹åŒ–æ¨¡å‹ initialize the model\n",
        "# å­¦ä¹ ç‡\n",
        "#è®¡ç®—æŸå¤± -----è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±\n",
        "#ä¼˜åŒ–å™¨     ã€1 å®šä¹‰ä¼˜åŒ–å™¨--2 ä¼ é€’æ¨¡å‹å‚æ•°æ¥è¿›è¡Œæ›´æ–°ã€‚+ è°ƒç”¨optim.SGDæ—¶è®¾ç½®çš„å­¦ä¹ ç‡ 3 ä½¿ç”¨çš„æ˜¯SGD ä¼˜åŒ–å™¨https://pytorch.org/docs/stable/optim.html\n",
        "# å®šä¹‰æ—¶æœŸï¼ˆçºªå…ƒï¼‰\n",
        "'''ä½ åœ¨æƒ³ä»€ä¹ˆè½äº†ä¼˜åŒ–å™¨è¿˜æœ‰å…¶ä»–çš„å‡ æ­¥â€¦â€¦'''\n",
        "#ä¿®æ”¹æƒé‡ã€‚ï¼ˆç”¨ç»™å®šçš„å­¦ä¹ ç‡ï¼‰æ¯ä¸ªé˜¶æ®µ   1 åˆå§‹åŒ–[è·å¾—input å’Œæ ‡ç­¾==output] 2train mode[æ¨¡å¼ã€‘ï¼ˆnet.train(mode = True) or evaluation (è¯„ä¼°) mode (when net.train(mode = False)/ net.eval())\n",
        "'''\n",
        "åˆå§‹åŒ–æŠ•å…¥æ•°æ®â€”â€”>>è®­ç»ƒè¯„ä¼°æ¨¡å¼\n",
        "ä¸€ä¸ªæ¨¡å—å¯ä»¥è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼net.train mode = Trueï¼› è¯„ä¼°æ¨¡å¼ net.trainä¸­ mode è¯„ä¼°=false æˆ–net.eval()\n",
        "ä»…å¯¹certain modules (Dropout, BtchNormç­‰)æœ‰æ•ˆï¼› ä»…å¯¹æŸäº›æ¨¡å—æœ‰æ•ˆ\n",
        "'''\n",
        "#è®¾ç½®æ¢¯åº¦ä¸º0 \n",
        "#è¾“å‡º   ï¼š å‘å‰ä¼ æ’­+å‘åä¼ æ’­+ ä¼˜åŒ–\n",
        "'''\n",
        "output(model-inputs) --- loss(softmax) ---backward---optimiser\n",
        "'''\n",
        "#å¼€å§‹æŒ‰ç…§æ—¶æœŸå‡†å¤‡è¾“å‡ºæ•°æ®äº†\n",
        "'''\n",
        "1é¢„æµ‹ï¼š model.eval\n",
        "2 outputs\n",
        "3 é¢„æµ‹ ï¼š ç”¨2çš„æ•°æ®è¿›è¡Œargmax  ä»2çš„æ•°æ®ä¸­ï¼Œæ‰¾å‡ºdim = 1 ï¼š1ç»´åº¦æœ€å¤§çš„å€¼çš„index\n",
        "4  å‡†ç¡®ç‡ accuracy_score\n",
        "'''"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\noutput(model-inputs) --- loss(softmax) ---backward---optimiser\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_-QPWaZRVpX",
        "outputId": "ceeb4509-a379-4bd5-fda2-579958f1f6f5"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim #bt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class ModelWithoutHiddenLayer(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super(ModelWithoutHiddenLayer, self).__init__()  #å¿…é¡»æœ‰çš„ä½ å¿˜äº†\n",
        "    #AttributeError: cannot assign module before Module.__init__() call  æ²¡æœ‰.__init__() å°±æ²¡åŠæ³•è°ƒç”¨æ¨¡å—\n",
        "    self.linear = nn.Linear(input_size, output_size) # corresponds å¯¹åº” W1,B1 (æ˜¯ä¸æ˜¯å°±æ˜¯W1ï¼ŒB1)\n",
        "  \n",
        "  def forward(self, x):         #å°±æ˜¯åšçº¿æ€§å›å½’çš„å‡½æ•°\n",
        "    x = self.linear(x)\n",
        "    return x    #æ²¡è¿”å›x\n",
        "  \n",
        "model = ModelWithoutHiddenLayer(num_features, num_classes) # åˆå§‹åŒ–æ¨¡å‹\n",
        "learning_rate = 0.01\n",
        "criterion = nn.NLLLoss() # è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤± calculate negatice log likelihood loss\n",
        "\n",
        "optimiser = optim.SGD(model.parameters(), lr=learning_rate) # å®šä¹‰ä¼˜åŒ–å™¨\n",
        "\n",
        "no_of_epochs = 2000 #epochs\n",
        "\n",
        "for epoch in range(no_of_epochs): #for every epoch, the model weights will be modified using the given learning rate\n",
        "  inputs = x_data_torch\n",
        "  labels = y_data_torch\n",
        "\n",
        "  model.train()  # mode = True (default é»˜è®¤)\n",
        "  optimiser.zero_grad() \n",
        "\n",
        "# forward + backward + optimize\n",
        "  outputs = model(inputs) \n",
        "  loss = criterion(F.log_softmax(outputs,dim=1), labels) # å‡†åˆ™\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "\n",
        "  if epoch % 200 == 199: # æ‰“å°200æ—¶æœŸ\n",
        "    model.eval() #predict( set the module to evaluation mode)\n",
        "    pre_outputs = model(inputs)\n",
        "    predicted = torch.argmax(pred_outputs, 1)\n",
        "    train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "    print('%d, loss: %.3f, train_acc: %.3f' %(epoch + 1, loss.item(),train_acc))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "#result\n",
        "model.eval()\n",
        "pred_outputs = model(inputs)\n",
        "predicted = torch.argmax(pred_outputs, 1)\n",
        "print('Predicted :', predicted.numpy())\n",
        "print('Truth :', y_data)\n",
        "\n",
        "train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "print('Accuracy :%.2f' %train_acc)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200, loss: 0.955, train_acc: 1.000\n",
            "400, loss: 0.782, train_acc: 1.000\n",
            "600, loss: 0.660, train_acc: 1.000\n",
            "800, loss: 0.568, train_acc: 1.000\n",
            "1000, loss: 0.496, train_acc: 1.000\n",
            "1200, loss: 0.438, train_acc: 1.000\n",
            "1400, loss: 0.391, train_acc: 1.000\n",
            "1600, loss: 0.352, train_acc: 1.000\n",
            "1800, loss: 0.319, train_acc: 1.000\n",
            "2000, loss: 0.291, train_acc: 1.000\n",
            "Finished Training\n",
            "Predicted : [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy :1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXPbhcjXZee0"
      },
      "source": [
        "#**Hidden Layer with the optimiser**   ä¼˜åŒ–å™¨çš„éšè—å±‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8L_jfc8fj7c"
      },
      "source": [
        "#è°ƒåŒ…\n",
        "#å®šä¹‰ç±»\n",
        "'''\n",
        "å¤šå®šä¹‰äº†ä¸€å±‚ æ˜¯æŠŠinput output  ä¸­é—´åŠ äº†ä¸€ä¸ªhiddenå±‚\n",
        "è¿™æ ·å°±å˜æˆäº† input hidd   hidd outp\n",
        "\n",
        "'''\n",
        "#å®šä¹‰å‡½æ•°å‘å‰ä¼ æ’­\n",
        "'''\n",
        "å¤šä¸ªæ¿€æ´»å‡½æ•°è¦æ¿€æ´»ä¸€ä¸‹z1 ç„¶åæ”¾åˆ°Zout\n",
        "'''\n",
        "\n",
        "#æ¨¡å‹è°ƒç”¨å€¼ã€‚inputï¼š ç‰¹ç‚¹æ€»æ•°ï¼› ä¸€ä¸ªéšè—å±‚ï¼› outputï¼š ç±»æ•°\n",
        "#å­¦ä¹ ç‡\n",
        "#å®šä¹‰æ—¶æœŸ\n",
        "#æŸå¤±å‡½æ•°  ï¼šè¦è¿›è¡Œsoftmax åªä¸è¿‡è¿™é‡Œæ¢äº†ä¸ªæ–¹æ³•\n",
        "'''\n",
        "Pythorch's CrossEntropyLoss â€”â€”â€”â€”ã€‹criterionå‡†åˆ™\n",
        "same result -- Pytorch's  NLLLoss -->LogSoftmax layer add after output layer(original)\n",
        "'''\n",
        "#ä¼˜åŒ–å™¨\n",
        "#å¯¼å…¥skl-å‡†ç¡®ç‡åˆ†æ•°çš„åŒ…\n",
        "# å¤šæ¬¡å¾ªç¯æ•°æ®é›†\n",
        "'''\n",
        "ä¼ é€’æ•°æ®å’Œæ ‡ç­¾ \n",
        "è®­ç»ƒæ¨¡å‹\n",
        "æ¸…ç©ºä¼˜åŒ–æ¢¯åº¦\n",
        "è¾“å‡ºè®­ç»ƒåæ•°æ®\n",
        "æŸå¤±\n",
        "åå‘ä¼ æ’­\n",
        "ä¼˜åŒ–å™¨ï¼ˆå¤šæ¬¡é‡æ–°è®¡ç®—ï¼‰\n",
        "'''\n",
        "#å¼€å§‹è¿›è¡Œ200æ‰“ä¸€æ¬¡æ•°æ®æ‰“ä¸€æ¬¡æŸå¤±å’Œ è®­ç»ƒå‡†ç¡®åº¦\n",
        "'''\n",
        "è¿™é‡Œ4å¥çœ‹èµ·æ¥éƒ½æ˜¯åœ¨ä¸ºè®­ç»ƒå‡†ç¡®åº¦è¿™ä¸ªç»“æœæœåŠ¡çš„\n",
        "'''\n",
        "\n",
        "#ç„¶åè¾“å‡ºç»“æœã€‚\n",
        "'''\n",
        "é¢„æµ‹çœŸå®å’Œå‡†ç¡®ç‡\n",
        "ä»¥åŠæ€ä¹ˆå»å®ç°çš„å‡†å¤‡æƒ…å†µã€‚\n",
        "'''\n",
        "'''\n",
        "ã€1000é¢„æµ‹çš„ä¹ä¸å‡†äº†ã€‘\n",
        "200, loss: 0.9767, train_acc: 0.5000\n",
        "400, loss: 0.8606, train_acc: 0.5000\n",
        "600, loss: 0.7692, train_acc: 0.8333\n",
        "800, loss: 0.6840, train_acc: 0.8333\n",
        "1000, loss: 0.6091, train_acc: 0.8333\n",
        "Finished Training\n",
        "Predicted : [0 0 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 0.83\n",
        "\n",
        "ã€2000ï¼Œæœ‰éšè—å±‚çš„ä¼˜åŒ–ã€‘\n",
        "200, loss: 0.9377, train_acc: 0.8333\n",
        "400, loss: 0.7203, train_acc: 0.8333\n",
        "600, loss: 0.5153, train_acc: 0.8333\n",
        "800, loss: 0.3646, train_acc: 0.8333\n",
        "1000, loss: 0.2612, train_acc: 1.0000\n",
        "1200, loss: 0.1882, train_acc: 1.0000\n",
        "1400, loss: 0.1382, train_acc: 1.0000\n",
        "1600, loss: 0.1047, train_acc: 1.0000\n",
        "1800, loss: 0.0822, train_acc: 1.0000\n",
        "2000, loss: 0.0664, train_acc: 1.0000\n",
        "Finished Training\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4h-02--XUOQ",
        "outputId": "7045c065-fee7-41d7-b3b7-01e852f5a0c1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "n_hidden_1 = 5   #è€å¸ˆæ²¡è¿™éƒ¨\n",
        "class ModelWithHiddenLayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(ModelWithHiddenLayer, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)    #b\n",
        "    self.linear2 = nn.Linear(hidden_size, output_size)  #b\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = self.linear1(x)\n",
        "    Zout = self.linear2(F.relu(z1))  #b\n",
        "    return Zout\n",
        "\n",
        "model = ModelWithHiddenLayer(num_features, n_hidden_1, num_classes)\n",
        "\n",
        "learning_rate=0.01\n",
        "no_of_epochs= 2000\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # == criterion = nn.NLLLoss()  ##b\n",
        "optimiser = optim.SGD(model.parameters(), lr=learning_rate) \n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for epoch in range(no_of_epochs): #loop dataset multiple times\n",
        "  #get inputs\n",
        "  inputs = x_data_torch\n",
        "  labels = y_data_torch\n",
        "\n",
        "  model.train()\n",
        "  # zero parameter gradients\n",
        "  optimiser.zero_grad()\n",
        "  # forward + backward+ optimize\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, labels) # don't need to calcualte logsoftmax here\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "\n",
        "  # print statistics\n",
        "  if epoch % 200 == 199:    # print æ¯200 epochs\n",
        "    model.eval()\n",
        "    pred_outputs = model(inputs)\n",
        "    predicted = torch.argmax(pred_outputs, 1)\n",
        "    train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "    print('%d, loss: %.4f, train_acc: %.4f' %(epoch+1, loss.item(), train_acc))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "#Result\n",
        "pred_outputs = model(inputs)\n",
        "_,predicted = torch.max(pred_outputs, 1)\n",
        "print('Predicted :', predicted.numpy())\n",
        "print('Truth :', y_data)\n",
        "\n",
        "train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "print('Accuracy : %.2f'%train_acc)\n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200, loss: 0.9377, train_acc: 0.8333\n",
            "400, loss: 0.7203, train_acc: 0.8333\n",
            "600, loss: 0.5153, train_acc: 0.8333\n",
            "800, loss: 0.3646, train_acc: 0.8333\n",
            "1000, loss: 0.2612, train_acc: 1.0000\n",
            "1200, loss: 0.1882, train_acc: 1.0000\n",
            "1400, loss: 0.1382, train_acc: 1.0000\n",
            "1600, loss: 0.1047, train_acc: 1.0000\n",
            "1800, loss: 0.0822, train_acc: 1.0000\n",
            "2000, loss: 0.0664, train_acc: 1.0000\n",
            "Finished Training\n",
            "Predicted : [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy : 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nVoSjL0k3Wr"
      },
      "source": [
        "# **Word2Vec on Pytorch** åšä¸ªWordVec-Skip Gram åœ¨Neural Network (NN é€šè¿‡pytorchï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahfHhyZ9rfHK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ZOPrNbHzxw"
      },
      "source": [
        "#**TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cRRG78grflY"
      },
      "source": [
        "#Word2vec 5.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xACvg-hwlB0b",
        "outputId": "92ebdda6-c59e-4d84-f1ea-b66794058715"
      },
      "source": [
        "#4.2\n",
        "print(model)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ModelWithHiddenLayer(\n",
            "  (linear1): Linear(in_features=2, out_features=5, bias=True)\n",
            "  (linear2): Linear(in_features=5, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxAnTfY3ZfWx",
        "outputId": "30b13909-df27-48c1-d052-6573cfdf9bfc"
      },
      "source": [
        "#4ã€‚1\n",
        "model"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelWithHiddenLayer(\n",
              "  (linear1): Linear(in_features=2, out_features=5, bias=True)\n",
              "  (linear2): Linear(in_features=5, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-2AGjej332L"
      },
      "source": [
        "#3.1\n",
        "output"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1XndBB23zXa"
      },
      "source": [
        "optimiser no hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-87AU7wE6Y2A",
        "outputId": "331108a3-44ed-4286-a5f9-11acc0c352e4"
      },
      "source": [
        "#2.4\n",
        "Bout.data -= learning_rate*Bout.grad.data  #b\n",
        "print(Bout.data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.9189, -0.1212,  0.2067])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m643ySif6Oh9",
        "outputId": "d9241ac0-34cc-4cda-978e-0e3e8ba5e76b"
      },
      "source": [
        "#2.3\n",
        "Zout = torch.add(torch.matmul(F.relu(z1), Wout), Bout) \n",
        "print(Zout)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5934,  0.7461,  1.3760],\n",
            "        [-1.4566, -0.0133,  0.5646],\n",
            "        [-1.8992,  0.0396,  0.2620],\n",
            "        [-0.5934,  0.7461,  1.3760],\n",
            "        [-0.5934,  0.7461,  1.3760],\n",
            "        [-1.8286,  0.6143,  0.4600]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM8vDadV6EJP",
        "outputId": "41aca658-f19f-49a3-9378-091e6f03e3b2"
      },
      "source": [
        "#2.2\n",
        "Wout = torch.rand(n_hidden_1, num_classes, requires_grad=True)\n",
        "print(Wout)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.7730, 0.1804, 0.5983],\n",
            "        [0.9212, 0.4871, 0.7432],\n",
            "        [0.5285, 0.3293, 0.5707],\n",
            "        [0.7976, 0.9384, 0.7502],\n",
            "        [0.0467, 0.3825, 0.1316]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLvbRdoVR2ic",
        "outputId": "7b8706ef-5f92-4c79-d34e-4febcc024f3c"
      },
      "source": [
        "#2.1\n",
        "Zout = torch.add(torch.matmul(F.relu(z1),Wout),Bout)\n",
        "print(Zout)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3.5850, -0.1930,  0.2251],\n",
            "        [-0.6030,  0.0824, -0.4356],\n",
            "        [-1.3784, -0.2961,  0.7000],\n",
            "        [ 3.5850, -0.1930,  0.2251],\n",
            "        [ 3.5850, -0.1930,  0.2251],\n",
            "        [ 0.5547, -0.9210,  2.4629]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW8AlLHGRX0s"
      },
      "source": [
        "æ²¡éšè—å±‚æ‰‹åŠ¨è°ƒå‚ã€‚ æµ‹è¯•å¦‚ä¸‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj6P5yPpMnJy",
        "outputId": "08bd5ca2-aeea-46bc-978c-cb625cc9fef6"
      },
      "source": [
        "#16\n",
        "tain_acc = accuracy_score(predicted.numpy(), y_data)\n",
        "print(tain_acc)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXupZX1qMUbI",
        "outputId": "0c2b5ebc-6bbe-4a31-c05f-d55b0db134d8"
      },
      "source": [
        "#15\n",
        "predicted = torch.argmax(pred_outputs, 1)\n",
        "print(predicted)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 0, 0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945ciGNxMFu3",
        "outputId": "15c647f8-c707-4f0c-9f73-98945a94beda"
      },
      "source": [
        "#14\n",
        "print(pred_outputs)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3947,  0.6585,  0.5634],\n",
            "        [ 0.9237, -0.4688,  0.6831],\n",
            "        [-1.6573,  1.1094,  1.3526],\n",
            "        [ 1.3947,  0.6585,  0.5634],\n",
            "        [ 1.3947,  0.6585,  0.5634],\n",
            "        [-1.1862,  2.2367,  1.2329]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBVVQhb8JTZ1",
        "outputId": "5697a777-5d1d-4091-a040-24fa8adca807"
      },
      "source": [
        "#13\n",
        "B1.data -= learning_rate*B1.grad.data\n",
        "print(B1.data)\n",
        "#tensor([ 2.1613,  0.7510, -0.7514],  #tensor([ 34.8541,  -0.3064, -33.4468])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 34.8541,  -0.3064, -33.4468])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w55lxdsH-YB",
        "outputId": "8bf88958-d56d-44cb-8633-f057cbf35b2b"
      },
      "source": [
        "#12\n",
        "W1.data -= learning_rate*W1.grad.data\n",
        "print(W1.data)\n",
        "\n",
        "\n",
        "'''\n",
        "tensor([[ 0.9477,  1.5061, -0.7059],\n",
        "        [-0.3978, -0.5679, -0.0613]\n",
        "        tensor([[ 0.3480,  0.0354,  0.5222],\n",
        "        [ 2.0451, -0.0493,  1.2841]])\n",
        "        '''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3480,  0.0354,  0.5222],\n",
            "        [ 2.0451, -0.0493,  1.2841]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eKzzYiTH551",
        "outputId": "8bd9aae9-2c6f-4e2f-d15c-20da46054136"
      },
      "source": [
        "#11\n",
        "loss = F.nll_loss(log_softmax, y_data_torch)\n",
        "print(loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.6704, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6H5td2MERT_",
        "outputId": "0ffb0e72-e23b-4517-bf25-573798fbc8bb"
      },
      "source": [
        "#10\n",
        "log_softmax = F.log_softmax(z,dim=1)\n",
        "print(log_softmax)\n",
        "\n",
        "#https://blog.csdn.net/hao5335156/article/details/80607732?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629884116780265451148%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161629884116780265451148&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-80607732.first_rank_v2_pc_rank_v29&utm_term=F.log_softmax\n",
        "#åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œæ•°å€¼ä¸Šä¹Ÿæ›´ç¨³å®šã€‚\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2611, -1.6715, -3.1738],\n",
            "        [-0.2168, -1.9441, -2.9598],\n",
            "        [-0.0504, -3.8751, -3.5608],\n",
            "        [-0.2611, -1.6715, -3.1738],\n",
            "        [-0.2611, -1.6715, -3.1738],\n",
            "        [-0.0537, -3.5615, -3.7339]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRoUblpt41wH",
        "outputId": "bede2b65-930b-45cc-a09a-4bd97302a8ec"
      },
      "source": [
        "#9 torch.matmul å¯ä»¥è¾“å…¥é«˜ç»´çš„ï¼›äºŒç»´å°±æ˜¯å›¾é€šä¹˜æ³•\n",
        "#è¾“å…¥å¤šç»´å°±æ˜¯æŠŠæ‹–å‡ºæ¥çš„ä¸€ä½ä½œä¸ºbatch æå‡ºæ¥ã€‚å…¶ä»–éƒ¨åˆ†åšçŸ©é˜µä¹˜æ³•\n",
        "#å°†bçš„ç¬¬0ç»´ 5 broadcast æå‡ºæ¥ã€‚åä¸¤ç»´åšçŸ©é˜µä¹˜æ³•\n",
        "import pprint\n",
        "a = torch.ones(3,4)\n",
        "b = torch.ones(5,4,2)\n",
        "c = torch.matmul(a,b)\n",
        "print(c.shape)\n",
        "pprint.pprint(c)\n",
        "#https://blog.csdn.net/qsmx666/article/details/105783610?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629814016780271553753%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161629814016780271553753&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-4-105783610.first_rank_v2_pc_rank_v29&utm_term=torch.matmulå‚æ•°æ€ä¹ˆç”¨\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 2])\n",
            "tensor([[[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb4iwTMW29ED",
        "outputId": "993fee4a-6517-4744-fdc5-62e5f42e4c33"
      },
      "source": [
        "#8\n",
        "z =torch.add(torch.matmul(x_data_torch, W1),B1) #å‚æ•°ä¼ é€’åˆ° torch.add åè¿”å›è¾“å…¥å‚æ•°çš„æ±‚å’Œç»“æœä½œä¸ºè¾“å‡º\n",
        "#torch.matmul æ˜¯å¸¸ç”¨ä¹˜æ³•\n",
        "print(z)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.1613,  0.7510, -0.7514],\n",
            "        [ 2.5123,  0.7850, -0.2307],\n",
            "        [ 4.5605,  0.7358,  1.0501],\n",
            "        [ 2.1613,  0.7510, -0.7514],\n",
            "        [ 2.1613,  0.7510, -0.7514],\n",
            "        [ 4.2096,  0.7018,  0.5294]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EKSDj8g24hf",
        "outputId": "a4c30f12-dc20-4234-9740-eafce6d6e97d"
      },
      "source": [
        "#7\n",
        "B1 = torch.randn(num_classes, requires_grad=True)\n",
        "print(B1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2.1613,  0.7510, -0.7514], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgLWHdZ-UGfW",
        "outputId": "5a04070d-0f6e-4b3d-dadc-9cab6c5f0e1e"
      },
      "source": [
        "W1 = torch.randn(num_features, num_classes, requires_grad=True)\n",
        "print(W1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9477,  1.5061, -0.7059],\n",
            "        [-0.3978, -0.5679, -0.0613]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95YTLYnWMyEJ",
        "outputId": "ed3a7bd3-a67d-4e71-e4e9-2e68eba7ec11"
      },
      "source": [
        "#5\n",
        "num_features = 2 # 2ä¸ªç‰¹å¾--hair, feather\n",
        "num_classes = 3 # 3 è¾“å‡ºç±» other,mammal,bird\n",
        "print(num_features,num_classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Rmcm2-LlBV",
        "outputId": "43508915-3370-4140-a8ef-612b2bd933b4"
      },
      "source": [
        "#4\n",
        "y_data_torch = torch.from_numpy(y_data)\n",
        "print(y_data_torch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 0, 0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYI10BEFJ-jz",
        "outputId": "db621d25-ba54-4b4d-c745-c24096695b65"
      },
      "source": [
        "#3\n",
        "y_data = np.array([0,1,2,0,0,2])\n",
        "print(y_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 0 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P7lRrFIJLRA",
        "outputId": "88489beb-0a19-4602-b079-23846c4b9ad6"
      },
      "source": [
        "#2\n",
        "x_data_torch = torch.from_numpy(x_data)\n",
        "print(x_data_torch)\n",
        "x_data_torch = torch.from_numpy(x_data).float()\n",
        "print(x_data_torch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 1]])\n",
            "tensor([[0., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09hJb5nSH2di",
        "outputId": "e3fc01fc-1558-40de-92b2-59f3e90cd481"
      },
      "source": [
        "#1\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])\n",
        "print(x_data)#ç«–ç€å…¨æ‰“å‡ºæ¥äº† ä¹Ÿå°±æ˜¯ä¸€è¡Œä¸ºã€ã€‘ç„¶åæ•´ä¸ªã€ã€‘å†ï¼ˆï¼‰æ”¾åœ¨æ•°ç»„å½“ä¸­"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}