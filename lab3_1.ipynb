{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqm/2RAW7Ftpk/rDGhPtY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alecia113/NLP-Lab/blob/main/lab3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWQeQDbaGUnC"
      },
      "source": [
        "# **Neural Network Example**实战了有点\n",
        "#identifying animal species (features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE8KNEpMGmJt"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZF7WPOwGq7T"
      },
      "source": [
        "two features: two aspects \n",
        "1: animal have hair\n",
        "2: animal have feathers\n",
        "has hair [011000]\n",
        "has feather [001001]\n",
        "----input ^\n",
        "0-Oher 1-Manmmal 2-Bird [012002]\n",
        "---output/y ^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgKImD0lHmu2"
      },
      "source": [
        "# aim: predict animal == bird/ manmmal/others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThpMFoWwHx-l"
      },
      "source": [
        "'''\n",
        "创建数据one-hot\n",
        "Create our feature data\n",
        "[hair,feather]:0: X; 1:✅\n",
        "[1,0]: animal has hair + doesn't have feathers\n",
        "'''\n",
        "\n",
        "'''\n",
        "转换数据；变张量\n",
        "transform data --> torch data type (Pytorch)\n",
        "【传说中的如何让老师进行测试】\n",
        "# Uncomment the following line to print out if you want to see the details\n",
        "# print(x_data_torch)\n",
        "'''\n",
        "\n",
        "'''\n",
        "好像是将输出的数据也录入了数组。\n",
        "0-other； 1-mammal 2-bird\n",
        "#然后再转换成张量\n",
        "'''\n",
        "\n",
        "'''\n",
        "记录数据特征，和输出类的数量;;;就是赋值\n",
        "'''\n",
        "#这个部分更像是准备数据\n",
        "#print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLCQB_crIObM"
      },
      "source": [
        "#perpare for data\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])  #创建数据one-hot\n",
        "\n",
        "x_data_torch = torch.from_numpy(x_data).float() #转类型变张量，目前还是整数\n",
        "\n",
        "y_data = np.array([0,1,2,0,0,2]) #output\n",
        "y_data_torch = torch.from_numpy(y_data) #output torch\n",
        "\n",
        "num_features = 2 # 2个特征--hair, feather\n",
        "num_classes = 3 # 3 输出类 other,mammal,bird"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiTa6k1yNCPq"
      },
      "source": [
        "**No hidden layer --- manual 🤚 parameter update (weight + bias)** EG\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Z_fdTrTAGV"
      },
      "source": [
        "'''\n",
        "调包\n",
        "nn\n",
        "和矩阵准确率分数\n",
        "'''\n",
        "'''\n",
        "initialize weight + bias manually🤚 + setup gredient\n",
        "torch.randn returns --->tensor (random fill with) (from normal distribution with mean 0 + vaiance方差 1)\n",
        "[standard normal distribution 标准正态分布]\n",
        "  # 功能：从标准正态分布（均值为0，方差为1）中抽取的一组随机数。返回一个张量\n",
        "sizes (int…) - 整数序列，定义输出张量的形状\n",
        "out (Tensor, optinal) - 结果张量\n",
        "\n",
        "该方法能够决定自动梯度机制是否需要为当前这个张量计算记录运算操作.\n",
        "该方法能对当前张量的requires_grad属性进行原地操作.返回这个当前张量.\n",
        "\n",
        "'''\n",
        "# Learning Rate - determines the step size at each iteration while moving toward a minimum of a loss function\n",
        "\n",
        "# Epoch - A measure of the number of times all of the training vectors are used once to update the weights.\n",
        "#方法训练向量的次数。（训练向量来每次更新权重）\n",
        "#尝试2000看会发生什么\n",
        "\n",
        "'''\n",
        "for 循环开始正向传播 forward propagation   calculation+ storage of intermediate variables(incl. outputs)\n",
        "from input layer --> output layer \n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "softmax change each value--->(0,1) + all values  +  add up(sum) = 1\n",
        "eg:  [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]\n",
        "(l唠割锐泽母 log_softmax )\n",
        "\n",
        "#啊哈！算法；\n",
        "#算法图解\n",
        "先进行softmax 然后进行logarithm softmax 对数\n",
        "softmax： exp(x_i) / exp(x).sum() and log_softmax: log(exp(x_i)) /exp(x).sum() ) #只是分子做log\n",
        "log(softmax(x)) 但是实际做起来 is different + efficient\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax\n",
        "    def log_softmax(input: Tensor, dim: Optional[int]=None, _stacklevel: \n",
        "      int=3, dtype: Optional[int]=None) ->Tensor\n",
        "'''\n",
        "\n",
        "#然后损失 开始要对比情况了。计算消极log 可能损失;[计算负对数似然损失]\n",
        "'''\n",
        "torch.nn.functional.nll_loss(input, target, weight=None, \n",
        "size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "\n",
        "一般只赋值前两个张量就可以了\n",
        "'''\n",
        "\n",
        "'''\n",
        "开始反向传播：back propagation 进行计算梯度。 优化WB 使用学习率 -学习率*W/B 的梯度数据  然后再清零\n",
        "torch.no_grad()\n",
        "https://blog.csdn.net/weixin_46559271/article/details/105658654?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629843016780357253890%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161629843016780357253890&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-105658654.first_rank_v2_pc_rank_v29&utm_term=torch.no_grad\n",
        "当你做反向传播时，不要累积梯度。\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "argmax函数：torch.argmax(input, dim=None, keepdim=False)返回指定维度最大值的序号，dim给定的定义是：the demention to reduce.也就是把dim这个维度的，变成这个维度的最大值的index。\n",
        "\n",
        "https://blog.csdn.net/weixin_42494287/article/details/92797061?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161630304416780269870820%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161630304416780269870820&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-92797061.first_rank_v2_pc_rank_v29&utm_term=torch.argmax做什么用的\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayovWGA6Nbau",
        "outputId": "01f7f8df-1f82-40e2-d186-bc764460a236"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "W1 = torch.randn(num_features, num_classes, requires_grad=True)#torch.randn(2,3)\n",
        "B1 = torch.randn(num_classes, requires_grad=True) #3\n",
        "\n",
        "learning_rate = 0.01 \n",
        "\n",
        "number_of_epochs = 2000\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "\n",
        "  z =torch.add(torch.matmul(x_data_torch, W1),B1) # 输入两个单词张量，和weight 和bias、 forward propagation；【其实感觉还是在整合数据】\n",
        "  \n",
        "  log_softmax = F.log_softmax(z,dim=1)  #nn.functional.log_softmax   【softmax--log】\n",
        "\n",
        "  loss = F.nll_loss(log_softmax, y_data_torch)  # input target  ----loss【一个对数概率向量和一个目标标签】\n",
        "\n",
        "  loss.backward() #calculate gradient\n",
        "  with torch.no_grad():   #进入with 调用torch.no_grad 返回一个grad对象 torch.no_grad() 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度。\n",
        "      W1.data -= learning_rate*W1.grad.data   #gradient descent\n",
        "      B1.data -= learning_rate*B1.grad.data\n",
        "  W1.grad.data.zero_() #reset gradient\n",
        "  B1.grad.data.zero_()\n",
        "\n",
        "  if epoch % 200 == 199:\n",
        "    with torch.no_grad():        #预测不需要梯度的\n",
        "        pred_outputs = torch.add(torch.matmul(x_data_torch ,W1),B1)  #重新开始做乘法，回到了最开始的时候。\n",
        "        predicted = torch.argmax(pred_outputs, 1)  #不是.outputs 是——\n",
        "        train_acc = accuracy_score(predicted.numpy(), y_data)\n",
        "        print('Epoch:%d, loss: %.4f, train_acc:%.3f' %(epoch + 1, loss.item() , train_acc))\n",
        "\n",
        "#result\n",
        "print('Predicted :', predicted.numpy())\n",
        "print('Truth :', y_data)\n",
        "print('Accuracy : %.2f' %train_acc)\n",
        "\n",
        "\n",
        "#训练准确度在增加，损失在降低\n",
        "'''\n",
        "\n",
        "Epoch:200, loss: 1.8851, train_acc:0.167\n",
        "Epoch:400, loss: 1.1088, train_acc:0.833\n",
        "Epoch:600, loss: 0.7822, train_acc:0.833\n",
        "Epoch:800, loss: 0.6057, train_acc:1.000\n",
        "Epoch:1000, loss: 0.4985, train_acc:1.000\n",
        "Epoch:1200, loss: 0.4256, train_acc:1.000\n",
        "Epoch:1400, loss: 0.3718, train_acc:1.000\n",
        "Epoch:1600, loss: 0.3302, train_acc:1.000\n",
        "Epoch:1800, loss: 0.2968, train_acc:1.000\n",
        "Epoch:2000, loss: 0.2694, train_acc:1.000\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00[suji]\n",
        "\n",
        "有hidden\n",
        "\n",
        "Epoch: 200, loss: 0.9641, train_acc: 0.500\n",
        "Epoch: 400, loss: 0.8275, train_acc: 0.667\n",
        "Epoch: 600, loss: 0.7101, train_acc: 0.833\n",
        "Epoch: 800, loss: 0.6079, train_acc: 0.833\n",
        "Epoch: 1000, loss: 0.5234, train_acc: 0.833\n",
        "Epoch: 1200, loss: 0.4527, train_acc: 0.833\n",
        "Epoch: 1400, loss: 0.3903, train_acc: 0.833\n",
        "Epoch: 1600, loss: 0.3342, train_acc: 1.000\n",
        "Epoch: 1800, loss: 0.2883, train_acc: 1.000\n",
        "Epoch: 2000, loss: 0.2466, train_acc: 1.000\n",
        "Finished\n",
        "Predicted ： [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00[suiji]\n",
        "\n",
        "有优化没隐藏---训练的准确度能直接达到1 每次\n",
        "200, loss: 1.039, train_acc: 1.000\n",
        "400, loss: 0.837, train_acc: 1.000\n",
        "600, loss: 0.702, train_acc: 1.000\n",
        "800, loss: 0.602, train_acc: 1.000\n",
        "1000, loss: 0.524, train_acc: 1.000\n",
        "1200, loss: 0.462, train_acc: 1.000\n",
        "1400, loss: 0.411, train_acc: 1.000\n",
        "1600, loss: 0.368, train_acc: 1.000\n",
        "1800, loss: 0.333, train_acc: 1.000\n",
        "2000, loss: 0.303, train_acc: 1.000\n",
        "Finished Training\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy :1.00\n",
        "\n",
        "\n",
        "【2000，有隐藏层的优化】\n",
        "200, loss: 0.9377, train_acc: 0.8333\n",
        "400, loss: 0.7203, train_acc: 0.8333\n",
        "600, loss: 0.5153, train_acc: 0.8333\n",
        "800, loss: 0.3646, train_acc: 0.8333\n",
        "1000, loss: 0.2612, train_acc: 1.0000\n",
        "1200, loss: 0.1882, train_acc: 1.0000\n",
        "1400, loss: 0.1382, train_acc: 1.0000\n",
        "1600, loss: 0.1047, train_acc: 1.0000\n",
        "1800, loss: 0.0822, train_acc: 1.0000\n",
        "2000, loss: 0.0664, train_acc: 1.0000\n",
        "Finished Training\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:200, loss: 1.8851, train_acc:0.167\n",
            "Epoch:400, loss: 1.1088, train_acc:0.833\n",
            "Epoch:600, loss: 0.7822, train_acc:0.833\n",
            "Epoch:800, loss: 0.6057, train_acc:1.000\n",
            "Epoch:1000, loss: 0.4985, train_acc:1.000\n",
            "Epoch:1200, loss: 0.4256, train_acc:1.000\n",
            "Epoch:1400, loss: 0.3718, train_acc:1.000\n",
            "Epoch:1600, loss: 0.3302, train_acc:1.000\n",
            "Epoch:1800, loss: 0.2968, train_acc:1.000\n",
            "Epoch:2000, loss: 0.2694, train_acc:1.000\n",
            "Predicted : [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy : 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLj1ptKARpdk"
      },
      "source": [
        "# 换了顺序： Hidden layer + manual parameter update  有H + 🤚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzE3AFkzkw2b"
      },
      "source": [
        "'''\n",
        "in hidden layer neurons numbers\n",
        "定义隐藏层的神经元 \n",
        "\n",
        "input features, output neurons(in hidden layer)(numbers)--W1\n",
        "\n",
        "B1=== let Bias(hidden layer) output candidates numbers.  (neurons in hidden layer 5)\n",
        "\n",
        "wout input （neurons numbers [hidden], output(classes))\n",
        "\n",
        "'''\n",
        "#定义神经元构建WB 从单词到隐藏层神经元。   b 让b输出日志数量（神经元）【这地方不理解】 \n",
        "#w out 从中间到边上，输出大类。   Bout = 设置bias 为输出候选数。即3（类数）\n",
        "#设置学习率 和 周期\n",
        "'''\n",
        "然后开始进行内部的。从添加。\n",
        "F.relu 激活函数。然后进行激活函数\n",
        "然后进行softmax log 然后 import torch.nn.functional as F\n",
        "fit函数中采用损失函数F.nll_loss()\n",
        "NLLLoss 的 输入 是一个对数概率向量和一个目标标签. 它不会为我们计算对数概率. 适合网络的最后一层是log_softmax\n",
        "----^还在准备数据\n",
        "'''\n",
        "#激活函数准备输出的做分析的数据；；；对数softmax\n",
        "#损失loss，   反向传播损失\n",
        "#反向传播损失\n",
        "#然后学习率训练数据，（调学习率） 每次处理完都要清除数据zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT9335p2RVLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7699d2-9d6b-49af-d4b4-dc0119d59e5c"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "n_hidden_1 = 5 #隐藏层中的神经元\n",
        "\n",
        "W1 = torch.randn(num_features, n_hidden_1, requires_grad=True) #输入特征，输出（隐藏侧神经元数量）\n",
        "B1 = torch.randn(n_hidden_1, requires_grad=True) # 让隐藏层；偏移输出 候选日期的数量。即5 隐藏层中的神经元数量\n",
        "# w1 （ ……num_features， num_classes， requ）\n",
        "#Bout = 没隐藏的b\n",
        "Wout = torch.rand(n_hidden_1, num_classes, requires_grad=True)#输入神经元数，输出类\n",
        "\n",
        "Bout = torch.randn(num_classes, requires_grad=True)  #输出类3\n",
        "\n",
        "learning_rate=0.01 #没变\n",
        "no_of_epochs = 2000 # nob\n",
        "\n",
        "for epoch in range(no_of_epochs):\n",
        "  z1 = torch.add(torch.matmul(x_data_torch, W1), B1) # no 变\n",
        "  Zout = torch.add(torch.matmul(F.relu(z1), Wout), Bout) #  激活函数的加和\n",
        "\n",
        "  log_softmax = F.log_softmax(Zout,dim=1) #no大变\n",
        "  loss = F.nll_loss(log_softmax, y_data_torch) #no大变\n",
        "\n",
        "  loss.backward()#nb\n",
        "  with torch.no_grad():#nb\n",
        "    W1.data -= learning_rate*W1.grad.data#nb\n",
        "    B1.data -= learning_rate*B1.grad.data#nb\n",
        "    \n",
        "    Wout.data -= learning_rate*Wout.grad.data  #bian\n",
        "    Bout.data -= learning_rate*Bout.grad.data  #b\n",
        "\n",
        "  W1.grad.data.zero_()#nb\n",
        "  B1.grad.data.zero_()#nb\n",
        "  Wout.grad.data.zero_()#b\n",
        "  Bout.grad.data.zero_()#b\n",
        "\n",
        "\n",
        "  if epoch % 200 == 199:#nd\n",
        "    with torch.no_grad():#nd\n",
        "      z1 = torch.add(torch.matmul(x_data_torch ,W1),B1) #nd\n",
        "      Zout = torch.add(torch.matmul(F.relu(z1),Wout),Bout)#d\n",
        "      predicted = torch.argmax(Zout,1)#lued\n",
        "      train_acc = accuracy_score(predicted.numpy(),y_data)#nd\n",
        "      print('Epoch: %d, loss: %.4f, train_acc: %.3f' %(epoch +1, loss.item() , train_acc))\n",
        "#nd\n",
        "print(\"Finished\") #分隔\n",
        "\n",
        "#result\n",
        "print('Predicted ：', predicted.numpy()) #Predicted ： [0 1 2 0 0 2]\n",
        "print('Truth :', y_data)#Trure ： [0 1 2 0 0 2]\n",
        "print('Accuracy : %.2f' %train_acc) #Accuracy :\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 200, loss: 0.9641, train_acc: 0.500\n",
            "Epoch: 400, loss: 0.8275, train_acc: 0.667\n",
            "Epoch: 600, loss: 0.7101, train_acc: 0.833\n",
            "Epoch: 800, loss: 0.6079, train_acc: 0.833\n",
            "Epoch: 1000, loss: 0.5234, train_acc: 0.833\n",
            "Epoch: 1200, loss: 0.4527, train_acc: 0.833\n",
            "Epoch: 1400, loss: 0.3903, train_acc: 0.833\n",
            "Epoch: 1600, loss: 0.3342, train_acc: 1.000\n",
            "Epoch: 1800, loss: 0.2883, train_acc: 1.000\n",
            "Epoch: 2000, loss: 0.2466, train_acc: 1.000\n",
            "Finished\n",
            "Predicted ： [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy : 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-BmDmmE3aUI"
      },
      "source": [
        "# **No hidden layer --- Optimiser** 优化器没有隐藏层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glRGSA-O4kU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0d55400-133f-49b7-bb5f-1f9756613f69"
      },
      "source": [
        "#调包多调了个优化器\n",
        "'''\n",
        "build model (a neural network） ✅  --- initializing （parameters manually) X\n",
        "torch.nn.Linear 这个是做什么的： linear transformation (input data) ---- y=Ax+b\n",
        "这里是A的转置貌似AT\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "\n",
        "correspond  \n",
        " 英  [ˌkɒrəˈspɒnd]   美  [ˌkɔːrəˈspɑːnd]\n",
        "\n",
        "vi. 符合，一致；相应；通信\n",
        "\n",
        "#perpare for data\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])  #创建数据one-hot\n",
        "\n",
        "x_data_torch = torch.from_numpy(x_data).float() #转类型变张量，目前还是整数\n",
        "\n",
        "y_data = np.array([0,1,2,0,0,2]) #output\n",
        "y_data_torch = torch.from_numpy(y_data) #output torch\n",
        "\n",
        "num_features = 2 # 2个特征--hair, feather\n",
        "num_classes = 3 # 3 输出类 other,mammal,bird\n",
        "\n",
        "'''\n",
        "#定义大类。然后大类的inint中是使用nn线性回归然后做了个线性化。 （向前传播） 然后再做了个向前传播的函数，定义了变量x。【可能是输入的one-hot\n",
        "# 初始化模型 initialize the model\n",
        "# 学习率\n",
        "#计算损失 -----计算负对数似然损失\n",
        "#优化器     【1 定义优化器--2 传递模型参数来进行更新。+ 调用optim.SGD时设置的学习率 3 使用的是SGD 优化器https://pytorch.org/docs/stable/optim.html\n",
        "# 定义时期（纪元）\n",
        "'''你在想什么落了优化器还有其他的几步……'''\n",
        "#修改权重。（用给定的学习率）每个阶段   1 初始化[获得input 和标签==output] 2train mode[模式】（net.train(mode = True) or evaluation (评估) mode (when net.train(mode = False)/ net.eval())\n",
        "'''\n",
        "初始化投入数据——>>训练评估模式\n",
        "一个模块可以设置为训练模式net.train mode = True； 评估模式 net.train中 mode 评估=false 或net.eval()\n",
        "仅对certain modules (Dropout, BtchNorm等)有效； 仅对某些模块有效\n",
        "'''\n",
        "#设置梯度为0 \n",
        "#输出   ： 向前传播+向后传播+ 优化\n",
        "'''\n",
        "output(model-inputs) --- loss(softmax) ---backward---optimiser\n",
        "'''\n",
        "#开始按照时期准备输出数据了\n",
        "'''\n",
        "1预测： model.eval\n",
        "2 outputs\n",
        "3 预测 ： 用2的数据进行argmax  从2的数据中，找出dim = 1 ：1维度最大的值的index\n",
        "4  准确率 accuracy_score\n",
        "'''"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\noutput(model-inputs) --- loss(softmax) ---backward---optimiser\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_-QPWaZRVpX",
        "outputId": "ceeb4509-a379-4bd5-fda2-579958f1f6f5"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim #bt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class ModelWithoutHiddenLayer(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super(ModelWithoutHiddenLayer, self).__init__()  #必须有的你忘了\n",
        "    #AttributeError: cannot assign module before Module.__init__() call  没有.__init__() 就没办法调用模块\n",
        "    self.linear = nn.Linear(input_size, output_size) # corresponds 对应 W1,B1 (是不是就是W1，B1)\n",
        "  \n",
        "  def forward(self, x):         #就是做线性回归的函数\n",
        "    x = self.linear(x)\n",
        "    return x    #没返回x\n",
        "  \n",
        "model = ModelWithoutHiddenLayer(num_features, num_classes) # 初始化模型\n",
        "learning_rate = 0.01\n",
        "criterion = nn.NLLLoss() # 计算负对数似然损失 calculate negatice log likelihood loss\n",
        "\n",
        "optimiser = optim.SGD(model.parameters(), lr=learning_rate) # 定义优化器\n",
        "\n",
        "no_of_epochs = 2000 #epochs\n",
        "\n",
        "for epoch in range(no_of_epochs): #for every epoch, the model weights will be modified using the given learning rate\n",
        "  inputs = x_data_torch\n",
        "  labels = y_data_torch\n",
        "\n",
        "  model.train()  # mode = True (default 默认)\n",
        "  optimiser.zero_grad() \n",
        "\n",
        "# forward + backward + optimize\n",
        "  outputs = model(inputs) \n",
        "  loss = criterion(F.log_softmax(outputs,dim=1), labels) # 准则\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "\n",
        "  if epoch % 200 == 199: # 打印200时期\n",
        "    model.eval() #predict( set the module to evaluation mode)\n",
        "    pre_outputs = model(inputs)\n",
        "    predicted = torch.argmax(pred_outputs, 1)\n",
        "    train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "    print('%d, loss: %.3f, train_acc: %.3f' %(epoch + 1, loss.item(),train_acc))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "#result\n",
        "model.eval()\n",
        "pred_outputs = model(inputs)\n",
        "predicted = torch.argmax(pred_outputs, 1)\n",
        "print('Predicted :', predicted.numpy())\n",
        "print('Truth :', y_data)\n",
        "\n",
        "train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "print('Accuracy :%.2f' %train_acc)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200, loss: 0.955, train_acc: 1.000\n",
            "400, loss: 0.782, train_acc: 1.000\n",
            "600, loss: 0.660, train_acc: 1.000\n",
            "800, loss: 0.568, train_acc: 1.000\n",
            "1000, loss: 0.496, train_acc: 1.000\n",
            "1200, loss: 0.438, train_acc: 1.000\n",
            "1400, loss: 0.391, train_acc: 1.000\n",
            "1600, loss: 0.352, train_acc: 1.000\n",
            "1800, loss: 0.319, train_acc: 1.000\n",
            "2000, loss: 0.291, train_acc: 1.000\n",
            "Finished Training\n",
            "Predicted : [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy :1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXPbhcjXZee0"
      },
      "source": [
        "#**Hidden Layer with the optimiser**   优化器的隐藏层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8L_jfc8fj7c"
      },
      "source": [
        "#调包\n",
        "#定义类\n",
        "'''\n",
        "多定义了一层 是把input output  中间加了一个hidden层\n",
        "这样就变成了 input hidd   hidd outp\n",
        "\n",
        "'''\n",
        "#定义函数向前传播\n",
        "'''\n",
        "多个激活函数要激活一下z1 然后放到Zout\n",
        "'''\n",
        "\n",
        "#模型调用值。input： 特点总数； 一个隐藏层； output： 类数\n",
        "#学习率\n",
        "#定义时期\n",
        "#损失函数  ：要进行softmax 只不过这里换了个方法\n",
        "'''\n",
        "Pythorch's CrossEntropyLoss ————》criterion准则\n",
        "same result -- Pytorch's  NLLLoss -->LogSoftmax layer add after output layer(original)\n",
        "'''\n",
        "#优化器\n",
        "#导入skl-准确率分数的包\n",
        "# 多次循环数据集\n",
        "'''\n",
        "传递数据和标签 \n",
        "训练模型\n",
        "清空优化梯度\n",
        "输出训练后数据\n",
        "损失\n",
        "反向传播\n",
        "优化器（多次重新计算）\n",
        "'''\n",
        "#开始进行200打一次数据打一次损失和 训练准确度\n",
        "'''\n",
        "这里4句看起来都是在为训练准确度这个结果服务的\n",
        "'''\n",
        "\n",
        "#然后输出结果。\n",
        "'''\n",
        "预测真实和准确率\n",
        "以及怎么去实现的准备情况。\n",
        "'''\n",
        "'''\n",
        "【1000预测的九不准了】\n",
        "200, loss: 0.9767, train_acc: 0.5000\n",
        "400, loss: 0.8606, train_acc: 0.5000\n",
        "600, loss: 0.7692, train_acc: 0.8333\n",
        "800, loss: 0.6840, train_acc: 0.8333\n",
        "1000, loss: 0.6091, train_acc: 0.8333\n",
        "Finished Training\n",
        "Predicted : [0 0 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 0.83\n",
        "\n",
        "【2000，有隐藏层的优化】\n",
        "200, loss: 0.9377, train_acc: 0.8333\n",
        "400, loss: 0.7203, train_acc: 0.8333\n",
        "600, loss: 0.5153, train_acc: 0.8333\n",
        "800, loss: 0.3646, train_acc: 0.8333\n",
        "1000, loss: 0.2612, train_acc: 1.0000\n",
        "1200, loss: 0.1882, train_acc: 1.0000\n",
        "1400, loss: 0.1382, train_acc: 1.0000\n",
        "1600, loss: 0.1047, train_acc: 1.0000\n",
        "1800, loss: 0.0822, train_acc: 1.0000\n",
        "2000, loss: 0.0664, train_acc: 1.0000\n",
        "Finished Training\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4h-02--XUOQ",
        "outputId": "7045c065-fee7-41d7-b3b7-01e852f5a0c1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "n_hidden_1 = 5   #老师没这部\n",
        "class ModelWithHiddenLayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(ModelWithHiddenLayer, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)    #b\n",
        "    self.linear2 = nn.Linear(hidden_size, output_size)  #b\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = self.linear1(x)\n",
        "    Zout = self.linear2(F.relu(z1))  #b\n",
        "    return Zout\n",
        "\n",
        "model = ModelWithHiddenLayer(num_features, n_hidden_1, num_classes)\n",
        "\n",
        "learning_rate=0.01\n",
        "no_of_epochs= 2000\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # == criterion = nn.NLLLoss()  ##b\n",
        "optimiser = optim.SGD(model.parameters(), lr=learning_rate) \n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for epoch in range(no_of_epochs): #loop dataset multiple times\n",
        "  #get inputs\n",
        "  inputs = x_data_torch\n",
        "  labels = y_data_torch\n",
        "\n",
        "  model.train()\n",
        "  # zero parameter gradients\n",
        "  optimiser.zero_grad()\n",
        "  # forward + backward+ optimize\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, labels) # don't need to calcualte logsoftmax here\n",
        "  loss.backward()\n",
        "  optimiser.step()\n",
        "\n",
        "  # print statistics\n",
        "  if epoch % 200 == 199:    # print 每200 epochs\n",
        "    model.eval()\n",
        "    pred_outputs = model(inputs)\n",
        "    predicted = torch.argmax(pred_outputs, 1)\n",
        "    train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "    print('%d, loss: %.4f, train_acc: %.4f' %(epoch+1, loss.item(), train_acc))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "#Result\n",
        "pred_outputs = model(inputs)\n",
        "_,predicted = torch.max(pred_outputs, 1)\n",
        "print('Predicted :', predicted.numpy())\n",
        "print('Truth :', y_data)\n",
        "\n",
        "train_acc = accuracy_score(predicted.numpy(),y_data)\n",
        "print('Accuracy : %.2f'%train_acc)\n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200, loss: 0.9377, train_acc: 0.8333\n",
            "400, loss: 0.7203, train_acc: 0.8333\n",
            "600, loss: 0.5153, train_acc: 0.8333\n",
            "800, loss: 0.3646, train_acc: 0.8333\n",
            "1000, loss: 0.2612, train_acc: 1.0000\n",
            "1200, loss: 0.1882, train_acc: 1.0000\n",
            "1400, loss: 0.1382, train_acc: 1.0000\n",
            "1600, loss: 0.1047, train_acc: 1.0000\n",
            "1800, loss: 0.0822, train_acc: 1.0000\n",
            "2000, loss: 0.0664, train_acc: 1.0000\n",
            "Finished Training\n",
            "Predicted : [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy : 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nVoSjL0k3Wr"
      },
      "source": [
        "# **Word2Vec on Pytorch** 做个WordVec-Skip Gram 在Neural Network (NN 通过pytorch）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_73zP56hr33"
      },
      "source": [
        "# 原始数据----套数 步型 Raw data - setences \n",
        "#[创建数据] 为了简单我们创建一个玩具数据 create toy data simplicity\n",
        "#【转换形式】将所有的句子转变成单词列表 convert 转变 split 分开 #把每个单词拆出来\n",
        "# 【每个词的词频】每个单词出现多少次\n",
        "'''\n",
        "在同时需要index和value值的时候可以使用 enumerate。\n",
        "1.有一 list= [1, 2, 3, 4, 5, 6]  \n",
        "请打印输出：\n",
        "0, 1 \n",
        "1, 2 \n",
        "2, 3 \n",
        "3, 4 \n",
        "4, 5 \n",
        "5, 6 \n",
        "\n",
        "list=[1,2,3,4,5,6]\n",
        " \n",
        "for i ,j in enumerate(list)\n",
        " \n",
        "　　print(i,j)\n",
        "\n",
        "\n",
        "word_to_idx = {w:i for i, w in enumerate(unique_vocab)}\n",
        "#给unique_vocab中的词加一个序号标签:\n",
        "    格式为w(词)：i(序号) \n",
        "    进行循环将词和序号取出来：for i, w(enumerate中的两个变量) in enumerate()\n",
        "\n",
        "#https://blog.csdn.net/weixin_40952784/article/details/90693555?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161641229716780266234301%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161641229716780266234301&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-90693555.first_rank_v2_pc_rank_v29&utm_term=%7Bw%3A+i+for+i%2C+w+in+enumerate%28word_list%29%7D+\n",
        "\n",
        "\n",
        "window size = 1 for skip-gram\n",
        "# i.e.) he likes cat\n",
        "#   -> (he, [likes]), (likes,[he, cat]), (cat,[likes])\n",
        "#   -> (he, likes), (likes, he), (likes, cat), (cat, likes)\n",
        "#https://blog.csdn.net/weixin_41843918/article/details/90312339?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161641162716780357265067%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161641162716780357265067&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-90312339.first_rank_v2_pc_rank_v29&utm_term=skip-gram+\n",
        "跳表\n",
        "'''\n",
        "#初始化 skip_grams : 开始跳表\n",
        "#开始作循环  在做window 和跳步\n",
        "#取两边的内容然后有点迭代的意思 感觉就是整个skip_grams 方法\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahfHhyZ9rfHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c79812-f357-4b81-f352-fd2de655fa3b"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sentences = [\"he likes cat\",\n",
        "             \"he likes dog\",\n",
        "             \"he likes animal\",\n",
        "             \"dog cat animal\",\n",
        "             \"she likes cat\",\n",
        "             \"she dislikes dog\",\n",
        "             \"cat likes fish\",\n",
        "             \"cat likes milk\",\n",
        "             \"dog likes bone\",\n",
        "             \"dog dislikes fish\",\n",
        "             \"dog likes milk\",\n",
        "             \"she likes movie\",\n",
        "             \"she likes music\",\n",
        "             \"he likes game\",\n",
        "             \"he likes movie\",\n",
        "             \"cat dislikes dog\"]\n",
        "\n",
        "word_list = \" \".join(sentences).split()   #把每个单词拆出来\n",
        "word_list = list(set(word_list))   #把重复的单词都去掉，每个单词都取一个\n",
        "\n",
        "word_dict = {w: i for i, w in enumerate(word_list)} # enumerate  （因·妞·摸·锐·忒）列举，枚举，计算。#取的不是个数么？怎么取得是序号ß\n",
        "skip_grams = []\n",
        "\n",
        "# make window size=1 for skip-gram\n",
        "\n",
        "for sentence in sentences:\n",
        "  sentence = sentence.split()       #['cat', 'dislikes', 'dog']\n",
        "  for i in range(len(sentence)):      #3\n",
        "    centre = word_dict[sentence[i]]     #5\n",
        "    if i > 0 and i < len(sentence)-1:\n",
        "      context = [word_dict[sentence[i - 1]], word_dict[sentence[i + 1]]]  #[11, 5]\n",
        "    elif i ==0:\n",
        "      context = [word_dict[sentence[i + 1]]]\n",
        "    else:\n",
        "      context = [word_dict[sentence[i - 1]]]\n",
        "\n",
        "    # skipgrams - (centre, context[0]), (centre, context[1])..\n",
        "    for w in context:\n",
        "      skip_grams.append([centre, w])\n",
        "\n",
        "    print(skip_grams)#自加\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8, 12]]\n",
            "[[8, 12], [12, 8], [12, 11]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6], [6, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6], [6, 12], [8, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6], [6, 12], [8, 12], [12, 8], [12, 0]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6], [6, 12], [8, 12], [12, 8], [12, 0], [0, 12]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6], [6, 12], [8, 12], [12, 8], [12, 0], [0, 12], [11, 9]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6], [6, 12], [8, 12], [12, 8], [12, 0], [0, 12], [11, 9], [9, 11], [9, 5]]\n",
            "[[8, 12], [12, 8], [12, 11], [11, 12], [8, 12], [12, 8], [12, 5], [5, 12], [8, 12], [12, 8], [12, 2], [2, 12], [5, 11], [11, 5], [11, 2], [2, 11], [10, 12], [12, 10], [12, 11], [11, 12], [10, 9], [9, 10], [9, 5], [5, 9], [11, 12], [12, 11], [12, 7], [7, 12], [11, 12], [12, 11], [12, 3], [3, 12], [5, 12], [12, 5], [12, 4], [4, 12], [5, 9], [9, 5], [9, 7], [7, 9], [5, 12], [12, 5], [12, 3], [3, 12], [10, 12], [12, 10], [12, 0], [0, 12], [10, 12], [12, 10], [12, 1], [1, 12], [8, 12], [12, 8], [12, 6], [6, 12], [8, 12], [12, 8], [12, 0], [0, 12], [11, 9], [9, 11], [9, 5], [5, 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uta2JLJdwg1U"
      },
      "source": [
        "# 不重复的单词数量；大小\n",
        "# 分批准备 batch（拜吃） prepare \n",
        "'''\n",
        "输入+ 标签\n",
        "初始化这13个词，让他们都是0\n",
        "然后one-hot input\n",
        "获得中心词    添加它进入到input \n",
        "获得内容词\n",
        "#np.array(inputs), np.array(labels) 传参\n",
        "'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oMRKplKvdxw"
      },
      "source": [
        "voc_size = len(word_list)       # 不重复的单词一共13; 13\n",
        "\n",
        "def prepare_batch(data_temp):\n",
        "  inputs = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(len(data_temp)):\n",
        "    input_temp = [0]*voc_size     #让这13个不同的单词位置上都是0;#[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]s\n",
        "    input_temp[data_temp[i][0]] = 1   # one-hot input 【？？】是指【input】【labels】么？\n",
        "    inputs.append(input_temp)   # centre\n",
        "    labels.append(data_temp[i][1])  #context word\n",
        "\n",
        "  return np.array(inputs), np.array(labels)\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TTlw0KKzA-r"
      },
      "source": [
        "# 调包\n",
        "# 批量的大小\n",
        "#学习率\n",
        "#时期\n",
        "#W权重  \n",
        "# （（（改组训练集以每个纪元的步长不同；也可以跳过此步 ）））嵌入大小 #shuffle 洗牌\n",
        "'''\n",
        "……\n",
        "[[8, 12], [12, 11], [9, 5], [10, 12], [12, 11], [9, 10], [9, 5], [10, 12], [9, 7], [11, 12], [7, 9], [12, 1], [11, 12], [12, 11], [12, 8], [10, 12], [5, 11], [12, 0], [2, 12], [11, 2], [4, 12], [8, 12], [12, 10], [12, 5], [1, 12], [12, 5], [12, 8], [3, 12], [12, 6], [12, 0], [2, 11], [12, 4], [6, 12], [12, 3], [5, 12], [9, 5], [5, 12], [0, 12], [10, 9], [11, 12], [12, 5], [12, 7], [11, 5], [0, 12], [12, 3], [12, 11], [7, 12], [12, 8], [8, 12], [8, 12], [12, 2], [8, 12], [3, 12], [5, 12], [11, 9], [11, 12], [5, 9], [12, 8], [12, 10], [5, 9], [12, 8], [9, 11], [12, 10], [5, 9]]\n",
        "[[2, 11], [12, 11], [11, 2], [9, 5], [9, 11], [1, 12], [5, 9], [10, 12], [3, 12], [5, 12], [12, 10], [5, 9], [7, 9], [12, 10], [10, 12], [8, 12], [12, 0], [12, 1], [12, 11], [12, 2], [12, 8], [12, 8], [10, 9], [9, 10], [12, 8], [12, 5], [10, 12], [8, 12], [0, 12], [11, 5], [12, 8], [12, 11], [12, 5], [12, 3], [8, 12], [9, 7], [8, 12], [12, 7], [9, 5], [11, 12], [6, 12], [5, 11], [12, 6], [0, 12], [12, 3], [5, 12], [12, 4], [12, 0], [12, 5], [12, 10], [2, 12], [5, 9], [8, 12], [11, 12], [9, 5], [12, 11], [11, 12], [4, 12], [7, 12], [11, 9], [11, 12], [5, 12], [12, 8], [3, 12]]\n",
        "[[8, 12], [9, 5], [12, 11], [11, 12], [3, 12], [4, 12], [11, 9], [10, 12], [12, 5], [11, 12], [12, 8], [12, 11], [5, 9], [12, 8], [12, 10], [0, 12], [8, 12], [12, 8], [9, 10], [9, 5], [8, 12], [12, 6], [12, 5], [2, 11], [12, 10], [10, 9], [1, 12], [11, 2], [12, 8], [5, 12], [5, 9], [3, 12], [8, 12], [5, 12], [11, 12], [12, 2], [5, 9], [12, 10], [11, 12], [6, 12], [12, 1], [9, 5], [12, 7], [9, 7], [2, 12], [12, 0], [11, 5], [10, 12], [12, 8], [7, 12], [5, 11], [12, 0], [9, 11], [5, 12], [8, 12], [10, 12], [0, 12], [7, 9], [12, 3], [12, 5], [12, 4], [12, 11], [12, 3], [12, 11]]\n",
        "[[12, 10], [12, 8], [12, 8], [12, 11], [7, 12], [5, 9], [11, 5], [5, 11], [4, 12], [10, 9], [9, 10], [12, 11], [12, 4], [5, 12], [12, 11], [11, 12], [12, 0], [9, 5], [3, 12], [10, 12], [8, 12], [11, 12], [5, 9], [12, 1], [12, 10], [12, 8], [3, 12], [8, 12], [12, 8], [12, 6], [8, 12], [0, 12], [12, 3], [11, 2], [7, 9], [12, 11], [10, 12], [12, 7], [12, 2], [1, 12], [0, 12], [9, 7], [10, 12], [11, 12], [12, 5], [6, 12], [9, 5], [9, 11], [2, 12], [5, 12], [11, 12], [8, 12], [12, 5], [2, 11], [12, 3], [5, 12], [8, 12], [12, 5], [12, 10], [12, 0], [11, 9], [12, 8], [5, 9], [9, 5]]\n",
        "[[5, 9], [10, 12], [5, 12], [9, 10], [11, 12], [12, 1], [12, 11], [12, 3], [3, 12], [1, 12], [9, 5], [7, 9], [9, 11], [12, 4], [12, 5], [12, 10], [12, 7], [10, 12], [6, 12], [5, 11], [12, 3], [12, 11], [12, 2], [12, 8], [2, 11], [9, 7], [8, 12], [11, 5], [5, 12], [5, 9], [12, 0], [11, 12], [12, 10], [0, 12], [12, 0], [10, 9], [12, 6], [12, 8], [11, 12], [7, 12], [3, 12], [12, 8], [11, 2], [12, 11], [4, 12], [12, 10], [12, 8], [9, 5], [2, 12], [8, 12], [10, 12], [12, 5], [12, 5], [5, 12], [5, 9], [8, 12], [0, 12], [11, 12], [8, 12], [12, 8], [8, 12], [12, 11], [11, 9], [9, 5]]\n",
        "[[8, 12], [11, 9], [1, 12], [7, 9], [12, 0], [0, 12], [12, 5], [12, 0], [12, 10], [12, 2], [12, 10], [5, 9], [5, 11], [11, 12], [5, 9], [3, 12], [8, 12], [12, 4], [12, 8], [5, 12], [12, 7], [12, 3], [8, 12], [11, 12], [6, 12], [5, 12], [12, 11], [12, 8], [3, 12], [10, 12], [10, 9], [2, 12], [12, 1], [7, 12], [9, 5], [12, 3], [9, 7], [11, 12], [5, 9], [12, 5], [11, 5], [2, 11], [12, 8], [12, 8], [8, 12], [12, 10], [10, 12], [12, 5], [12, 11], [5, 12], [8, 12], [9, 10], [11, 12], [4, 12], [12, 11], [10, 12], [9, 5], [11, 2], [12, 11], [12, 8], [9, 5], [0, 12], [12, 6], [9, 11]]\n",
        "[[5, 12], [2, 11], [11, 5], [3, 12], [5, 12], [11, 9], [12, 3], [12, 11], [11, 12], [8, 12], [5, 12], [12, 4], [11, 12], [9, 10], [12, 0], [9, 5], [9, 7], [12, 11], [5, 9], [8, 12], [10, 12], [10, 12], [5, 11], [8, 12], [9, 5], [9, 11], [10, 9], [0, 12], [1, 12], [12, 7], [12, 2], [7, 12], [12, 10], [5, 9], [7, 9], [12, 8], [5, 9], [12, 8], [11, 12], [6, 12], [12, 6], [12, 5], [12, 10], [4, 12], [12, 11], [10, 12], [11, 12], [12, 10], [12, 5], [0, 12], [9, 5], [12, 8], [3, 12], [12, 8], [8, 12], [12, 0], [12, 8], [12, 3], [11, 2], [12, 1], [12, 11], [8, 12], [12, 5], [2, 12]]\n",
        "[[12, 3], [10, 12], [12, 5], [12, 8], [11, 12], [0, 12], [8, 12], [12, 10], [0, 12], [12, 5], [9, 10], [8, 12], [5, 12], [11, 2], [3, 12], [5, 11], [10, 12], [5, 9], [5, 12], [12, 11], [11, 12], [2, 11], [1, 12], [8, 12], [4, 12], [5, 9], [3, 12], [12, 8], [11, 5], [12, 11], [5, 12], [11, 12], [9, 5], [12, 0], [12, 7], [12, 5], [8, 12], [12, 2], [12, 11], [9, 5], [2, 12], [7, 12], [12, 1], [12, 8], [5, 9], [12, 4], [12, 0], [7, 9], [10, 9], [12, 10], [12, 3], [12, 11], [11, 12], [6, 12], [9, 11], [12, 8], [8, 12], [9, 7], [9, 5], [12, 10], [12, 6], [10, 12], [12, 8], [11, 9]]\n",
        "[[12, 8], [2, 12], [4, 12], [12, 10], [12, 4], [9, 5], [1, 12], [0, 12], [9, 5], [2, 11], [11, 2], [11, 12], [11, 9], [12, 10], [10, 12], [12, 5], [5, 9], [12, 5], [9, 5], [12, 11], [3, 12], [12, 0], [9, 10], [12, 11], [10, 12], [12, 10], [5, 9], [12, 11], [10, 12], [10, 9], [11, 12], [9, 11], [5, 11], [9, 7], [3, 12], [7, 9], [12, 7], [8, 12], [8, 12], [8, 12], [12, 3], [12, 2], [12, 8], [11, 12], [12, 8], [6, 12], [8, 12], [12, 5], [12, 8], [12, 0], [0, 12], [11, 12], [5, 12], [12, 3], [12, 11], [5, 12], [12, 1], [11, 5], [5, 12], [12, 6], [7, 12], [8, 12], [5, 9], [12, 8]]\n",
        "[[5, 12], [12, 1], [12, 8], [0, 12], [12, 8], [11, 12], [9, 5], [11, 12], [12, 10], [12, 3], [9, 5], [9, 11], [12, 3], [12, 10], [11, 9], [11, 5], [12, 5], [8, 12], [11, 12], [8, 12], [11, 2], [5, 9], [12, 11], [12, 5], [10, 12], [10, 12], [12, 11], [10, 12], [12, 11], [12, 0], [5, 11], [12, 0], [1, 12], [12, 2], [12, 4], [11, 12], [8, 12], [6, 12], [5, 9], [12, 8], [12, 8], [10, 9], [3, 12], [2, 12], [3, 12], [0, 12], [9, 10], [5, 9], [12, 5], [7, 9], [12, 7], [8, 12], [5, 12], [9, 5], [8, 12], [7, 12], [12, 11], [12, 10], [9, 7], [5, 12], [12, 8], [4, 12], [12, 6], [2, 11]]\n",
        "[[12, 8], [7, 9], [12, 6], [9, 5], [11, 5], [8, 12], [12, 11], [1, 12], [10, 12], [12, 1], [12, 7], [12, 10], [11, 12], [12, 2], [7, 12], [2, 12], [6, 12], [3, 12], [10, 12], [9, 5], [4, 12], [5, 9], [12, 0], [0, 12], [9, 11], [9, 7], [11, 12], [8, 12], [12, 5], [12, 10], [0, 12], [12, 11], [12, 4], [2, 11], [8, 12], [5, 11], [11, 9], [12, 0], [10, 9], [3, 12], [12, 5], [12, 8], [5, 9], [12, 11], [11, 2], [9, 10], [8, 12], [12, 10], [5, 12], [10, 12], [8, 12], [12, 8], [12, 8], [12, 11], [12, 3], [11, 12], [12, 8], [11, 12], [5, 9], [5, 12], [12, 5], [5, 12], [9, 5], [12, 3]]\n",
        "[[8, 12]……\n",
        "''''\n",
        "# 每个时期中还有个for循环\n",
        "#\n",
        "'''\n",
        "min(iterable, *[, default=obj, key=func]) -> value\n",
        "min(arg1, arg2, *args, *[, key=func]) -> value\n",
        "'''\n",
        "#sotmax\n",
        "#backward\n",
        "# grad 优化学习率\n",
        "#清零 \n",
        "#损失的和\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQxUGqn1zBha",
        "outputId": "178fc862-c67d-4128-833b-eac992e02920"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import shuffle\n",
        "\n",
        "batch_size = 16\n",
        "learning_rate = 0.1\n",
        "embedding_size = 2\n",
        "no_of_epochs = 5000\n",
        "\n",
        "W1 = torch.randn(voc_size, embedding_size, requires_grad = True)  #还是随机生成\n",
        "Wout = torch.randn(embedding_size, voc_size, requires_grad=True)  #还是随机生成\n",
        "\n",
        "for epoch in range(no_of_epochs):\n",
        "  shuffle(skip_grams) #非必须\n",
        "  loss_sum = 0  #非必须\n",
        "\n",
        "  for ind in range(0,len(skip_grams),batch_size):\n",
        "    data_temp = skip_grams[ind: min(ind+batch_size, len(skip_grams))]\n",
        "    inputs_temp, labels_temp = prepare_batch(data_temp)\n",
        "\n",
        "    inputs_torch = torch.from_numpy(inputs_temp).float()\n",
        "    labels_torch = torch.from_numpy(labels_temp)  #把数组转成张量\n",
        "\n",
        "    hidden = torch.matmul(inputs_torch,W1)\n",
        "    out = torch.matmul(hidden,Wout)\n",
        "\n",
        "    log_softmax = F.log_softmax(out,dim=1) #(out,dim=1)落东西了\n",
        "    loss = F.nll_loss(log_softmax, labels_torch)\n",
        "\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      W1.data -= learning_rate*W1.grad.data\n",
        "      Wout.data -= learning_rate*Wout.grad.data\n",
        "    W1.grad.data.zero_()\n",
        "    Wout.grad.data.zero_()\n",
        "\n",
        "    loss_sum += loss.item()\n",
        "\n",
        "  if epoch % 500 == 499:\n",
        "    print('Epoch: %d, loss: %.4f' %(epoch +1 , loss_sum))\n",
        "\n",
        "\n",
        "#各种打错\n",
        "#每次的loss都不一样\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 500, loss: 5.5482\n",
            "Epoch: 1000, loss: 5.4800\n",
            "Epoch: 1500, loss: 5.4591\n",
            "Epoch: 2000, loss: 5.4658\n",
            "Epoch: 2500, loss: 5.4497\n",
            "Epoch: 3000, loss: 5.4275\n",
            "Epoch: 3500, loss: 5.4261\n",
            "Epoch: 4000, loss: 5.4184\n",
            "Epoch: 4500, loss: 5.4333\n",
            "Epoch: 5000, loss: 5.4104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wmrTE9k70ZF"
      },
      "source": [
        "#开始画图了"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHYw_Ool8gU-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ZOPrNbHzxw"
      },
      "source": [
        "#**TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhQkzyUb7yZf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tKn51YZ5DvL"
      },
      "source": [
        "#9.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WloFAzg74913",
        "outputId": "3102402d-33c4-45d6-f327-dfe76a7fc2b0"
      },
      "source": [
        "#8.0\n",
        "out"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.5332e-01, -6.2606e-01, -6.5686e-01,  1.0695e+00,  2.0570e-01,\n",
              "          1.6159e+00,  9.9116e-01, -4.7721e-01, -4.8659e-01,  2.4906e-01,\n",
              "         -9.5885e-01, -2.2234e-03, -4.2856e-01],\n",
              "        [-1.5327e+00,  3.2539e-02, -1.5283e+00,  3.9316e-01, -1.1887e+00,\n",
              "          3.8653e-01, -1.2951e+00, -1.7716e-01, -3.1022e-01, -8.4771e-02,\n",
              "          1.1408e+00,  6.5776e-01,  3.0735e-01],\n",
              "        [ 5.0555e+00, -7.7394e-01,  3.5022e+00,  8.3063e-02,  3.5071e+00,\n",
              "          6.9841e-01,  4.6591e+00, -3.2242e-02,  3.2490e-01,  5.0622e-01,\n",
              "         -4.1978e+00, -1.8187e+00, -1.3169e+00],\n",
              "        [ 4.4253e+00, -1.1316e+00,  2.0176e+00,  1.0127e+00,  2.7882e+00,\n",
              "          1.9556e+00,  4.3423e+00, -4.4826e-01, -1.9130e-01,  5.9750e-01,\n",
              "         -3.9710e+00, -1.3530e+00, -1.3594e+00],\n",
              "        [-6.5855e-01, -7.1827e-01, -2.3466e+00,  1.6846e+00, -9.6507e-01,\n",
              "          2.3337e+00, -1.3078e-01, -7.5341e-01, -9.0033e-01,  2.1251e-01,\n",
              "          1.2266e-02,  6.6796e-01, -2.0103e-01],\n",
              "        [-3.3384e+00, -8.6428e-02, -3.6917e+00,  1.1819e+00, -2.6867e+00,\n",
              "          1.3075e+00, -2.7294e+00, -5.3137e-01, -8.4044e-01, -1.3116e-01,\n",
              "          2.3821e+00,  1.5154e+00,  5.9787e-01],\n",
              "        [ 4.1325e-01, -5.9573e-01, -9.4261e-01,  1.1089e+00, -4.3704e-02,\n",
              "          1.6333e+00,  6.9038e-01, -4.9514e-01, -5.3121e-01,  2.2239e-01,\n",
              "         -6.9065e-01,  1.3155e-01, -3.4986e-01],\n",
              "        [ 4.4253e+00, -1.1316e+00,  2.0176e+00,  1.0127e+00,  2.7882e+00,\n",
              "          1.9556e+00,  4.3423e+00, -4.4826e-01, -1.9130e-01,  5.9750e-01,\n",
              "         -3.9710e+00, -1.3530e+00, -1.3594e+00],\n",
              "        [-3.3384e+00, -8.6428e-02, -3.6917e+00,  1.1819e+00, -2.6867e+00,\n",
              "          1.3075e+00, -2.7294e+00, -5.3137e-01, -8.4044e-01, -1.3116e-01,\n",
              "          2.3821e+00,  1.5154e+00,  5.9787e-01],\n",
              "        [ 4.4253e+00, -1.1316e+00,  2.0176e+00,  1.0127e+00,  2.7882e+00,\n",
              "          1.9556e+00,  4.3423e+00, -4.4826e-01, -1.9130e-01,  5.9750e-01,\n",
              "         -3.9710e+00, -1.3530e+00, -1.3594e+00],\n",
              "        [ 5.0555e+00, -7.7394e-01,  3.5022e+00,  8.3063e-02,  3.5071e+00,\n",
              "          6.9841e-01,  4.6591e+00, -3.2242e-02,  3.2490e-01,  5.0622e-01,\n",
              "         -4.1978e+00, -1.8187e+00, -1.3169e+00],\n",
              "        [ 2.0115e+00, -1.2590e-01,  1.8136e+00, -3.4375e-01,  1.5084e+00,\n",
              "         -2.6098e-01,  1.7480e+00,  1.5555e-01,  3.1996e-01,  1.3953e-01,\n",
              "         -1.5514e+00, -8.1942e-01, -4.4119e-01],\n",
              "        [ 4.4253e+00, -1.1316e+00,  2.0176e+00,  1.0127e+00,  2.7882e+00,\n",
              "          1.9556e+00,  4.3423e+00, -4.4826e-01, -1.9130e-01,  5.9750e-01,\n",
              "         -3.9710e+00, -1.3530e+00, -1.3594e+00],\n",
              "        [-1.5327e+00,  3.2539e-02, -1.5283e+00,  3.9316e-01, -1.1887e+00,\n",
              "          3.8653e-01, -1.2951e+00, -1.7716e-01, -3.1022e-01, -8.4771e-02,\n",
              "          1.1408e+00,  6.5776e-01,  3.0735e-01],\n",
              "        [ 4.4253e+00, -1.1316e+00,  2.0176e+00,  1.0127e+00,  2.7882e+00,\n",
              "          1.9556e+00,  4.3423e+00, -4.4826e-01, -1.9130e-01,  5.9750e-01,\n",
              "         -3.9710e+00, -1.3530e+00, -1.3594e+00],\n",
              "        [ 5.0555e+00, -7.7394e-01,  3.5022e+00,  8.3063e-02,  3.5071e+00,\n",
              "          6.9841e-01,  4.6591e+00, -3.2242e-02,  3.2490e-01,  5.0622e-01,\n",
              "         -4.1978e+00, -1.8187e+00, -1.3169e+00]], grad_fn=<MmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CykMvzbY4rRk",
        "outputId": "0d48ccc1-ade0-4cae-e97b-cdf0f855e5df"
      },
      "source": [
        "#7.9\n",
        "torch.matmul(inputs_torch,W1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1217,  0.6713],\n",
              "        [ 0.1553, -0.0029],\n",
              "        [ 0.0227, -0.7057],\n",
              "        [ 0.8917,  2.1404],\n",
              "        [-0.0432,  0.0333],\n",
              "        [-0.2686,  0.3370],\n",
              "        [-1.5963,  1.8939],\n",
              "        [ 0.1553, -0.0029],\n",
              "        [ 0.8917,  2.1404],\n",
              "        [ 0.8917,  2.1404],\n",
              "        [ 0.0227, -0.7057],\n",
              "        [ 0.8917,  2.1404],\n",
              "        [-0.2686,  0.3370],\n",
              "        [ 0.8917,  2.1404],\n",
              "        [ 0.8917,  2.1404],\n",
              "        [ 0.8087, -1.3710]], grad_fn=<MmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr4QyC7j4LG-",
        "outputId": "977a5665-585b-4310-8aef-2d8142ff9bfe"
      },
      "source": [
        "#7.8\n",
        "labels_torch"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 12, 11,  3, 12,  7, 12, 12,  0,  8, 12, 10,  5,  4,  2, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEsqQGli397N",
        "outputId": "872d4f97-5412-4b6d-c1c3-762f0cc1e4a8"
      },
      "source": [
        "#7.7\n",
        "inputs_torch"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALSTh943oRL",
        "outputId": "7220baf3-d4be-4be1-a213-4184d21f8096"
      },
      "source": [
        "#7.6\n",
        "data_temp"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 12],\n",
              " [8, 12],\n",
              " [5, 11],\n",
              " [11, 12],\n",
              " [12, 3],\n",
              " [12, 10],\n",
              " [12, 10],\n",
              " [11, 2],\n",
              " [12, 5],\n",
              " [12, 8],\n",
              " [2, 11],\n",
              " [10, 12],\n",
              " [5, 9],\n",
              " [5, 12],\n",
              " [12, 11],\n",
              " [11, 12]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eTdxHOo3io-",
        "outputId": "09863fe7-09ef-4a55-ddd6-9ae5f7b15030"
      },
      "source": [
        "#7.5\n",
        "prepare_batch(data_temp)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]),\n",
              " array([12, 12, 11, 12,  3, 10, 10,  2,  5,  8, 11, 12,  9, 12, 11, 12]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5Dl-F9r3fvk",
        "outputId": "a2b5b9ed-4ac8-494b-8f5a-2d8c02ea863a"
      },
      "source": [
        "#7.4\n",
        "labels_temp"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12, 12, 11, 12,  3, 10, 10,  2,  5,  8, 11, 12,  9, 12, 11, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScGFg0cf3cTI",
        "outputId": "32cc53b5-9d00-4492-a1b8-8a2b689abd24"
      },
      "source": [
        "#7.3\n",
        "inputs_temp"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UMwGmld3NoE",
        "outputId": "b50aef3e-60c3-41e5-ba8d-824f5cc596dc"
      },
      "source": [
        "#7.2\n",
        "data_temp"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[12, 6],\n",
              " [12, 4],\n",
              " [8, 12],\n",
              " [12, 7],\n",
              " [12, 8],\n",
              " [12, 5],\n",
              " [12, 1],\n",
              " [11, 12],\n",
              " [12, 5],\n",
              " [0, 12],\n",
              " [9, 5],\n",
              " [12, 2],\n",
              " [12, 3],\n",
              " [12, 11],\n",
              " [12, 0],\n",
              " [12, 11]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtj9KuBw0Bo1",
        "outputId": "5ee0683d-f76b-4bbb-9574-9f6ee6b2e441"
      },
      "source": [
        "#7.1\n",
        "Wout"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6159, -0.2847,  0.9176, -0.6348,  0.0147,  0.0952,  1.3493,  1.7976,\n",
              "          0.1350,  1.4466,  0.1889, -1.7932, -0.1516],\n",
              "        [-0.4044,  0.6437,  0.3943, -1.6288,  2.2797, -1.7545,  1.4212,  1.7390,\n",
              "          0.8627, -0.3189,  0.8507, -0.3310, -1.3315]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGJivKyGx7_K",
        "outputId": "0436105b-677a-4128-c771-a4015c720a50"
      },
      "source": [
        "#7.0\n",
        "W1"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5661, -0.8366],\n",
              "        [ 0.2910, -2.1765],\n",
              "        [-0.6783, -1.8235],\n",
              "        [-0.2273, -0.7827],\n",
              "        [ 1.0453, -0.2252],\n",
              "        [ 1.1485,  0.1908],\n",
              "        [ 0.6545, -0.7477],\n",
              "        [ 2.0658, -0.0719],\n",
              "        [ 0.7261, -0.3559],\n",
              "        [-0.1800, -0.0757],\n",
              "        [-0.4821, -1.1116],\n",
              "        [ 0.4999, -3.1947],\n",
              "        [ 0.7890, -1.7659]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuL8lQi0xrLI",
        "outputId": "c22996ee-df46-41ef-afc1-718f8598b2bc"
      },
      "source": [
        "#6.0\n",
        "[0]*voc_size"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cenk6MO0vzaL",
        "outputId": "8ab180dc-499e-43ac-bb7b-e15e75a73359"
      },
      "source": [
        "#5.15\n",
        "voc_size"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ehouQGvOjJ",
        "outputId": "5f6a1838-c563-4882-afa7-04fa4b64add3"
      },
      "source": [
        "#5.14\n",
        "len(word_list)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUBG8g3uvKJ4",
        "outputId": "d93422af-bec2-4da1-bc5c-9dc57cb73bf6"
      },
      "source": [
        "#5.13\n",
        "centre"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CEDUwBnvBiO",
        "outputId": "422dc30b-9ed8-4ab5-8a18-3579f1dd36ef"
      },
      "source": [
        "#5.12\n",
        "w"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc5KcicluQhX",
        "outputId": "9ff44861-f3ca-4021-b45e-f84cdeef96e2"
      },
      "source": [
        "#5.11\n",
        "skip_grams"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 12],\n",
              " [12, 8],\n",
              " [12, 11],\n",
              " [11, 12],\n",
              " [8, 12],\n",
              " [12, 8],\n",
              " [12, 5],\n",
              " [5, 12],\n",
              " [8, 12],\n",
              " [12, 8],\n",
              " [12, 2],\n",
              " [2, 12],\n",
              " [5, 11],\n",
              " [11, 5],\n",
              " [11, 2],\n",
              " [2, 11],\n",
              " [10, 12],\n",
              " [12, 10],\n",
              " [12, 11],\n",
              " [11, 12],\n",
              " [10, 9],\n",
              " [9, 10],\n",
              " [9, 5],\n",
              " [5, 9],\n",
              " [11, 12],\n",
              " [12, 11],\n",
              " [12, 7],\n",
              " [7, 12],\n",
              " [11, 12],\n",
              " [12, 11],\n",
              " [12, 3],\n",
              " [3, 12],\n",
              " [5, 12],\n",
              " [12, 5],\n",
              " [12, 4],\n",
              " [4, 12],\n",
              " [5, 9],\n",
              " [9, 5],\n",
              " [9, 7],\n",
              " [7, 9],\n",
              " [5, 12],\n",
              " [12, 5],\n",
              " [12, 3],\n",
              " [3, 12],\n",
              " [10, 12],\n",
              " [12, 10],\n",
              " [12, 0],\n",
              " [0, 12],\n",
              " [10, 12],\n",
              " [12, 10],\n",
              " [12, 1],\n",
              " [1, 12],\n",
              " [8, 12],\n",
              " [12, 8],\n",
              " [12, 6],\n",
              " [6, 12],\n",
              " [8, 12],\n",
              " [12, 8],\n",
              " [12, 0],\n",
              " [0, 12],\n",
              " [11, 9],\n",
              " [9, 11],\n",
              " [9, 5],\n",
              " [5, 9]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7dFHDK_t9S1",
        "outputId": "3d5aa741-7021-4e71-f0be-417250563fa1"
      },
      "source": [
        "#5.10\n",
        "#word_dict[sentence[i + 1]] #IndexError: list index out of range\n",
        "context"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrHJnk_2t5wd",
        "outputId": "abd041ab-6f5a-440b-de4d-235b630ae453"
      },
      "source": [
        "#5.9\n",
        "word_dict[sentence[i - 1]] #9"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSqXG2OJrKlr",
        "outputId": "c6feb54d-477b-4cba-ea64-ed2a5c125315"
      },
      "source": [
        "#5.8\n",
        "for i in range(len(sentence)):\n",
        "  print(i)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvkbiT3WqsPI",
        "outputId": "344e2c19-9616-4a3d-a31d-223cffb6a02d"
      },
      "source": [
        "#5.7\n",
        "context #cat 。dog"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxRJxxeTqhKV",
        "outputId": "ef0de13e-91ef-41d8-ee43-8e728340236d"
      },
      "source": [
        "#5.6\n",
        "centre #dog【不应该是9dislike】"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR3rnSX8qc-C",
        "outputId": "27238cb3-2e2a-454f-c3f3-24eb52d95670"
      },
      "source": [
        "#5.5\n",
        "len(sentence)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnTb5DjKnGLb",
        "outputId": "43c360fb-1129-4581-ea19-5f2b8932cf28"
      },
      "source": [
        "#5.4\n",
        "sentence"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat', 'dislikes', 'dog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHEOKdNNlEoP",
        "outputId": "7a1e0d0c-898a-4158-b77a-5f464b048ebc"
      },
      "source": [
        "#5，3\n",
        "word_dict\n",
        "'''\n",
        "{'animal': 2,\n",
        " 'bone': 4,\n",
        " 'cat': 11,\n",
        " 'dislikes': 9,\n",
        " 'dog': 5,\n",
        " '''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'animal': 2,\n",
              " 'bone': 4,\n",
              " 'cat': 11,\n",
              " 'dislikes': 9,\n",
              " 'dog': 5,\n",
              " 'fish': 7,\n",
              " 'game': 6,\n",
              " 'he': 8,\n",
              " 'likes': 12,\n",
              " 'milk': 3,\n",
              " 'movie': 0,\n",
              " 'music': 1,\n",
              " 'she': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfu5_7tckUB3",
        "outputId": "45bf3e65-45a9-4b07-973b-dcf697753623"
      },
      "source": [
        "#5.2\n",
        "word_list\n",
        "'''\n",
        "['movie',\n",
        " 'music',\n",
        " 'animal',\n",
        " 'milk',\n",
        " 'bone',\n",
        " 'dog',\n",
        " 'game',\n",
        " '''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie',\n",
              " 'music',\n",
              " 'animal',\n",
              " 'milk',\n",
              " 'bone',\n",
              " 'dog',\n",
              " 'game',\n",
              " 'fish',\n",
              " 'he',\n",
              " 'dislikes',\n",
              " 'she',\n",
              " 'cat',\n",
              " 'likes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cRRG78grflY",
        "outputId": "9f9f676f-6603-4a86-fb32-9105c9cb4236"
      },
      "source": [
        "#Word2vec 5.1\n",
        "word_list\n",
        "\n",
        "'''\n",
        "\n",
        "['he',\n",
        " 'likes',\n",
        " 'cat',\n",
        " 'he',\n",
        " 'likes',\n",
        " 'dog',\n",
        " 'he',\n",
        " 'likes',\n",
        " 'animal',\n",
        " 'dog',\n",
        " 'cat',\n",
        " 'animal',\n",
        "\n",
        " '''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'likes',\n",
              " 'cat',\n",
              " 'he',\n",
              " 'likes',\n",
              " 'dog',\n",
              " 'he',\n",
              " 'likes',\n",
              " 'animal',\n",
              " 'dog',\n",
              " 'cat',\n",
              " 'animal',\n",
              " 'she',\n",
              " 'likes',\n",
              " 'cat',\n",
              " 'she',\n",
              " 'dislikes',\n",
              " 'dog',\n",
              " 'cat',\n",
              " 'likes',\n",
              " 'fish',\n",
              " 'cat',\n",
              " 'likes',\n",
              " 'milk',\n",
              " 'dog',\n",
              " 'likes',\n",
              " 'bone',\n",
              " 'dog',\n",
              " 'dislikes',\n",
              " 'fish',\n",
              " 'dog',\n",
              " 'likes',\n",
              " 'milk',\n",
              " 'she',\n",
              " 'likes',\n",
              " 'movie',\n",
              " 'she',\n",
              " 'likes',\n",
              " 'music',\n",
              " 'he',\n",
              " 'likes',\n",
              " 'game',\n",
              " 'he',\n",
              " 'likes',\n",
              " 'movie',\n",
              " 'cat',\n",
              " 'dislikes',\n",
              " 'dog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xACvg-hwlB0b",
        "outputId": "92ebdda6-c59e-4d84-f1ea-b66794058715"
      },
      "source": [
        "#4.2\n",
        "print(model)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ModelWithHiddenLayer(\n",
            "  (linear1): Linear(in_features=2, out_features=5, bias=True)\n",
            "  (linear2): Linear(in_features=5, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxAnTfY3ZfWx",
        "outputId": "30b13909-df27-48c1-d052-6573cfdf9bfc"
      },
      "source": [
        "#4。1\n",
        "model"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelWithHiddenLayer(\n",
              "  (linear1): Linear(in_features=2, out_features=5, bias=True)\n",
              "  (linear2): Linear(in_features=5, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-2AGjej332L"
      },
      "source": [
        "#3.1\n",
        "output"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1XndBB23zXa"
      },
      "source": [
        "optimiser no hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-87AU7wE6Y2A",
        "outputId": "331108a3-44ed-4286-a5f9-11acc0c352e4"
      },
      "source": [
        "#2.4\n",
        "Bout.data -= learning_rate*Bout.grad.data  #b\n",
        "print(Bout.data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.9189, -0.1212,  0.2067])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m643ySif6Oh9",
        "outputId": "d9241ac0-34cc-4cda-978e-0e3e8ba5e76b"
      },
      "source": [
        "#2.3\n",
        "Zout = torch.add(torch.matmul(F.relu(z1), Wout), Bout) \n",
        "print(Zout)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5934,  0.7461,  1.3760],\n",
            "        [-1.4566, -0.0133,  0.5646],\n",
            "        [-1.8992,  0.0396,  0.2620],\n",
            "        [-0.5934,  0.7461,  1.3760],\n",
            "        [-0.5934,  0.7461,  1.3760],\n",
            "        [-1.8286,  0.6143,  0.4600]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM8vDadV6EJP",
        "outputId": "41aca658-f19f-49a3-9378-091e6f03e3b2"
      },
      "source": [
        "#2.2\n",
        "Wout = torch.rand(n_hidden_1, num_classes, requires_grad=True)\n",
        "print(Wout)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.7730, 0.1804, 0.5983],\n",
            "        [0.9212, 0.4871, 0.7432],\n",
            "        [0.5285, 0.3293, 0.5707],\n",
            "        [0.7976, 0.9384, 0.7502],\n",
            "        [0.0467, 0.3825, 0.1316]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLvbRdoVR2ic",
        "outputId": "7b8706ef-5f92-4c79-d34e-4febcc024f3c"
      },
      "source": [
        "#2.1\n",
        "Zout = torch.add(torch.matmul(F.relu(z1),Wout),Bout)\n",
        "print(Zout)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3.5850, -0.1930,  0.2251],\n",
            "        [-0.6030,  0.0824, -0.4356],\n",
            "        [-1.3784, -0.2961,  0.7000],\n",
            "        [ 3.5850, -0.1930,  0.2251],\n",
            "        [ 3.5850, -0.1930,  0.2251],\n",
            "        [ 0.5547, -0.9210,  2.4629]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW8AlLHGRX0s"
      },
      "source": [
        "没隐藏层手动调参。 测试如下。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj6P5yPpMnJy",
        "outputId": "08bd5ca2-aeea-46bc-978c-cb625cc9fef6"
      },
      "source": [
        "#16\n",
        "tain_acc = accuracy_score(predicted.numpy(), y_data)\n",
        "print(tain_acc)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXupZX1qMUbI",
        "outputId": "0c2b5ebc-6bbe-4a31-c05f-d55b0db134d8"
      },
      "source": [
        "#15\n",
        "predicted = torch.argmax(pred_outputs, 1)\n",
        "print(predicted)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 0, 0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945ciGNxMFu3",
        "outputId": "15c647f8-c707-4f0c-9f73-98945a94beda"
      },
      "source": [
        "#14\n",
        "print(pred_outputs)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3947,  0.6585,  0.5634],\n",
            "        [ 0.9237, -0.4688,  0.6831],\n",
            "        [-1.6573,  1.1094,  1.3526],\n",
            "        [ 1.3947,  0.6585,  0.5634],\n",
            "        [ 1.3947,  0.6585,  0.5634],\n",
            "        [-1.1862,  2.2367,  1.2329]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBVVQhb8JTZ1",
        "outputId": "5697a777-5d1d-4091-a040-24fa8adca807"
      },
      "source": [
        "#13\n",
        "B1.data -= learning_rate*B1.grad.data\n",
        "print(B1.data)\n",
        "#tensor([ 2.1613,  0.7510, -0.7514],  #tensor([ 34.8541,  -0.3064, -33.4468])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 34.8541,  -0.3064, -33.4468])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w55lxdsH-YB",
        "outputId": "8bf88958-d56d-44cb-8633-f057cbf35b2b"
      },
      "source": [
        "#12\n",
        "W1.data -= learning_rate*W1.grad.data\n",
        "print(W1.data)\n",
        "\n",
        "\n",
        "'''\n",
        "tensor([[ 0.9477,  1.5061, -0.7059],\n",
        "        [-0.3978, -0.5679, -0.0613]\n",
        "        tensor([[ 0.3480,  0.0354,  0.5222],\n",
        "        [ 2.0451, -0.0493,  1.2841]])\n",
        "        '''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3480,  0.0354,  0.5222],\n",
            "        [ 2.0451, -0.0493,  1.2841]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eKzzYiTH551",
        "outputId": "8bd9aae9-2c6f-4e2f-d15c-20da46054136"
      },
      "source": [
        "#11\n",
        "loss = F.nll_loss(log_softmax, y_data_torch)\n",
        "print(loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.6704, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6H5td2MERT_",
        "outputId": "0ffb0e72-e23b-4517-bf25-573798fbc8bb"
      },
      "source": [
        "#10\n",
        "log_softmax = F.log_softmax(z,dim=1)\n",
        "print(log_softmax)\n",
        "\n",
        "#https://blog.csdn.net/hao5335156/article/details/80607732?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629884116780265451148%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161629884116780265451148&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-80607732.first_rank_v2_pc_rank_v29&utm_term=F.log_softmax\n",
        "#加快计算速度，数值上也更稳定。\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2611, -1.6715, -3.1738],\n",
            "        [-0.2168, -1.9441, -2.9598],\n",
            "        [-0.0504, -3.8751, -3.5608],\n",
            "        [-0.2611, -1.6715, -3.1738],\n",
            "        [-0.2611, -1.6715, -3.1738],\n",
            "        [-0.0537, -3.5615, -3.7339]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRoUblpt41wH",
        "outputId": "bede2b65-930b-45cc-a09a-4bd97302a8ec"
      },
      "source": [
        "#9 torch.matmul 可以输入高维的；二维就是图通乘法\n",
        "#输入多维就是把拖出来的一位作为batch 提出来。其他部分做矩阵乘法\n",
        "#将b的第0维 5 broadcast 提出来。后两维做矩阵乘法\n",
        "import pprint\n",
        "a = torch.ones(3,4)\n",
        "b = torch.ones(5,4,2)\n",
        "c = torch.matmul(a,b)\n",
        "print(c.shape)\n",
        "pprint.pprint(c)\n",
        "#https://blog.csdn.net/qsmx666/article/details/105783610?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629814016780271553753%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161629814016780271553753&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-4-105783610.first_rank_v2_pc_rank_v29&utm_term=torch.matmul参数怎么用\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 2])\n",
            "tensor([[[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb4iwTMW29ED",
        "outputId": "993fee4a-6517-4744-fdc5-62e5f42e4c33"
      },
      "source": [
        "#8\n",
        "z =torch.add(torch.matmul(x_data_torch, W1),B1) #参数传递到 torch.add 后返回输入参数的求和结果作为输出\n",
        "#torch.matmul 是常用乘法\n",
        "print(z)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.1613,  0.7510, -0.7514],\n",
            "        [ 2.5123,  0.7850, -0.2307],\n",
            "        [ 4.5605,  0.7358,  1.0501],\n",
            "        [ 2.1613,  0.7510, -0.7514],\n",
            "        [ 2.1613,  0.7510, -0.7514],\n",
            "        [ 4.2096,  0.7018,  0.5294]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EKSDj8g24hf",
        "outputId": "a4c30f12-dc20-4234-9740-eafce6d6e97d"
      },
      "source": [
        "#7\n",
        "B1 = torch.randn(num_classes, requires_grad=True)\n",
        "print(B1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2.1613,  0.7510, -0.7514], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgLWHdZ-UGfW",
        "outputId": "5a04070d-0f6e-4b3d-dadc-9cab6c5f0e1e"
      },
      "source": [
        "W1 = torch.randn(num_features, num_classes, requires_grad=True)\n",
        "print(W1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9477,  1.5061, -0.7059],\n",
            "        [-0.3978, -0.5679, -0.0613]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95YTLYnWMyEJ",
        "outputId": "ed3a7bd3-a67d-4e71-e4e9-2e68eba7ec11"
      },
      "source": [
        "#5\n",
        "num_features = 2 # 2个特征--hair, feather\n",
        "num_classes = 3 # 3 输出类 other,mammal,bird\n",
        "print(num_features,num_classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Rmcm2-LlBV",
        "outputId": "43508915-3370-4140-a8ef-612b2bd933b4"
      },
      "source": [
        "#4\n",
        "y_data_torch = torch.from_numpy(y_data)\n",
        "print(y_data_torch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 0, 0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYI10BEFJ-jz",
        "outputId": "db621d25-ba54-4b4d-c745-c24096695b65"
      },
      "source": [
        "#3\n",
        "y_data = np.array([0,1,2,0,0,2])\n",
        "print(y_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 0 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P7lRrFIJLRA",
        "outputId": "88489beb-0a19-4602-b079-23846c4b9ad6"
      },
      "source": [
        "#2\n",
        "x_data_torch = torch.from_numpy(x_data)\n",
        "print(x_data_torch)\n",
        "x_data_torch = torch.from_numpy(x_data).float()\n",
        "print(x_data_torch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 1]])\n",
            "tensor([[0., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09hJb5nSH2di",
        "outputId": "e3fc01fc-1558-40de-92b2-59f3e90cd481"
      },
      "source": [
        "#1\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])\n",
        "print(x_data)#竖着全打出来了 也就是一行为【】然后整个【】再（）放在数组当中"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}