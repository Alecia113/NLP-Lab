{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+lw2Sbv7lg9+WqNNw9xH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alecia113/NLP-Lab/blob/main/lab3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWQeQDbaGUnC"
      },
      "source": [
        "# **Neural Network Example**å®æˆ˜äº†æœ‰ç‚¹\n",
        "#identifying animal species (features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE8KNEpMGmJt"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZF7WPOwGq7T"
      },
      "source": [
        "two features: two aspects \n",
        "1: animal have hair\n",
        "2: animal have feathers\n",
        "has hair [011000]\n",
        "has feather [001001]\n",
        "----input ^\n",
        "0-Oher 1-Manmmal 2-Bird [012002]\n",
        "---output/y ^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgKImD0lHmu2"
      },
      "source": [
        "# aim: predict animal == bird/ manmmal/others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThpMFoWwHx-l"
      },
      "source": [
        "'''\n",
        "åˆ›å»ºæ•°æ®one-hot\n",
        "Create our feature data\n",
        "[hair,feather]:0: X; 1:âœ…\n",
        "[1,0]: animal has hair + doesn't have feathers\n",
        "'''\n",
        "\n",
        "'''\n",
        "è½¬æ¢æ•°æ®ï¼›å˜å¼ é‡\n",
        "transform data --> torch data type (Pytorch)\n",
        "ã€ä¼ è¯´ä¸­çš„å¦‚ä½•è®©è€å¸ˆè¿›è¡Œæµ‹è¯•ã€‘\n",
        "# Uncomment the following line to print out if you want to see the details\n",
        "# print(x_data_torch)\n",
        "'''\n",
        "\n",
        "'''\n",
        "å¥½åƒæ˜¯å°†è¾“å‡ºçš„æ•°æ®ä¹Ÿå½•å…¥äº†æ•°ç»„ã€‚\n",
        "0-otherï¼› 1-mammal 2-bird\n",
        "#ç„¶åå†è½¬æ¢æˆå¼ é‡\n",
        "'''\n",
        "\n",
        "'''\n",
        "è®°å½•æ•°æ®ç‰¹å¾ï¼Œå’Œè¾“å‡ºç±»çš„æ•°é‡;;;å°±æ˜¯èµ‹å€¼\n",
        "'''\n",
        "#è¿™ä¸ªéƒ¨åˆ†æ›´åƒæ˜¯å‡†å¤‡æ•°æ®\n",
        "#print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLCQB_crIObM"
      },
      "source": [
        "#perpare for data\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])  #åˆ›å»ºæ•°æ®one-hot\n",
        "\n",
        "x_data_torch = torch.from_numpy(x_data).float() #è½¬ç±»å‹å˜å¼ é‡ï¼Œç›®å‰è¿˜æ˜¯æ•´æ•°\n",
        "\n",
        "y_data = np.array([0,1,2,0,0,2]) #output\n",
        "y_data_torch = torch.from_numpy(y_data) #output torch\n",
        "\n",
        "num_features = 2 # 2ä¸ªç‰¹å¾--hair, feather\n",
        "num_classes = 3 # 3 è¾“å‡ºç±» other,mammal,bird"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiTa6k1yNCPq"
      },
      "source": [
        "**No hidden layer --- manual ğŸ¤š parameter update (weight + bias)** EG\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Z_fdTrTAGV"
      },
      "source": [
        "'''\n",
        "è°ƒåŒ…\n",
        "nn\n",
        "å’ŒçŸ©é˜µå‡†ç¡®ç‡åˆ†æ•°\n",
        "'''\n",
        "'''\n",
        "initialize weight + bias manuallyğŸ¤š + setup gredient\n",
        "torch.randn returns --->tensor (random fill with) (from normal distribution with mean 0 + vaianceæ–¹å·® 1)\n",
        "[standard normal distribution æ ‡å‡†æ­£æ€åˆ†å¸ƒ]\n",
        "  # åŠŸèƒ½ï¼šä»æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰ä¸­æŠ½å–çš„ä¸€ç»„éšæœºæ•°ã€‚è¿”å›ä¸€ä¸ªå¼ é‡\n",
        "sizes (intâ€¦) - æ•´æ•°åºåˆ—ï¼Œå®šä¹‰è¾“å‡ºå¼ é‡çš„å½¢çŠ¶\n",
        "out (Tensor, optinal) - ç»“æœå¼ é‡\n",
        "\n",
        "è¯¥æ–¹æ³•èƒ½å¤Ÿå†³å®šè‡ªåŠ¨æ¢¯åº¦æœºåˆ¶æ˜¯å¦éœ€è¦ä¸ºå½“å‰è¿™ä¸ªå¼ é‡è®¡ç®—è®°å½•è¿ç®—æ“ä½œ.\n",
        "è¯¥æ–¹æ³•èƒ½å¯¹å½“å‰å¼ é‡çš„requires_gradå±æ€§è¿›è¡ŒåŸåœ°æ“ä½œ.è¿”å›è¿™ä¸ªå½“å‰å¼ é‡.\n",
        "\n",
        "'''\n",
        "# Learning Rate - determines the step size at each iteration while moving toward a minimum of a loss function\n",
        "\n",
        "# Epoch - A measure of the number of times all of the training vectors are used once to update the weights.\n",
        "#æ–¹æ³•è®­ç»ƒå‘é‡çš„æ¬¡æ•°ã€‚ï¼ˆè®­ç»ƒå‘é‡æ¥æ¯æ¬¡æ›´æ–°æƒé‡ï¼‰\n",
        "#å°è¯•2000çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆ\n",
        "\n",
        "'''\n",
        "for å¾ªç¯å¼€å§‹æ­£å‘ä¼ æ’­ forward propagation   calculation+ storage of intermediate variables(incl. outputs)\n",
        "from input layer --> output layer \n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "softmax change each value--->(0,1) + all values  +  add up(sum) = 1\n",
        "eg:  [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]\n",
        "(lå” å‰²é”æ³½æ¯ log_softmax )\n",
        "\n",
        "#å•Šå“ˆï¼ç®—æ³•ï¼›\n",
        "#ç®—æ³•å›¾è§£\n",
        "å…ˆè¿›è¡Œsoftmax ç„¶åè¿›è¡Œlogarithm softmax å¯¹æ•°\n",
        "softmaxï¼š exp(x_i) / exp(x).sum() and log_softmax: log(exp(x_i)) /exp(x).sum() ) #åªæ˜¯åˆ†å­åšlog\n",
        "log(softmax(x)) ä½†æ˜¯å®é™…åšèµ·æ¥ is different + efficient\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax\n",
        "    def log_softmax(input: Tensor, dim: Optional[int]=None, _stacklevel: \n",
        "      int=3, dtype: Optional[int]=None) ->Tensor\n",
        "'''\n",
        "\n",
        "#ç„¶åæŸå¤± å¼€å§‹è¦å¯¹æ¯”æƒ…å†µäº†ã€‚è®¡ç®—æ¶ˆælog å¯èƒ½æŸå¤±;[è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±]\n",
        "'''\n",
        "torch.nn.functional.nll_loss(input, target, weight=None, \n",
        "size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
        "\n",
        "ä¸€èˆ¬åªèµ‹å€¼å‰ä¸¤ä¸ªå¼ é‡å°±å¯ä»¥äº†\n",
        "'''\n",
        "\n",
        "'''\n",
        "å¼€å§‹åå‘ä¼ æ’­ï¼šback propagation è¿›è¡Œè®¡ç®—æ¢¯åº¦ã€‚ ä¼˜åŒ–WB ä½¿ç”¨å­¦ä¹ ç‡ -å­¦ä¹ ç‡*W/B çš„æ¢¯åº¦æ•°æ®  ç„¶åå†æ¸…é›¶\n",
        "torch.no_grad()\n",
        "https://blog.csdn.net/weixin_46559271/article/details/105658654?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629843016780357253890%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161629843016780357253890&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-105658654.first_rank_v2_pc_rank_v29&utm_term=torch.no_grad\n",
        "å½“ä½ åšåå‘ä¼ æ’­æ—¶ï¼Œä¸è¦ç´¯ç§¯æ¢¯åº¦ã€‚\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "argmaxå‡½æ•°ï¼štorch.argmax(input, dim=None, keepdim=False)è¿”å›æŒ‡å®šç»´åº¦æœ€å¤§å€¼çš„åºå·ï¼Œdimç»™å®šçš„å®šä¹‰æ˜¯ï¼šthe demention to reduce.ä¹Ÿå°±æ˜¯æŠŠdimè¿™ä¸ªç»´åº¦çš„ï¼Œå˜æˆè¿™ä¸ªç»´åº¦çš„æœ€å¤§å€¼çš„indexã€‚\n",
        "\n",
        "https://blog.csdn.net/weixin_42494287/article/details/92797061?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161630304416780269870820%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161630304416780269870820&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-92797061.first_rank_v2_pc_rank_v29&utm_term=torch.argmaxåšä»€ä¹ˆç”¨çš„\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayovWGA6Nbau",
        "outputId": "01f7f8df-1f82-40e2-d186-bc764460a236"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "W1 = torch.randn(num_features, num_classes, requires_grad=True)#torch.randn(2,3)\n",
        "B1 = torch.randn(num_classes, requires_grad=True) #3\n",
        "\n",
        "learning_rate = 0.01 \n",
        "\n",
        "number_of_epochs = 2000\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "\n",
        "  z =torch.add(torch.matmul(x_data_torch, W1),B1) # è¾“å…¥ä¸¤ä¸ªå•è¯å¼ é‡ï¼Œå’Œweight å’Œbiasã€ forward propagationï¼›ã€å…¶å®æ„Ÿè§‰è¿˜æ˜¯åœ¨æ•´åˆæ•°æ®ã€‘\n",
        "  \n",
        "  log_softmax = F.log_softmax(z,dim=1)  #nn.functional.log_softmax   ã€softmax--logã€‘\n",
        "\n",
        "  loss = F.nll_loss(log_softmax, y_data_torch)  # input target  ----lossã€ä¸€ä¸ªå¯¹æ•°æ¦‚ç‡å‘é‡å’Œä¸€ä¸ªç›®æ ‡æ ‡ç­¾ã€‘\n",
        "\n",
        "  loss.backward() #calculate gradient\n",
        "  with torch.no_grad():   #è¿›å…¥with è°ƒç”¨torch.no_grad è¿”å›ä¸€ä¸ªgradå¯¹è±¡ torch.no_grad() æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè¢«è¯¥è¯­å¥ wrap èµ·æ¥çš„éƒ¨åˆ†å°†ä¸ä¼štrack æ¢¯åº¦ã€‚\n",
        "      W1.data -= learning_rate*W1.grad.data   #gradient descent\n",
        "      B1.data -= learning_rate*B1.grad.data\n",
        "  W1.grad.data.zero_() #reset gradient\n",
        "  B1.grad.data.zero_()\n",
        "\n",
        "  if epoch % 200 == 199:\n",
        "    with torch.no_grad():        #é¢„æµ‹ä¸éœ€è¦æ¢¯åº¦çš„\n",
        "        pred_outputs = torch.add(torch.matmul(x_data_torch ,W1),B1)  #é‡æ–°å¼€å§‹åšä¹˜æ³•ï¼Œå›åˆ°äº†æœ€å¼€å§‹çš„æ—¶å€™ã€‚\n",
        "        predicted = torch.argmax(pred_outputs, 1)  #ä¸æ˜¯.outputs æ˜¯â€”â€”\n",
        "        train_acc = accuracy_score(predicted.numpy(), y_data)\n",
        "        print('Epoch:%d, loss: %.4f, train_acc:%.3f' %(epoch + 1, loss.item() , train_acc))\n",
        "\n",
        "#result\n",
        "print('Predicted :', predicted.numpy())\n",
        "print('Truth :', y_data)\n",
        "print('Accuracy : %.2f' %train_acc)\n",
        "\n",
        "\n",
        "#è®­ç»ƒå‡†ç¡®åº¦åœ¨å¢åŠ ï¼ŒæŸå¤±åœ¨é™ä½\n",
        "'''\n",
        "\n",
        "Epoch:200, loss: 1.8851, train_acc:0.167\n",
        "Epoch:400, loss: 1.1088, train_acc:0.833\n",
        "Epoch:600, loss: 0.7822, train_acc:0.833\n",
        "Epoch:800, loss: 0.6057, train_acc:1.000\n",
        "Epoch:1000, loss: 0.4985, train_acc:1.000\n",
        "Epoch:1200, loss: 0.4256, train_acc:1.000\n",
        "Epoch:1400, loss: 0.3718, train_acc:1.000\n",
        "Epoch:1600, loss: 0.3302, train_acc:1.000\n",
        "Epoch:1800, loss: 0.2968, train_acc:1.000\n",
        "Epoch:2000, loss: 0.2694, train_acc:1.000\n",
        "Predicted : [0 1 2 0 0 2]\n",
        "Truth : [0 1 2 0 0 2]\n",
        "Accuracy : 1.00\n",
        "\n",
        "'''"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:200, loss: 1.8851, train_acc:0.167\n",
            "Epoch:400, loss: 1.1088, train_acc:0.833\n",
            "Epoch:600, loss: 0.7822, train_acc:0.833\n",
            "Epoch:800, loss: 0.6057, train_acc:1.000\n",
            "Epoch:1000, loss: 0.4985, train_acc:1.000\n",
            "Epoch:1200, loss: 0.4256, train_acc:1.000\n",
            "Epoch:1400, loss: 0.3718, train_acc:1.000\n",
            "Epoch:1600, loss: 0.3302, train_acc:1.000\n",
            "Epoch:1800, loss: 0.2968, train_acc:1.000\n",
            "Epoch:2000, loss: 0.2694, train_acc:1.000\n",
            "Predicted : [0 1 2 0 0 2]\n",
            "Truth : [0 1 2 0 0 2]\n",
            "Accuracy : 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ZOPrNbHzxw"
      },
      "source": [
        "#**TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj6P5yPpMnJy",
        "outputId": "08bd5ca2-aeea-46bc-978c-cb625cc9fef6"
      },
      "source": [
        "#16\n",
        "tain_acc = accuracy_score(predicted.numpy(), y_data)\n",
        "print(tain_acc)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXupZX1qMUbI",
        "outputId": "0c2b5ebc-6bbe-4a31-c05f-d55b0db134d8"
      },
      "source": [
        "#15\n",
        "predicted = torch.argmax(pred_outputs, 1)\n",
        "print(predicted)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 0, 0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945ciGNxMFu3",
        "outputId": "15c647f8-c707-4f0c-9f73-98945a94beda"
      },
      "source": [
        "#14\n",
        "print(pred_outputs)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3947,  0.6585,  0.5634],\n",
            "        [ 0.9237, -0.4688,  0.6831],\n",
            "        [-1.6573,  1.1094,  1.3526],\n",
            "        [ 1.3947,  0.6585,  0.5634],\n",
            "        [ 1.3947,  0.6585,  0.5634],\n",
            "        [-1.1862,  2.2367,  1.2329]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBVVQhb8JTZ1",
        "outputId": "5697a777-5d1d-4091-a040-24fa8adca807"
      },
      "source": [
        "#13\n",
        "B1.data -= learning_rate*B1.grad.data\n",
        "print(B1.data)\n",
        "#tensor([ 2.1613,  0.7510, -0.7514],  #tensor([ 34.8541,  -0.3064, -33.4468])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 34.8541,  -0.3064, -33.4468])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w55lxdsH-YB",
        "outputId": "8bf88958-d56d-44cb-8633-f057cbf35b2b"
      },
      "source": [
        "#12\n",
        "W1.data -= learning_rate*W1.grad.data\n",
        "print(W1.data)\n",
        "\n",
        "\n",
        "'''\n",
        "tensor([[ 0.9477,  1.5061, -0.7059],\n",
        "        [-0.3978, -0.5679, -0.0613]\n",
        "        tensor([[ 0.3480,  0.0354,  0.5222],\n",
        "        [ 2.0451, -0.0493,  1.2841]])\n",
        "        '''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3480,  0.0354,  0.5222],\n",
            "        [ 2.0451, -0.0493,  1.2841]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eKzzYiTH551",
        "outputId": "8bd9aae9-2c6f-4e2f-d15c-20da46054136"
      },
      "source": [
        "#11\n",
        "loss = F.nll_loss(log_softmax, y_data_torch)\n",
        "print(loss)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.6704, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6H5td2MERT_",
        "outputId": "0ffb0e72-e23b-4517-bf25-573798fbc8bb"
      },
      "source": [
        "#10\n",
        "log_softmax = F.log_softmax(z,dim=1)\n",
        "print(log_softmax)\n",
        "\n",
        "#https://blog.csdn.net/hao5335156/article/details/80607732?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629884116780265451148%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161629884116780265451148&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-80607732.first_rank_v2_pc_rank_v29&utm_term=F.log_softmax\n",
        "#åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œæ•°å€¼ä¸Šä¹Ÿæ›´ç¨³å®šã€‚\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2611, -1.6715, -3.1738],\n",
            "        [-0.2168, -1.9441, -2.9598],\n",
            "        [-0.0504, -3.8751, -3.5608],\n",
            "        [-0.2611, -1.6715, -3.1738],\n",
            "        [-0.2611, -1.6715, -3.1738],\n",
            "        [-0.0537, -3.5615, -3.7339]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRoUblpt41wH",
        "outputId": "bede2b65-930b-45cc-a09a-4bd97302a8ec"
      },
      "source": [
        "#9 torch.matmul å¯ä»¥è¾“å…¥é«˜ç»´çš„ï¼›äºŒç»´å°±æ˜¯å›¾é€šä¹˜æ³•\n",
        "#è¾“å…¥å¤šç»´å°±æ˜¯æŠŠæ‹–å‡ºæ¥çš„ä¸€ä½ä½œä¸ºbatch æå‡ºæ¥ã€‚å…¶ä»–éƒ¨åˆ†åšçŸ©é˜µä¹˜æ³•\n",
        "#å°†bçš„ç¬¬0ç»´ 5 broadcast æå‡ºæ¥ã€‚åä¸¤ç»´åšçŸ©é˜µä¹˜æ³•\n",
        "import pprint\n",
        "a = torch.ones(3,4)\n",
        "b = torch.ones(5,4,2)\n",
        "c = torch.matmul(a,b)\n",
        "print(c.shape)\n",
        "pprint.pprint(c)\n",
        "#https://blog.csdn.net/qsmx666/article/details/105783610?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161629814016780271553753%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161629814016780271553753&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-4-105783610.first_rank_v2_pc_rank_v29&utm_term=torch.matmulå‚æ•°æ€ä¹ˆç”¨\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 2])\n",
            "tensor([[[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]],\n",
            "\n",
            "        [[4., 4.],\n",
            "         [4., 4.],\n",
            "         [4., 4.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb4iwTMW29ED",
        "outputId": "993fee4a-6517-4744-fdc5-62e5f42e4c33"
      },
      "source": [
        "#8\n",
        "z =torch.add(torch.matmul(x_data_torch, W1),B1) #å‚æ•°ä¼ é€’åˆ° torch.add åè¿”å›è¾“å…¥å‚æ•°çš„æ±‚å’Œç»“æœä½œä¸ºè¾“å‡º\n",
        "#torch.matmul æ˜¯å¸¸ç”¨ä¹˜æ³•\n",
        "print(z)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.1613,  0.7510, -0.7514],\n",
            "        [ 2.5123,  0.7850, -0.2307],\n",
            "        [ 4.5605,  0.7358,  1.0501],\n",
            "        [ 2.1613,  0.7510, -0.7514],\n",
            "        [ 2.1613,  0.7510, -0.7514],\n",
            "        [ 4.2096,  0.7018,  0.5294]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EKSDj8g24hf",
        "outputId": "a4c30f12-dc20-4234-9740-eafce6d6e97d"
      },
      "source": [
        "#7\n",
        "B1 = torch.randn(num_classes, requires_grad=True)\n",
        "print(B1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 2.1613,  0.7510, -0.7514], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgLWHdZ-UGfW",
        "outputId": "5a04070d-0f6e-4b3d-dadc-9cab6c5f0e1e"
      },
      "source": [
        "W1 = torch.randn(num_features, num_classes, requires_grad=True)\n",
        "print(W1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9477,  1.5061, -0.7059],\n",
            "        [-0.3978, -0.5679, -0.0613]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95YTLYnWMyEJ",
        "outputId": "ed3a7bd3-a67d-4e71-e4e9-2e68eba7ec11"
      },
      "source": [
        "#5\n",
        "num_features = 2 # 2ä¸ªç‰¹å¾--hair, feather\n",
        "num_classes = 3 # 3 è¾“å‡ºç±» other,mammal,bird\n",
        "print(num_features,num_classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Rmcm2-LlBV",
        "outputId": "43508915-3370-4140-a8ef-612b2bd933b4"
      },
      "source": [
        "#4\n",
        "y_data_torch = torch.from_numpy(y_data)\n",
        "print(y_data_torch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 0, 0, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYI10BEFJ-jz",
        "outputId": "db621d25-ba54-4b4d-c745-c24096695b65"
      },
      "source": [
        "#3\n",
        "y_data = np.array([0,1,2,0,0,2])\n",
        "print(y_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 0 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P7lRrFIJLRA",
        "outputId": "88489beb-0a19-4602-b079-23846c4b9ad6"
      },
      "source": [
        "#2\n",
        "x_data_torch = torch.from_numpy(x_data)\n",
        "print(x_data_torch)\n",
        "x_data_torch = torch.from_numpy(x_data).float()\n",
        "print(x_data_torch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [1, 0],\n",
            "        [1, 1],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 1]])\n",
            "tensor([[0., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09hJb5nSH2di",
        "outputId": "e3fc01fc-1558-40de-92b2-59f3e90cd481"
      },
      "source": [
        "#1\n",
        "x_data = np.array(\n",
        "    [[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])\n",
        "print(x_data)#ç«–ç€å…¨æ‰“å‡ºæ¥äº† ä¹Ÿå°±æ˜¯ä¸€è¡Œä¸ºã€ã€‘ç„¶åæ•´ä¸ªã€ã€‘å†ï¼ˆï¼‰æ”¾åœ¨æ•°ç»„å½“ä¸­"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}