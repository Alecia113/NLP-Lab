{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMO5EXJe2IAM0hpcFTQrsI0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alecia113/NLP-Lab/blob/main/lab4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Os8_WS3mTJ"
      },
      "source": [
        "Recurrent Neural Networks + Sequence Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAuGdg_j4eJM"
      },
      "source": [
        "#recurrent （复发的 蕊·科·run3·忒） sequence （计数，序数） （C 困·嘶） neural（牛肉）\n",
        "#RNN ； seq2seq\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# you can GPU(cuda)/ just CPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxOSsoZA5WdZ"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "afnsAoF96a3g",
        "outputId": "bd4f2c52-c422-4c8a-e095-2576fa535bc7"
      },
      "source": [
        "'''\n",
        "RNN 是一类神经网络。其中节点之间的连接形成沿着时间序列的有向图。 \n",
        "时间手段跨时间分布。\n",
        "将它与分布在空间中的网络进行比较。这可让他表现出时间动态行为。\n",
        "RNN 源自前馈神经网络。\n",
        "可以使用其内部状态（内存）来处理可变长度的输入序列\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nRNN 是一类神经网络。其中节点之间的连接形成沿着时间序列的有向图。 \\n时间手段跨时间分布。\\n将它与分布在空间中的网络进行比较。这可让他表现出时间动态行为。\\nRNN 源自前馈神经网络。\\n可以使用其内部状态（内存）来处理可变长度的输入序列\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4LzEjeO7D8W"
      },
      "source": [
        "#**predict the last character of the word** 预测单词的最后一个字符"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b4h-xy_7Gkp"
      },
      "source": [
        "**eg：\"wor\"-->\"d\", \"dee\"-->\"p\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OFcMG5RCtfa"
      },
      "source": [
        "##有什么用呢？？？？？？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qprbwVge7nMJ",
        "outputId": "38d22aeb-4a82-4a7c-ab2c-b6d5d616c692"
      },
      "source": [
        "#这个模块的用意呢：输入单词。输入除了最后一个看，看能不能准确的匹配上最后一位\n",
        "\n",
        "'''\n",
        "1导包\n",
        "2导入文本库 tip：有，直接换行就好了  [字母表]\n",
        "encoding 编码 decoding解码  num_dic 让word 和index 对应起来\n",
        "看下长度26\n",
        "4这才开始导入文本。你想做测试的文本\n",
        "\n",
        "5写函数了，开始要做拆解了(批量处理)\n",
        "目的\n",
        "\n",
        "# Make a batch to have sequence data for input and ouput\n",
        "# wor -> X, d -> Y\n",
        "# dee -> X, p -> Y\n",
        "\n",
        "6开始循环，把除了最后一个【：-1】的字母的index都取出来\n",
        "            # input data is:\n",
        "        # wor       woo       dee     div      ...\n",
        "        # [22, 14, 17] [22, 14, 14] [3, 4, 4] [3, 8, 21] ...\n",
        "\n",
        "\n",
        "    再把最后一个单词取出来，把index 放到target里\n",
        "\n",
        "    #制作one-hot np.eye 批量制作。然后第一个是0.所以index+1的位置是1.代表了这个元素\n",
        "【将输入转为了一键编码】就不像之前我还得一个个编进去用*vec【0】\n",
        " # convert input to one-hot encoding.\n",
        "        # if input is [3, 4, 4]:\n",
        "        # [[ 0,  0,  0,  1,  0,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]]\n",
        "'''\n",
        "\n",
        "'''\n",
        "数据准备完开始设置hyerparameters\n",
        "'''\n",
        "\n",
        "'''\n",
        "然后准备dropout 是一个全连接层，开始丢弃神经元了\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n然后准备dropout 是一个全连接层，开始丢弃神经元了\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ6uumwH7kje"
      },
      "source": [
        "#这个过程的数据准备还是很像CBOW的\n",
        "\n",
        "import numpy as np\n",
        "char_arr = ['a','b','c','d','e',\n",
        "            'f','g','h','i','j',\n",
        "            'k','l','m','n','o',\n",
        "            'p','q','r','s','t',\n",
        "            'u','v','w','x','y','z']\n",
        "\n",
        "num_dic = {n:i for i,n in enumerate(char_arr)}  # {'a': 0, 'b': 1, 'c': 2, ..., 'j': 9, 'k', 10, ...}\n",
        "dic_len = len(num_dic)\n",
        "\n",
        "seq_data = ['word','wood','deep','dive','cold',\n",
        "            'cool','load','love','kiss','kind']\n",
        "\n",
        "def make_batch(seq_data):\n",
        "  input_batch = []\n",
        "  target_batch = []\n",
        "\n",
        "  for seq in seq_data:\n",
        "    input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\n",
        "    target = num_dic[seq[-1]]\n",
        "\n",
        "    input_batch.append(np.eye(dic_len)[input_data])\n",
        "\n",
        "    target_batch.append([target])  #就是输入的index ；target要加【】\n",
        "\n",
        "  return input_batch, target_batch\n",
        "\n",
        "#这个过程的数据准备还是很像CBOW的\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70FqlUfSIyEg"
      },
      "source": [
        "# setting hyperparameters\n",
        "learning_rate = 0.01\n",
        "n_hidden = 64\n",
        "total_epoch = 50\n",
        "\n",
        "n_step = 3    #暂时的RNN序列长度 temporal length of sequences for RNN\n",
        "\n",
        "n_input = dic_len  #26 输入向量的维度（dimension of input vector)\n",
        "n_class = dic_len #类的数量 26 number of class\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYeLmYhpJyaJ"
      },
      "source": [
        "**dropout 让每个隐藏单元更强大； 并推动其自行创建有用的功能。不用依赖其他隐藏单元来纠正错误**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "zh-1aZB1Klci",
        "outputId": "1382914b-4fa8-4231-f575-41d7589b2755"
      },
      "source": [
        "#感觉像是从一个全连接开始丢神经元。（还是全连接）\n",
        "'''\n",
        "1调包\n",
        "建类别 调用nn模型开始建设RNN\n",
        "    讲解RNN中参数： \n",
        "          batch_first 默认（default）False ； 代表输入和输出张量的提供方式为（seq_len, batch_size, feature)\n",
        "          但是：我们需要True ：bec：我们要使用形状输入（batch_size, seq_len, feature)\n",
        "            设置 num_layer = 2 我们将两个RNN 层堆叠在一起形成一个堆叠的RNN。\n",
        "                              第一个RNN接收第一个RNN的输出，并计算最终结果。\n",
        "          应用dropout（=0.2） aim：防止过拟合； 可更改 ； 【注意】可以用在RNN的每一层除了最后一层\n",
        "          https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
        "          官方解读\n",
        "\n",
        "  forward function（函数）\n",
        "   nn.RNN 有两个output\n",
        "  1：形状张量（batch_size, seq_len, hidden_size)有点像True；包含每个时间步长t 的RNN的最后一层输出特征。\n",
        "  2： 形状张量（num_layers * num_directions, batch, hidden_size) :包含 t = seq_len 的隐藏状态的张量\n",
        "   我们只关心第一个输出\n",
        "    nn.RNN: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\n",
        "\n",
        "\n",
        "    我们仅仅要RNN输出功能中提取最后一个隐藏状态（from output features get(extract) last hidden state)\n",
        "    最后的隐藏状态将信息从RNN信元（cell）随时间流逝中移走\n",
        "    因此    基于最后一个隐藏状态的预测，不仅考虑当前时间'  步长的数据，还要考虑历史数据。（就是输出中包含很多类别的数据）\n",
        "    来源复杂\n",
        "\n",
        "输入然后得到的输出项（forward）\n",
        "\n",
        "  3:设置模型，到GPU\n",
        "  4: loss + optimizer\n",
        "\n",
        "二\n",
        "\n",
        "5模型建设完，开始准备输入数据\n",
        "#https://blog.csdn.net/u014687517/article/details/90770132?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698050316780265445973%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161698050316780265445973&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-90770132.first_rank_v2_pc_rank_v29&utm_term=.view的用途\n",
        "view 用法。\n",
        "view 很像是reshape\n",
        "a = torch.range(1, 25) #a是长度25的张量\n",
        "#改成了5*5：a = a.view(5, 5)\n",
        "或者：a = a.view(-1, 5)\n",
        "\n",
        "（感觉就是将数据类型转变成为了张量。再传参一波，没做什么其他的感觉）\n",
        "\n",
        "三\n",
        "开始训练了epoch\n",
        "然后经典三部 forward + backward + optimize\n",
        "  #神经网络中经常会有\n",
        "  作用:output 是通过神经网络最后一层softmax 函数作用之后的输出。\n",
        "  \n",
        "  例如：假设我们在分类问题中共有4类。 分别是0123； 假如output.data 第一行【1，000】（属于第一个类别的概率是1\n",
        "  不加_, :输出则是1， （其中1是tensor） 加了之后输出变成0\n",
        "\n",
        "  下划线+'，'的作用是：使预测返回的output.data行中最大数值所在位置代表的类别。\n",
        "  _,predicted=torch.max(output.data,dim=1)\n",
        "\n",
        "  【另】\n",
        "    torch.max()返回两个值，一个是具体的value ；用下划线表示。第二个值是 value对应的index（predicted）\n",
        "    下划线_ 表示的就是具体的value，也就是输出的最大值（可用其他名词代替下划线）\n",
        "    数字1其实可以写为dim=1，这里简写为1\n",
        "    dim = 1 输出行的最大值。 dim = 0 输出列的最大值\n",
        "    #https://blog.csdn.net/weixin_48249563/article/details/111387501?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=1328740.37292.16169815268198889&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\n",
        "\n",
        "\n",
        "结论是损失和 训练准确度\n",
        "\n",
        "四：\n",
        "预测\n",
        "设置flag 去计算模型； 会 turn off ：dropout \n",
        "将标志设置为评估模式，这将dropout退出。\n",
        "\n",
        "训练完train_datasets之后，model要来测试样本了。在model(test_datasets)之前，需要加上model.eval(). 否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有batch normalization层所带来的的性质。\n",
        "在做one classification的时候，训练集和测试集的样本分布是不一样的，尤其需要注意这一点。\n",
        "\n",
        "[训练完数据要训练样本；为了让训练集和测试集的样本分开]（感觉更像是实现全连接的需要的感觉）\n",
        "#https://blog.csdn.net/qq_38410428/article/details/101102075?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698276116780271557000%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161698276116780271557000&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-101102075.first_rank_v2_pc_rank_v29&utm_term=model.eval\n",
        "\n",
        "先把预测值取出来。\n",
        "然后循环起来\n",
        "\n",
        "pytorch中GPU与CPU的相互转化\n",
        "\n",
        "深度学习中我们默认使用的是CPU，如果我们要使用GPU，需要使用.cuda将计算或者数据从CPU移动至GPU，\n",
        "\n",
        "如果当我们需要在CPU上进行运算时，比如使用plt可视化绘图, 我们可以使用.cpu将计算或者数据转移至CPU.\n",
        "\n",
        "然后开始拼接单词。\n",
        "看拼出来的单词对不对\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n1调包\\n建类别 调用nn模型开始建设RNN\\n    讲解RNN中参数： \\n          batch_first 默认（default）False ； 代表输入和输出张量的提供方式为（seq_len, batch_size, feature)\\n          但是：我们需要True ：bec：我们要使用形状输入（batch_size, seq_len, feature)\\n            设置 num_layer = 2 我们将两个RNN 层堆叠在一起形成一个堆叠的RNN。\\n                              第一个RNN接收第一个RNN的输出，并计算最终结果。\\n          应用dropout（=0.2） aim：防止过拟合； 可更改 ； 【注意】可以用在RNN的每一层除了最后一层\\n          https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\\n          官方解读\\n\\n  forward function（函数）\\n   nn.RNN 有两个output\\n  1：形状张量（batch_size, seq_len, hidden_size)有点像True；包含每个时间步长t 的RNN的最后一层输出特征。\\n  2： 形状张量（num_layers * num_directions, batch, hidden_size) :包含 t = seq_len 的隐藏状态的张量\\n   我们只关心第一个输出\\n    nn.RNN: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\\n\\n\\n    我们仅仅要RNN输出功能中提取最后一个隐藏状态（from output features get(extract) last hidden state)\\n    最后的隐藏状态将信息从RNN信元（cell）随时间流逝中移走\\n    因此    基于最后一个隐藏状态的预测，不仅考虑当前时间'  步长的数据，还要考虑历史数据。（就是输出中包含很多类别的数据）\\n    来源复杂\\n\\n输入然后得到的输出项（forward）\\n\\n  3:设置模型，到GPU\\n  4: loss + optimizer\\n\\n二\\n\\n5模型建设完，开始准备输入数据\\n#https://blog.csdn.net/u014687517/article/details/90770132?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698050316780265445973%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161698050316780265445973&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-90770132.first_rank_v2_pc_rank_v29&utm_term=.view的用途\\nview 用法。\\nview 很像是reshape\\na = torch.range(1, 25) #a是长度25的张量\\n#改成了5*5：a = a.view(5, 5)\\n或者：a = a.view(-1, 5)\\n\\n（感觉就是将数据类型转变成为了张量。再传参一波，没做什么其他的感觉）\\n\\n三\\n开始训练了epoch\\n然后经典三部 forward + backward + optimize\\n  #神经网络中经常会有\\n  作用:output 是通过神经网络最后一层softmax 函数作用之后的输出。\\n  \\n  例如：假设我们在分类问题中共有4类。 分别是0123； 假如output.data 第一行【1，000】（属于第一个类别的概率是1\\n  不加_, :输出则是1， （其中1是tensor） 加了之后输出变成0\\n\\n  下划线+'，'的作用是：使预测返回的output.data行中最大数值所在位置代表的类别。\\n  _,predicted=torch.max(output.data,dim=1)\\n\\n  【另】\\n    torch.max()返回两个值，一个是具体的value ；用下划线表示。第二个值是 value对应的index（predicted）\\n    下划线_ 表示的就是具体的value，也就是输出的最大值（可用其他名词代替下划线）\\n    数字1其实可以写为dim=1，这里简写为1\\n    dim = 1 输出行的最大值。 dim = 0 输出列的最大值\\n    #https://blog.csdn.net/weixin_48249563/article/details/111387501?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=1328740.37292.16169815268198889&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\\n\\n\\n结论是损失和 训练准确度\\n\\n四：\\n预测\\n设置flag 去计算模型； 会 turn off ：dropout \\n将标志设置为评估模式，这将dropout退出。\\n\\n训练完train_datasets之后，model要来测试样本了。在model(test_datasets)之前，需要加上model.eval(). 否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有batch normalization层所带来的的性质。\\n在做one classification的时候，训练集和测试集的样本分布是不一样的，尤其需要注意这一点。\\n\\n[训练完数据要训练样本；为了让训练集和测试集的样本分开]（感觉更像是实现全连接的需要的感觉）\\n#https://blog.csdn.net/qq_38410428/article/details/101102075?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698276116780271557000%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161698276116780271557000&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-101102075.first_rank_v2_pc_rank_v29&utm_term=model.eval\\n\\n先把预测值取出来。\\n然后循环起来\\n\\npytorch中GPU与CPU的相互转化\\n\\n深度学习中我们默认使用的是CPU，如果我们要使用GPU，需要使用.cuda将计算或者数据从CPU移动至GPU，\\n\\n如果当我们需要在CPU上进行运算时，比如使用plt可视化绘图, 我们可以使用.cpu将计算或者数据转移至CPU.\\n\\n然后开始拼接单词。\\n看拼出来的单词对不对\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyuJ9JTqKygW"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyq3VaAGK1ET",
        "outputId": "c28a4d2b-7bf7-408b-bd0a-d377ff4e84ea"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "#感觉固定住了\n",
        "\n",
        "class RNN_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RNN_Model, self).__init__()\n",
        "    self.rnn = nn.RNN(n_input, n_hidden, num_layers=2, batch_first=True, dropout=0.2)\n",
        "    self.linear = nn.Linear(n_hidden, n_class) #output的线性层\n",
        "\n",
        "  def forward(self, x):\n",
        "    rnn_output, h_n = self.rnn(x)\n",
        "    x_last = rnn_output[:,-1,:]\n",
        "    x = self.linear(x_last)\n",
        "    return x\n",
        "\n",
        "model = RNN_Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = optim.Adam(model.parameters(), lr= learning_rate)\n",
        "#模型建立好了\n",
        "#然后准备输入\n",
        "input_batch, target_batch = make_batch(seq_data)\n",
        "input_batch_torch = torch.from_numpy(np.array(input_batch)).float().to(device)  #把一个单词前三的字母的one-hot 张量形式放到一个list里面\n",
        "target_batch_torch = torch.from_numpy(np.array(target_batch)).view(-1).to(device) #把每个单元都整合成了长单元\n",
        "# to(device) 将输入转换为张量，并将其设置成为GPU \n",
        "# 参数-1 含义：自行计算行数或列数 \n",
        "\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "  model.train()  #将标志设置为训练模式；\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(input_batch_torch)    #output训练\n",
        "  loss = criterion(outputs, target_batch_torch)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  _, predicted = torch.max(outputs,1) #这个_代表的是什么\n",
        "\n",
        "  acc = accuracy_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy()) #50个数据 epoch\n",
        "  print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch+1, loss.item(),acc))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "##Prediction\n",
        "model.eval()\n",
        "outputs = model(input_batch_torch)\n",
        "_, predicted = torch.max(outputs, 1)    # same as predicted = torch.argmax(pred_outputs, 1)\n",
        "\n",
        "predict_words = []\n",
        "for i in range(len(predicted.cpu().numpy())):\n",
        "  ind = predicted.cpu().numpy()[i] #这步骤是让他变回数组而不是张量然后分别取出预测的每个值' index\n",
        "  predict_words.append(seq_data[i][:-1]+char_arr[ind])  #他是去你除了最后一位的单词组合，然后将你预测的index放到对应的字母表中。从字母表中找到真实值。再将两个拼接\n",
        "  print(predict_words)\n",
        "\n",
        "print('\\n=== Prediction Result ===')\n",
        "print('Input:', [w[:3] + ' ' for w in seq_data])\n",
        "print('Predicted:', predict_words)\n",
        "print('Accuracy: %.2f' %acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 3.25724, train_acc: 0.00\n",
            "Epoch: 2, loss: 2.71709, train_acc: 0.50\n",
            "Epoch: 3, loss: 2.08581, train_acc: 0.50\n",
            "Epoch: 4, loss: 1.61668, train_acc: 0.50\n",
            "Epoch: 5, loss: 1.41686, train_acc: 0.50\n",
            "Epoch: 6, loss: 1.33283, train_acc: 0.50\n",
            "Epoch: 7, loss: 1.33529, train_acc: 0.50\n",
            "Epoch: 8, loss: 1.27455, train_acc: 0.60\n",
            "Epoch: 9, loss: 1.20393, train_acc: 0.60\n",
            "Epoch: 10, loss: 1.12294, train_acc: 0.50\n",
            "Epoch: 11, loss: 1.05021, train_acc: 0.60\n",
            "Epoch: 12, loss: 0.95618, train_acc: 0.70\n",
            "Epoch: 13, loss: 0.88508, train_acc: 0.80\n",
            "Epoch: 14, loss: 0.83438, train_acc: 0.80\n",
            "Epoch: 15, loss: 0.74400, train_acc: 0.70\n",
            "Epoch: 16, loss: 0.64337, train_acc: 0.80\n",
            "Epoch: 17, loss: 0.64427, train_acc: 0.80\n",
            "Epoch: 18, loss: 0.55463, train_acc: 0.80\n",
            "Epoch: 19, loss: 0.45344, train_acc: 0.90\n",
            "Epoch: 20, loss: 0.42318, train_acc: 0.90\n",
            "Epoch: 21, loss: 0.35303, train_acc: 0.90\n",
            "Epoch: 22, loss: 0.32012, train_acc: 0.90\n",
            "Epoch: 23, loss: 0.26987, train_acc: 0.80\n",
            "Epoch: 24, loss: 0.22863, train_acc: 0.90\n",
            "Epoch: 25, loss: 0.21186, train_acc: 1.00\n",
            "Epoch: 26, loss: 0.16598, train_acc: 1.00\n",
            "Epoch: 27, loss: 0.16142, train_acc: 1.00\n",
            "Epoch: 28, loss: 0.15020, train_acc: 1.00\n",
            "Epoch: 29, loss: 0.16007, train_acc: 1.00\n",
            "Epoch: 30, loss: 0.11434, train_acc: 1.00\n",
            "Epoch: 31, loss: 0.09836, train_acc: 1.00\n",
            "Epoch: 32, loss: 0.11447, train_acc: 1.00\n",
            "Epoch: 33, loss: 0.06179, train_acc: 1.00\n",
            "Epoch: 34, loss: 0.04500, train_acc: 1.00\n",
            "Epoch: 35, loss: 0.07634, train_acc: 1.00\n",
            "Epoch: 36, loss: 0.02949, train_acc: 1.00\n",
            "Epoch: 37, loss: 0.07471, train_acc: 1.00\n",
            "Epoch: 38, loss: 0.03746, train_acc: 1.00\n",
            "Epoch: 39, loss: 0.04838, train_acc: 1.00\n",
            "Epoch: 40, loss: 0.02428, train_acc: 1.00\n",
            "Epoch: 41, loss: 0.01659, train_acc: 1.00\n",
            "Epoch: 42, loss: 0.01046, train_acc: 1.00\n",
            "Epoch: 43, loss: 0.00863, train_acc: 1.00\n",
            "Epoch: 44, loss: 0.00733, train_acc: 1.00\n",
            "Epoch: 45, loss: 0.00970, train_acc: 1.00\n",
            "Epoch: 46, loss: 0.01493, train_acc: 1.00\n",
            "Epoch: 47, loss: 0.00779, train_acc: 1.00\n",
            "Epoch: 48, loss: 0.00643, train_acc: 1.00\n",
            "Epoch: 49, loss: 0.00654, train_acc: 1.00\n",
            "Epoch: 50, loss: 0.01066, train_acc: 1.00\n",
            "Finished Training\n",
            "['word']\n",
            "['word', 'wood']\n",
            "['word', 'wood', 'deep']\n",
            "['word', 'wood', 'deep', 'dive']\n",
            "['word', 'wood', 'deep', 'dive', 'cold']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
            "\n",
            "=== Prediction Result ===\n",
            "Input: ['wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n",
            "Predicted: ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
            "Accuracy: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97H71hv5K4Lj"
      },
      "source": [
        "#**Seq2Seq Model(N to M)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "MyY9ABm600ZK",
        "outputId": "2bb8bea1-be00-4f1d-cc58-acba428899cf"
      },
      "source": [
        "'''\n",
        "将一个序列转换为另一个序列。用RNN或者常用LSTM 或者GRU去避免梯度消失的问题。每个项目的上下文是上一步的输出。主要组件是一个编码器和一个解码器网络。\n",
        "编码器将每个项目转换为包含该项目及其上下文的隐藏向量。\n",
        "解码器使用先前的输出作为上下文来逆转该过程。将向量转换为输出项\n",
        "'''"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n将一个序列转换为另一个序列。用RNN或者常用LSTM 或者GRU去避免梯度消失的问题。每个项目的上下文是上一步的输出。主要组件是一个编码器和一个解码器网络。\\n编码器将每个项目转换为包含该项目及其上下文的隐藏向量。\\n解码器使用先前的输出作为上下文来逆转该过程。将向量转换为输出项\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYHs3bzrblSZ"
      },
      "source": [
        "**要开始一个新的项目了，该模型将纸牌符号（Ace，Jack，Queen，King） 转换为其相关编号**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oQrvVGVIb6Ps",
        "outputId": "ce1b991a-97ee-487a-90f0-3cf2443c93c6"
      },
      "source": [
        "'''\n",
        "其实就两个模型一个是RNN，一个是Seq2Seq\n",
        "1：处理数据。\n",
        "2分批次\n",
        "3模型\n",
        "4评估\n",
        "\n",
        "这个任务是\"ace\" 转变到\"01\" 将\"jack\"转变到\"11\"  【要求】老师\n",
        "'''"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n其实就两个模型一个是RNN，一个是Seq2Seq\\n1：处理数据。\\n2分批次\\n3模型\\n4评估\\n\\n这个任务是\"ace\" 转变到\"01\" 将\"jack\"转变到\"11\"  【要求】老师\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJdN7qsdcWxs"
      },
      "source": [
        "**Preprocess data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "9V96X1H6cekP",
        "outputId": "f25701d7-0749-440d-abf3-c469632f0aa7"
      },
      "source": [
        "'''\n",
        "1调包\n",
        "2 序列数据 sequence data\n",
        "3 chars 字符  生成唯一的符号列表     tokens符号 \n",
        "  每一个都拆开 + 去掉重复项\n",
        "4 需要特殊的tokens \n",
        "    BEPU\n",
        "    要额外添加\n",
        "    B 序列开始\n",
        "    E 序列结束\n",
        "    P padding 填充（fill） 序列。 对于不同的输入大小\n",
        "    U 序列中不知道的元素。 对于不同的输入大小\n",
        "\n",
        "5 然后将字母和序号一一匹配上 ： n：i\n",
        "6 记录整个长度\n",
        "7 限定最大输入和输出的数量\n",
        "'''"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n1调包\\n2 序列数据 sequence data\\n3 chars 字符  生成唯一的符号列表     tokens符号 \\n  每一个都拆开 + 去掉重复项\\n4 需要特殊的tokens \\n    BEPU\\n    要额外添加\\n    B 序列开始\\n    E 序列结束\\n    P padding 填充（fill） 序列。 对于不同的输入大小\\n    U 序列中不知道的元素。 对于不同的输入大小\\n\\n5 然后将字母和序号一一匹配上 ： n：i\\n6 记录整个长度\\n7 限定最大输入和输出的数量\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51nQLK-cdH7"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pprint\n",
        "\n",
        "seq_data = [['ace', '01'],['jack','11'],\n",
        "            ['queen','12'],['king','13']]\n",
        "\n",
        "chars =[] \n",
        "for seq in seq_data:\n",
        "  chars += list(seq[0])\n",
        "  chars += list(seq[1])\n",
        "\n",
        "char_arr = list(set(chars)) #筛除重复的然后生成了列表 14\n",
        "\n",
        "char_arr.append('B')\n",
        "char_arr.append('E')\n",
        "char_arr.append('P')\n",
        "char_arr.append('U')    #18\n",
        "\n",
        "\n",
        "num_dic = {n:i for i,n in enumerate(char_arr)} #对应字母：index 因为有0所以17 enumerate 就是让字母和数字一一对应\n",
        "\n",
        "dic_len = len(num_dic)    #18\n",
        "\n",
        "max_input_words_amount = 5\n",
        "max_output_words_amount = 3"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rIDCWd1hTTg"
      },
      "source": [
        "**产生batch--generate batch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4p8wOeV57hB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "4c7fbdd8-8810-428f-f313-0048e2141106"
      },
      "source": [
        "'''\n",
        "1.padding (fill 补充) 添满如果单词比最长的单词要短\n",
        "2.产生一批数据，给训练和测试\n",
        "    创建空白列表；编码输入；解码输入； 目标批次\n",
        "    然后开始输入，将字典的中的word输入到input中\n",
        " 然后找到固定的每个单词对应的index列表 P就是16\n",
        "\n",
        "[5, 1, 0, 16, 16]\n",
        "[11, 5, 1, 4, 16]\n",
        "[8, 2, 0, 0, 3]\n",
        "[4, 7, 3, 6, 16]\n",
        "\n",
        "    左边的输入准备完了，然后要进入右边了，要先来个B  B + index\n",
        "[14, 13, 9]\n",
        "[14, 9, 9]\n",
        "[14, 9, 10]\n",
        "[14, 9, 12]\n",
        "\n",
        "    B将index也转换成列表了\n",
        "    但之后就取消了B，加了E 来让index1又转换成列表\n",
        "[13, 9, 15]\n",
        "[9, 9, 15]\n",
        "[9, 10, 15]\n",
        "[9, 12, 15]   \n",
        "  \n",
        "  所以右边是解码器；\n",
        "    解码器单元的输出（实际结果），在序列数据的末尾添加E\n",
        "    由于目标长度是固定的，但实际上我们  不需要在最后加E\n",
        "    但不确定的目标长度，E就很重要了。\n",
        "    因为在预测的过程中当涉及到E我们就要停\n",
        "\n",
        "   然后开始将准备好的编码和解码输入变成 one-hot (逃不掉的one-hot)\n",
        "\n",
        "3 这里输入的编码和解码（b） 都变成了one-hot存起来了\n",
        "只有target （e） 存的是index，并没有存one-hot\n",
        "'''\n",
        "\n",
        "#这里是把词表输入。然后呢处理他们，得到 解码编码-onehot ；和目标（可能就是真实）index"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n1.padding (fill 补充) 添满如果单词比最长的单词要短\\n2.产生一批数据，给训练和测试\\n    创建空白列表；编码输入；解码输入； 目标批次\\n    然后开始输入，将字典的中的word输入到input中\\n 然后找到固定的每个单词对应的index列表 P就是16\\n\\n[5, 1, 0, 16, 16]\\n[11, 5, 1, 4, 16]\\n[8, 2, 0, 0, 3]\\n[4, 7, 3, 6, 16]\\n\\n    左边的输入准备完了，然后要进入右边了，要先来个B  B + index\\n[14, 13, 9]\\n[14, 9, 9]\\n[14, 9, 10]\\n[14, 9, 12]\\n\\n    B将index也转换成列表了\\n    但之后就取消了B，加了E 来让index1又转换成列表\\n[13, 9, 15]\\n[9, 9, 15]\\n[9, 10, 15]\\n[9, 12, 15]   \\n  \\n  所以右边是解码器；\\n    解码器单元的输出（实际结果），在序列数据的末尾添加E\\n    由于目标长度是固定的，但实际上我们  不需要在最后加E\\n    但不确定的目标长度，E就很重要了。\\n    因为在预测的过程中当涉及到E我们就要停\\n\\n   然后开始将准备好的编码和解码输入变成 one-hot (逃不掉的one-hot)\\n\\n3 这里输入的编码和解码（b） 都变成了one-hot存起来了\\n只有target （e） 存的是index，并没有存one-hot\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O9LFDDUhYfM"
      },
      "source": [
        "def add_paddings(word, max_num=5):    #padding (fill 补充) 添满如果单词比最长的单词要短\n",
        "  diff = max_num -len(word)\n",
        "  return word + 'P'*diff    #用P补全  看起来要不补一个要不补两个P\n",
        "\n",
        "def make_batch(seq_data):   #产生一批数据，给训练和测试\n",
        "  encoder_input_batch = []\n",
        "  decoder_input_batch = []\n",
        "  target_batch = []\n",
        "\n",
        "  for seq in seq_data:\n",
        "    input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "    en_input_data = [num_dic[n] for n in input_word]          #[5, 1, 0, 16, 16]\n",
        "    \n",
        "    de_input_data = [num_dic[n] for n in ('B' + seq[1])]  #B：14， 13：0； 9：1 它是把idnex也变成了列表\n",
        "\n",
        "    target = [num_dic[n] for n in (seq[1] + 'E')]       #   13:0      E:15\n",
        "\n",
        "    encoder_input_batch.append(np.eye(dic_len)) #就是五位。让他们在对应位置表1；  5；8；4；7；17 （还是需要减一，是从0开始；所以单独输出的还是King「 \n",
        "                                                #让他们input的word变成one-hot\n",
        "    decoder_input_batch.append(np.eye(dic_len)[de_input_data])    #np.eye(总单词长度)【实际你想要的变得单词index】\n",
        "                                                #还是包含B的index\n",
        "    target_batch.append(target)                 #包含E的,他是直接将输出的index存起来了，没做one-hot\n",
        "\n",
        "\n",
        "  return encoder_input_batch, decoder_input_batch, target_batch"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ0vEq3wEz4G"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EW180dzE2LU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "1c79f885-f7bc-4bba-b002-cbec3822804c"
      },
      "source": [
        "#数据处理好了开始做模型了。\n",
        "'''\n",
        "1，导包\n",
        "2，开始键模型nn模型来了\n",
        "    有一层编码  RNN编码器\n",
        "    有一层dropout tf.nn.dropout是TensorFlow里面为了防止或减轻过拟合而使用的函数，它一般用在全连接层。\n",
        "      这里应该是pytorch的 dropout\n",
        "\n",
        "        tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None,name=None)\n",
        "        上面方法中常用的是前两个参数：\n",
        "        第一个参数x：指输入\n",
        "        第二个参数keep_prob: 设置神经元被选中的概率,在初始化时keep_prob是一个占位符, keep_prob = tf.placeholder(tf.float32) 。tensorflow在run时设置keep_prob具体的值，例如keep_prob: 0.5\n",
        "        第五个参数name：指定该操作的名字。\n",
        "      drop out 可以作为一个层，在RNN输出中，请见下面的forward\n",
        "      以前我们将其作为nn.RNN 的参数（dropout= 0.2）\n",
        "\n",
        "      RNN 解码器 就比编码器多了一层线性\n",
        "'''\n",
        "\n",
        "'''\n",
        "开始向前传播了。\n",
        "隐藏层，包含隐藏状态对于 t = seq_len\n",
        "应用 dropout 层在 输出的RNN上\n",
        "\n",
        "设置隐藏作为 rnn解码器的初始状态。【很重要】\n",
        "\n",
        "模型的原理有点混乱需要重新看KDB或者Caren的课程。\n",
        "\n",
        "\n",
        "\n",
        "# prediction_output_before_softmax = self.linear(decoder_output)  也就是我们只需要这部了，因为nn.CrossEntropyLoss 结合了 logsoftmax 和Nllloss\n",
        "# output_after_softmax = torch.log_softmax(prediction_output_before_softmax,dim=-1)\n",
        "# Since nn.CrossEntropyLoss combines LogSoftmax and NLLLoss for us, we only need the prediction_output_before_softmax\n",
        "\n",
        "        '''"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n开始向前传播了。\\n隐藏层，包含隐藏状态对于 t = seq_len\\n应用 dropout 层在 输出的RNN上\\n\\n设置隐藏作为 rnn解码器的初始状态。【很重要】\\n\\n模型的原理有点混乱需要重新看KDB或者Caren的课程。\\n\\n\\n\\n# prediction_output_before_softmax = self.linear(decoder_output)\\n# output_after_softmax = torch.log_softmax(prediction_output_before_softmax,dim=-1)\\n# Since nn.CrossEntropyLoss combines LogSoftmax and NLLLoss for us, we only need the prediction_output_before_softmax\\n\\n        '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB5-N76KE66K"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "class Seq2Seq_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Seq2Seq_Model, self).__init__()\n",
        "\n",
        "    self.rnn.encoder = nn.RNN(n_input, n_hidden, batch_first = True)    #RNN编码器 encoder\n",
        "    self.dropout_encoder = nn.Dropout(0.1)    #我认为应该是p = 0.1   # dropout 可以作为一个层\n",
        "    \n",
        "                                              #RNN decoder\n",
        "    self.rnn_decoder = nn.RNN(n_input, n_hidden, batch_first = True)\n",
        "    self.dropout_decoder = nn.Dropout(0.1)\n",
        "    self.linear = nn.Linear(n_hidden,n_class) #多了层线性\n",
        "\n",
        "  def forward(self, x_encoder, x_decoder):\n",
        "    _,hidden = self.rnn_encoder(x_encoder)\n",
        "    hidden = self.dropout_encoder(hidden)   #输出上用dropout层\n",
        "\n",
        "                                            #***** 设置隐藏作为 rnn解码器的初始状态。\n",
        "    decoder_output,_ = self.rnn_decoder(x_decoder,hidden)\n",
        "    decoder_output = self.dropout_decoder(decoder_output)      #输出上用dropout层 和上个hidden的功能描述一样\n",
        "\n",
        "    output = self.linear(decoder_output)\n",
        "\n",
        "    return output\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV1JzhXO8oMs"
      },
      "source": [
        "**Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DY23fK8D6hd",
        "outputId": "bc4bdec8-b677-4f5b-bfe4-bf90d4c2ce72"
      },
      "source": [
        "target_batch.append(target)\n",
        "target_batch"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 12, 15], [9, 12, 15], [9, 12, 15]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57KG4MQZD0fW",
        "outputId": "1ab4fb55-6696-448c-bde4-dd1a470abf42"
      },
      "source": [
        "#4.18\n",
        "target"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 12, 15]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlnjrhJFDV0y",
        "outputId": "27f92610-2f61-4bf8-c566-ac819705f2bf"
      },
      "source": [
        "dic_len"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWVrYDKCDSjJ",
        "outputId": "bc4872ec-455b-42bb-87fb-d8baeeb91cbb"
      },
      "source": [
        "np.eye(dic_len)[de_input_data]  #14, 9 ,12"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS3oRBgkCzXo",
        "outputId": "b389e693-ab48-4355-c783-cc9c50760d44"
      },
      "source": [
        "en_input_data"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 7, 3, 6, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFB6aOrJBiZ9",
        "outputId": "c33879cf-7b34-4d68-9171-0097ab01e282"
      },
      "source": [
        "#4.14\n",
        "np.eye(dic_len)[en_input_data] #kingP "
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_yYzT3zBej4",
        "outputId": "0ccc7a9d-3520-4ecf-cba0-fc00f226ce46"
      },
      "source": [
        "#4.13\n",
        "np.eye(dic_len)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCojHtInAS4e",
        "outputId": "cddc6d4a-73d1-4acc-abc4-d4e243d7b1a7"
      },
      "source": [
        "#4.12\n",
        "encoder_input_batch = []\n",
        "decoder_input_batch = []\n",
        "target_batch = []\n",
        "\n",
        "for seq in seq_data:\n",
        "  input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "  en_input_data = [num_dic[n] for n in input_word]          #[5, 1, 0, 16, 16]\n",
        "  \n",
        "  de_input_data = [num_dic[n] for n in ('B' + seq[1])]  #B：14， 13：0； 9：1 它是把idnex也变成了列表\n",
        "\n",
        "  target = [num_dic[n] for n in (seq[1] + 'E')]\n",
        "  print(target)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13, 9, 15]\n",
            "[9, 9, 15]\n",
            "[9, 10, 15]\n",
            "[9, 12, 15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kJjjJBv-2Fq",
        "outputId": "ae904c65-dd66-4222-a062-a6a7f82da88f"
      },
      "source": [
        "#4.11\n",
        "seq"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king', '13']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc9KZB40-vf4",
        "outputId": "3064f591-c482-4748-d0c6-43108c798f4a"
      },
      "source": [
        "#4.10\n",
        "encoder_input_batch = []\n",
        "decoder_input_batch = []\n",
        "target_batch = []\n",
        "\n",
        "for seq in seq_data:\n",
        "  input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "  en_input_data = [num_dic[n] for n in input_word]\n",
        "  de_input_data = [num_dic[n] for n in ('B' + seq[1])]\n",
        "  print(de_input_data)    "
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14, 13, 9]\n",
            "[14, 9, 9]\n",
            "[14, 9, 10]\n",
            "[14, 9, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA42PJis9NV1",
        "outputId": "a2ac1bc3-9b46-46e2-ef94-83bd0096fc23"
      },
      "source": [
        "#4.9\n",
        "encoder_input_batch = []\n",
        "decoder_input_batch = []\n",
        "target_batch = []\n",
        "\n",
        "for seq in seq_data:\n",
        "  input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "  en_input_data = [num_dic[n] for n in input_word]\n",
        "  print(en_input_data)    \n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 1, 0, 16, 16]\n",
            "[11, 5, 1, 4, 16]\n",
            "[8, 2, 0, 0, 3]\n",
            "[4, 7, 3, 6, 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tWQZcDww9CgF",
        "outputId": "00807c8f-6c1f-4045-d193-a994208391a7"
      },
      "source": [
        "#4.8 \n",
        "n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'U'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbkgFh6p88rj",
        "outputId": "5d5d57fb-f0a2-44d2-c932-4722e12804dd"
      },
      "source": [
        "#4.7\n",
        "len(num_dic)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlJ9tfWN82Uo",
        "outputId": "fdd0f3c5-98c7-415f-94cc-705d5e5e79ce"
      },
      "source": [
        "#4.6\n",
        "num_dic[n]"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHQ3J8Ja8xzV",
        "outputId": "706a1317-40ed-4b07-fb62-b79191dbfd81"
      },
      "source": [
        "#4.5\n",
        "num_dic"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 13,\n",
              " '1': 9,\n",
              " '2': 10,\n",
              " '3': 12,\n",
              " 'B': 14,\n",
              " 'E': 15,\n",
              " 'P': 16,\n",
              " 'U': 17,\n",
              " 'a': 5,\n",
              " 'c': 1,\n",
              " 'e': 0,\n",
              " 'g': 6,\n",
              " 'i': 7,\n",
              " 'j': 11,\n",
              " 'k': 4,\n",
              " 'n': 3,\n",
              " 'q': 8,\n",
              " 'u': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CHCcxFBp7Ldv",
        "outputId": "89ba4729-fa46-4aa3-9bbb-5b2386979c92"
      },
      "source": [
        "input_word = add_paddings(seq[0])\n",
        "input_word"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'kingP'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u4e3EnRP7CbF",
        "outputId": "c54ea177-4789-420b-ed56-5bce7d27a82a"
      },
      "source": [
        "seq[1]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'13'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GQm3jTGQ670-",
        "outputId": "a291fccf-a103-4e80-a865-57fd0155851f"
      },
      "source": [
        "#4.2\n",
        "seq[0]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'king'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RQhpk5F6Q_U",
        "outputId": "d01f2ca0-6042-4c3d-8455-bb3c42e1d5c4"
      },
      "source": [
        "#4.1\n",
        "seq_data"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ace', '01'], ['jack', '11'], ['queen', '12'], ['king', '13']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "079-aKEFeNNi",
        "outputId": "d86dd3e3-0c2e-4d11-a2a0-d265c925c3e2"
      },
      "source": [
        "#3.1\n",
        "chars += list(seq[0])\n",
        "'''\n",
        "['a', 'c', 'e']\n",
        "['a', 'c', 'e', 'j', 'a', 'c', 'k']\n",
        "['a', 'c', 'e', 'j', 'a', 'c', 'k', 'q', 'u', 'e', 'e', 'n']\n",
        "['a', 'c', 'e', 'j', 'a', 'c', 'k', 'q', 'u', 'e', 'e', 'n', 'k', 'i', 'n', 'g']\n",
        "'''\n",
        "chars += list(seq[1])\n",
        "'''\n",
        "['a', 'c', 'e', '0', '1']\n",
        "['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1']\n",
        "['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2']\n",
        "['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2', 'k', 'i', 'n', 'g', '1', '3']\n",
        "\n",
        "'''"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n['a', 'c', 'e', '0', '1']\\n['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1']\\n['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2']\\n['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2', 'k', 'i', 'n', 'g', '1', '3']\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KQD9RkMxGLS",
        "outputId": "9c494078-a379-45b3-e124-71103e624e8b"
      },
      "source": [
        "#2.17\n",
        "seq_data"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ace', '01'], ['jack', '11'], ['queen', '12'], ['king', '13']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K21ZQs_LwRgl",
        "outputId": "5416abf6-f5fb-47ed-a0cf-33f49008445a"
      },
      "source": [
        "#2.16\n",
        "char_arr"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e',\n",
              " 'c',\n",
              " 'u',\n",
              " 'n',\n",
              " 'k',\n",
              " 'a',\n",
              " 'g',\n",
              " 'i',\n",
              " 'q',\n",
              " '1',\n",
              " '2',\n",
              " 'j',\n",
              " '3',\n",
              " '0',\n",
              " 'B',\n",
              " 'E',\n",
              " 'P',\n",
              " 'U']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1R66YV-EwOrK",
        "outputId": "82221144-96db-4d7e-c672-6f740f42f30a"
      },
      "source": [
        "#2.15\n",
        "char_arr[ind]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "AMSVcVsrv8ja",
        "outputId": "f8ce8687-6924-48fd-8a79-1a8699acd4b7"
      },
      "source": [
        "#2.14\n",
        "'''\n",
        "['wor']\n",
        "['wor', 'woo']\n",
        "['wor', 'woo', 'dee']\n",
        "['wor', 'woo', 'dee', 'div']\n",
        "['wor', 'woo', 'dee', 'div', 'col']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis', 'kin']\n",
        "'''\n",
        "\n",
        "#seq_data[i][:-1]\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n['wor']\\n['wor', 'woo']\\n['wor', 'woo', 'dee']\\n['wor', 'woo', 'dee', 'div']\\n['wor', 'woo', 'dee', 'div', 'col']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis', 'kin']\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUOTXvqvj6O",
        "outputId": "e2ea14a5-242c-4cb6-9b50-95cd5f1608c6"
      },
      "source": [
        "#2.13\n",
        "ind"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6jg502ctIyy",
        "outputId": "e2569fe4-f7d6-4d62-d059-cfdc9ff7417c"
      },
      "source": [
        "#2.12\n",
        "predicted.cpu()[1]"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d605TlHwp12o",
        "outputId": "b0f0b011-062e-4728-bd43-5a87032f6f02"
      },
      "source": [
        "#2.11\n",
        "predicted.cpu().numpy()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhtZxWM7pxWL",
        "outputId": "8067988a-3a7d-4614-b276-bb07fdb4f032"
      },
      "source": [
        "#2.10\n",
        "predicted.cpu()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY-Ugp7lpt9l",
        "outputId": "57e414f9-4aab-4df5-f1ba-1949304b3c01"
      },
      "source": [
        "#2.9\n",
        "predicted"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki13GzewpjGJ",
        "outputId": "c8de211f-07c2-4797-f926-2099fb470278"
      },
      "source": [
        "#2.8\n",
        "target_batch_torch.cpu().numpy()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a8eC7wkpfGJ",
        "outputId": "47c01e0f-b70a-45d5-d142-98abe09eb46c"
      },
      "source": [
        "#2.7\n",
        "target_batch_torch"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3359uRUvpaGj",
        "outputId": "12d240ce-d0f7-4641-dbfe-91a3bbd5643f"
      },
      "source": [
        "#2.6\n",
        "print(target_batch_torch.cpu())#tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXrJ-ibplvKo"
      },
      "source": [
        "#2.5\n",
        "  #print(_)    #tensor([0.2457, 0.1858, 0.2913, 0.1972, 0.2256, 0.2471, 0.2616, 0.1699, 0.2519,\n",
        "              #0.2905], device='cuda:0', grad_fn=<MaxBackward0>)  [10]torch.Size([10]) 50+(不会是64吧）)\n",
        "  #print(len(_))\n",
        "  #print(predicted) #tensor([ 4,  4,  4,  4,  4,  4,  4,  4, 10,  4], device='cuda:0')\n",
        "  #print(predicted.shape) #torch.Size([10])"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvFumYJCkxkX",
        "outputId": "21fbabb8-df3f-48c6-d446-a0140d5731d7"
      },
      "source": [
        "#2.4\n",
        "target_batch_torch"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgIsRMPKkuPx",
        "outputId": "443b41d2-1fbc-479e-a4b4-da137218f002"
      },
      "source": [
        "#2.3\n",
        "target_batch"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6HWwjJpkr8S",
        "outputId": "38c8baf6-2793-417f-fb21-1701715d704a"
      },
      "source": [
        "#2.2\n",
        "model.train()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN_Model(\n",
              "  (rnn): RNN(26, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (linear): Linear(in_features=64, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPFvrCr3ZBCl",
        "outputId": "074ac24a-a3c4-4270-bbd7-602df53c977a"
      },
      "source": [
        "#2.1\n",
        "input_batch_torch"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "su5l0yYpIUQH",
        "outputId": "e84ca5d7-9ccb-4e13-843a-5967786a59f7"
      },
      "source": [
        "#1.9\n",
        "'''\n",
        "target_batch = []\n",
        "for seq in seq_data:\n",
        "  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\n",
        "  target = num_dic[seq[-1]]\n",
        "\n",
        "  input_batch.append(np.eye(dic_len)[input_data])\n",
        "\n",
        "  target_batch.append([target])\n",
        "  print(target_batch)\n",
        "'''"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntarget_batch = []\\nfor seq in seq_data:\\n  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\\n  target = num_dic[seq[-1]]\\n\\n  input_batch.append(np.eye(dic_len)[input_data])\\n\\n  target_batch.append([target])\\n  print(target_batch)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "8bk2KjCTC6f7",
        "outputId": "120d4abf-488c-4cd1-e3fd-29731aa00ac4"
      },
      "source": [
        "#1.8\n",
        "'''\n",
        "import pprint\n",
        "input_batch = []\n",
        "for seq in seq_data:\n",
        "  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\n",
        "\n",
        "  input_batch.append(np.eye(dic_len)[input_data]) #2-3【0】【0】 还是个list；还没有形状0 0\n",
        "  \n",
        "\n",
        "'''"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport pprint\\ninput_batch = []\\nfor seq in seq_data:\\n  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\\n\\n  input_batch.append(np.eye(dic_len)[input_data]) #2-3【0】【0】 还是个list；还没有形状0 0\\n  \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcnEvNLxD2_h"
      },
      "source": [
        "#np.eye(dic_len)[input_data] #制作one-hot np.eye 批量制作。然后第一个是0.所以index+1的位置是1.代表了这个元素"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eNXUkvDD9Xb"
      },
      "source": [
        "#input_data #kid"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d2YzxQJDnFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7dca48-8b41-4137-93a9-fc79f4db4676"
      },
      "source": [
        "np.eye(dic_len)#弄了个对角线1其他都是0\n"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "53CyT1-KB-Nl",
        "outputId": "cdff77d9-6da7-4879-ff3c-b94a455ef48e"
      },
      "source": [
        "#1.7\n",
        "'''\n",
        "for seq in seq_data:\n",
        "  target = num_dic[seq[-1]]\n",
        "  print(target)     #3 :d  \n",
        "  '''"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor seq in seq_data:\\n  target = num_dic[seq[-1]]\\n  print(target)     #3 :d  \\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "e5QsK7l4BQlm",
        "outputId": "42107073-1820-4482-beb2-5fc4d8809793"
      },
      "source": [
        "#1.6\n",
        "'''\n",
        "for seq in seq_data:\n",
        "    input_data = [num_dic[n] for n in seq[:-1]] #不取最后一个\n",
        "    print(input_data)\n",
        "    #w:22 o:14 r:17\n",
        "    '''"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor seq in seq_data:\\n    input_data = [num_dic[n] for n in seq[:-1]] #不取最后一个\\n    print(input_data)\\n    #w:22 o:14 r:17\\n    '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USwFA6d1AoTa",
        "outputId": "d1b289a2-d5cb-4aea-827e-4c90919d73af"
      },
      "source": [
        "#1.5\n",
        "seq_data\n",
        "len(seq_data)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt9G3Hjm_pEH",
        "outputId": "72a17da2-58ce-48aa-af84-335f9806607e"
      },
      "source": [
        "#1.4\n",
        "dic_len"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc1qGzRz_RIK",
        "outputId": "0ea7a08b-76c6-411c-acef-30be20e6e475"
      },
      "source": [
        "#1.3\n",
        "{n:i for i, n in enumerate(char_arr)} #   n: i == 'a': 0,单词： index 目前看起来只有字典可以这样"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 13,\n",
              " '1': 9,\n",
              " '2': 10,\n",
              " '3': 12,\n",
              " 'B': 14,\n",
              " 'E': 15,\n",
              " 'P': 16,\n",
              " 'U': 17,\n",
              " 'a': 5,\n",
              " 'c': 1,\n",
              " 'e': 0,\n",
              " 'g': 6,\n",
              " 'i': 7,\n",
              " 'j': 11,\n",
              " 'k': 4,\n",
              " 'n': 3,\n",
              " 'q': 8,\n",
              " 'u': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iGHoeOZ8w4C",
        "outputId": "1d44ea78-f137-40c5-a8d9-04a335e20391"
      },
      "source": [
        "#1.2\n",
        "for i,n in enumerate(char_arr):\n",
        "  #print(i,)    #index\n",
        "  #print(n)    #word\n",
        "  print(i,n)  #这样是一一对应（横向）"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 e\n",
            "1 c\n",
            "2 u\n",
            "3 n\n",
            "4 k\n",
            "5 a\n",
            "6 g\n",
            "7 i\n",
            "8 q\n",
            "9 1\n",
            "10 2\n",
            "11 j\n",
            "12 3\n",
            "13 0\n",
            "14 B\n",
            "15 E\n",
            "16 P\n",
            "17 U\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSKe8G808VK5",
        "outputId": "6d1a9b94-f0fa-477f-a027-67b4cf8c2d32"
      },
      "source": [
        "#1.1\n",
        "list(enumerate(char_arr))#这没什么变化啊\n"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'e'),\n",
              " (1, 'c'),\n",
              " (2, 'u'),\n",
              " (3, 'n'),\n",
              " (4, 'k'),\n",
              " (5, 'a'),\n",
              " (6, 'g'),\n",
              " (7, 'i'),\n",
              " (8, 'q'),\n",
              " (9, '1'),\n",
              " (10, '2'),\n",
              " (11, 'j'),\n",
              " (12, '3'),\n",
              " (13, '0'),\n",
              " (14, 'B'),\n",
              " (15, 'E'),\n",
              " (16, 'P'),\n",
              " (17, 'U')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4SsWe_Y8XOy"
      },
      "source": [
        ""
      ],
      "execution_count": 168,
      "outputs": []
    }
  ]
}