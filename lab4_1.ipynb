{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlm+eECcM+wWYIs4f35r+M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alecia113/NLP-Lab/blob/main/lab4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Os8_WS3mTJ"
      },
      "source": [
        "Recurrent Neural Networks + Sequence Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAuGdg_j4eJM"
      },
      "source": [
        "#recurrent （复发的 蕊·科·run3·忒） sequence （计数，序数） （C 困·嘶） neural（牛肉）\n",
        "#RNN ； seq2seq\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# you can GPU(cuda)/ just CPU"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxOSsoZA5WdZ"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "afnsAoF96a3g",
        "outputId": "bd4f2c52-c422-4c8a-e095-2576fa535bc7"
      },
      "source": [
        "'''\n",
        "RNN 是一类神经网络。其中节点之间的连接形成沿着时间序列的有向图。 \n",
        "时间手段跨时间分布。\n",
        "将它与分布在空间中的网络进行比较。这可让他表现出时间动态行为。\n",
        "RNN 源自前馈神经网络。\n",
        "可以使用其内部状态（内存）来处理可变长度的输入序列\n",
        "\n",
        "'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nRNN 是一类神经网络。其中节点之间的连接形成沿着时间序列的有向图。 \\n时间手段跨时间分布。\\n将它与分布在空间中的网络进行比较。这可让他表现出时间动态行为。\\nRNN 源自前馈神经网络。\\n可以使用其内部状态（内存）来处理可变长度的输入序列\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4LzEjeO7D8W"
      },
      "source": [
        "#**predict the last character of the word** 预测单词的最后一个字符"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b4h-xy_7Gkp"
      },
      "source": [
        "**eg：\"wor\"-->\"d\", \"dee\"-->\"p\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OFcMG5RCtfa"
      },
      "source": [
        "##有什么用呢？？？？？？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qprbwVge7nMJ",
        "outputId": "38d22aeb-4a82-4a7c-ab2c-b6d5d616c692"
      },
      "source": [
        "#这个模块的用意呢：输入单词。输入除了最后一个看，看能不能准确的匹配上最后一位\n",
        "\n",
        "'''\n",
        "1导包\n",
        "2导入文本库 tip：有，直接换行就好了  [字母表]\n",
        "encoding 编码 decoding解码  num_dic 让word 和index 对应起来\n",
        "看下长度26\n",
        "4这才开始导入文本。你想做测试的文本\n",
        "\n",
        "5写函数了，开始要做拆解了(批量处理)\n",
        "目的\n",
        "\n",
        "# Make a batch to have sequence data for input and ouput\n",
        "# wor -> X, d -> Y\n",
        "# dee -> X, p -> Y\n",
        "\n",
        "6开始循环，把除了最后一个【：-1】的字母的index都取出来\n",
        "            # input data is:\n",
        "        # wor       woo       dee     div      ...\n",
        "        # [22, 14, 17] [22, 14, 14] [3, 4, 4] [3, 8, 21] ...\n",
        "\n",
        "\n",
        "    再把最后一个单词取出来，把index 放到target里\n",
        "\n",
        "    #制作one-hot np.eye 批量制作。然后第一个是0.所以index+1的位置是1.代表了这个元素\n",
        "【将输入转为了一键编码】就不像之前我还得一个个编进去用*vec【0】\n",
        " # convert input to one-hot encoding.\n",
        "        # if input is [3, 4, 4]:\n",
        "        # [[ 0,  0,  0,  1,  0,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]]\n",
        "'''\n",
        "\n",
        "'''\n",
        "数据准备完开始设置hyerparameters\n",
        "'''\n",
        "\n",
        "'''\n",
        "然后准备dropout 是一个全连接层，开始丢弃神经元了\n",
        "'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n然后准备dropout 是一个全连接层，开始丢弃神经元了\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ6uumwH7kje"
      },
      "source": [
        "#这个过程的数据准备还是很像CBOW的\n",
        "\n",
        "import numpy as np\n",
        "char_arr = ['a','b','c','d','e',\n",
        "            'f','g','h','i','j',\n",
        "            'k','l','m','n','o',\n",
        "            'p','q','r','s','t',\n",
        "            'u','v','w','x','y','z']\n",
        "\n",
        "num_dic = {n:i for i,n in enumerate(char_arr)}  # {'a': 0, 'b': 1, 'c': 2, ..., 'j': 9, 'k', 10, ...}\n",
        "dic_len = len(num_dic)\n",
        "\n",
        "seq_data = ['word','wood','deep','dive','cold',\n",
        "            'cool','load','love','kiss','kind']\n",
        "\n",
        "def make_batch(seq_data):\n",
        "  input_batch = []\n",
        "  target_batch = []\n",
        "\n",
        "  for seq in seq_data:\n",
        "    input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\n",
        "    target = num_dic[seq[-1]]\n",
        "\n",
        "    input_batch.append(np.eye(dic_len)[input_data])\n",
        "\n",
        "    target_batch.append([target])  #就是输入的index ；target要加【】\n",
        "\n",
        "  return input_batch, target_batch\n",
        "\n",
        "#这个过程的数据准备还是很像CBOW的\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70FqlUfSIyEg"
      },
      "source": [
        "# setting hyperparameters\n",
        "learning_rate = 0.01\n",
        "n_hidden = 64\n",
        "total_epoch = 50\n",
        "\n",
        "n_step = 3    #暂时的RNN序列长度 temporal length of sequences for RNN\n",
        "\n",
        "n_input = dic_len  #26 输入向量的维度（dimension of input vector)\n",
        "n_class = dic_len #类的数量 26 number of class\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYeLmYhpJyaJ"
      },
      "source": [
        "**dropout 让每个隐藏单元更强大； 并推动其自行创建有用的功能。不用依赖其他隐藏单元来纠正错误**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "zh-1aZB1Klci",
        "outputId": "1382914b-4fa8-4231-f575-41d7589b2755"
      },
      "source": [
        "#感觉像是从一个全连接开始丢神经元。（还是全连接）\n",
        "'''\n",
        "1调包\n",
        "建类别 调用nn模型开始建设RNN\n",
        "    讲解RNN中参数： \n",
        "          batch_first 默认（default）False ； 代表输入和输出张量的提供方式为（seq_len, batch_size, feature)\n",
        "          但是：我们需要True ：bec：我们要使用形状输入（batch_size, seq_len, feature)\n",
        "            设置 num_layer = 2 我们将两个RNN 层堆叠在一起形成一个堆叠的RNN。\n",
        "                              第一个RNN接收第一个RNN的输出，并计算最终结果。\n",
        "          应用dropout（=0.2） aim：防止过拟合； 可更改 ； 【注意】可以用在RNN的每一层除了最后一层\n",
        "          https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
        "          官方解读\n",
        "\n",
        "  forward function（函数）\n",
        "   nn.RNN 有两个output\n",
        "  1：形状张量（batch_size, seq_len, hidden_size)有点像True；包含每个时间步长t 的RNN的最后一层输出特征。\n",
        "  2： 形状张量（num_layers * num_directions, batch, hidden_size) :包含 t = seq_len 的隐藏状态的张量\n",
        "   我们只关心第一个输出\n",
        "    nn.RNN: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\n",
        "\n",
        "\n",
        "    我们仅仅要RNN输出功能中提取最后一个隐藏状态（from output features get(extract) last hidden state)\n",
        "    最后的隐藏状态将信息从RNN信元（cell）随时间流逝中移走\n",
        "    因此    基于最后一个隐藏状态的预测，不仅考虑当前时间'  步长的数据，还要考虑历史数据。（就是输出中包含很多类别的数据）\n",
        "    来源复杂\n",
        "\n",
        "输入然后得到的输出项（forward）\n",
        "\n",
        "  3:设置模型，到GPU\n",
        "  4: loss + optimizer\n",
        "\n",
        "二\n",
        "\n",
        "5模型建设完，开始准备输入数据\n",
        "#https://blog.csdn.net/u014687517/article/details/90770132?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698050316780265445973%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161698050316780265445973&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-90770132.first_rank_v2_pc_rank_v29&utm_term=.view的用途\n",
        "view 用法。\n",
        "view 很像是reshape\n",
        "a = torch.range(1, 25) #a是长度25的张量\n",
        "#改成了5*5：a = a.view(5, 5)\n",
        "或者：a = a.view(-1, 5)\n",
        "\n",
        "（感觉就是将数据类型转变成为了张量。再传参一波，没做什么其他的感觉）\n",
        "\n",
        "三\n",
        "开始训练了epoch\n",
        "然后经典三部 forward + backward + optimize\n",
        "  #神经网络中经常会有\n",
        "  作用:output 是通过神经网络最后一层softmax 函数作用之后的输出。\n",
        "  \n",
        "  例如：假设我们在分类问题中共有4类。 分别是0123； 假如output.data 第一行【1，000】（属于第一个类别的概率是1\n",
        "  不加_, :输出则是1， （其中1是tensor） 加了之后输出变成0\n",
        "\n",
        "  下划线+'，'的作用是：使预测返回的output.data行中最大数值所在位置代表的类别。\n",
        "  _,predicted=torch.max(output.data,dim=1)\n",
        "\n",
        "  【另】\n",
        "    torch.max()返回两个值，一个是具体的value ；用下划线表示。第二个值是 value对应的index（predicted）\n",
        "    下划线_ 表示的就是具体的value，也就是输出的最大值（可用其他名词代替下划线）\n",
        "    数字1其实可以写为dim=1，这里简写为1\n",
        "    dim = 1 输出行的最大值。 dim = 0 输出列的最大值\n",
        "    #https://blog.csdn.net/weixin_48249563/article/details/111387501?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=1328740.37292.16169815268198889&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\n",
        "\n",
        "\n",
        "结论是损失和 训练准确度\n",
        "\n",
        "四：\n",
        "预测\n",
        "设置flag 去计算模型； 会 turn off ：dropout \n",
        "将标志设置为评估模式，这将dropout退出。\n",
        "\n",
        "训练完train_datasets之后，model要来测试样本了。在model(test_datasets)之前，需要加上model.eval(). 否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有batch normalization层所带来的的性质。\n",
        "在做one classification的时候，训练集和测试集的样本分布是不一样的，尤其需要注意这一点。\n",
        "\n",
        "[训练完数据要训练样本；为了让训练集和测试集的样本分开]（感觉更像是实现全连接的需要的感觉）\n",
        "#https://blog.csdn.net/qq_38410428/article/details/101102075?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698276116780271557000%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161698276116780271557000&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-101102075.first_rank_v2_pc_rank_v29&utm_term=model.eval\n",
        "\n",
        "先把预测值取出来。\n",
        "然后循环起来\n",
        "\n",
        "pytorch中GPU与CPU的相互转化\n",
        "\n",
        "深度学习中我们默认使用的是CPU，如果我们要使用GPU，需要使用.cuda将计算或者数据从CPU移动至GPU，\n",
        "\n",
        "如果当我们需要在CPU上进行运算时，比如使用plt可视化绘图, 我们可以使用.cpu将计算或者数据转移至CPU.\n",
        "\n",
        "然后开始拼接单词。\n",
        "看拼出来的单词对不对\n",
        "\n",
        "'''"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n1调包\\n建类别 调用nn模型开始建设RNN\\n    讲解RNN中参数： \\n          batch_first 默认（default）False ； 代表输入和输出张量的提供方式为（seq_len, batch_size, feature)\\n          但是：我们需要True ：bec：我们要使用形状输入（batch_size, seq_len, feature)\\n            设置 num_layer = 2 我们将两个RNN 层堆叠在一起形成一个堆叠的RNN。\\n                              第一个RNN接收第一个RNN的输出，并计算最终结果。\\n          应用dropout（=0.2） aim：防止过拟合； 可更改 ； 【注意】可以用在RNN的每一层除了最后一层\\n          https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\\n          官方解读\\n\\n  forward function（函数）\\n   nn.RNN 有两个output\\n  1：形状张量（batch_size, seq_len, hidden_size)有点像True；包含每个时间步长t 的RNN的最后一层输出特征。\\n  2： 形状张量（num_layers * num_directions, batch, hidden_size) :包含 t = seq_len 的隐藏状态的张量\\n   我们只关心第一个输出\\n    nn.RNN: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\\n\\n\\n    我们仅仅要RNN输出功能中提取最后一个隐藏状态（from output features get(extract) last hidden state)\\n    最后的隐藏状态将信息从RNN信元（cell）随时间流逝中移走\\n    因此    基于最后一个隐藏状态的预测，不仅考虑当前时间'  步长的数据，还要考虑历史数据。（就是输出中包含很多类别的数据）\\n    来源复杂\\n\\n输入然后得到的输出项（forward）\\n\\n  3:设置模型，到GPU\\n  4: loss + optimizer\\n\\n二\\n\\n5模型建设完，开始准备输入数据\\n#https://blog.csdn.net/u014687517/article/details/90770132?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698050316780265445973%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=161698050316780265445973&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-2-90770132.first_rank_v2_pc_rank_v29&utm_term=.view的用途\\nview 用法。\\nview 很像是reshape\\na = torch.range(1, 25) #a是长度25的张量\\n#改成了5*5：a = a.view(5, 5)\\n或者：a = a.view(-1, 5)\\n\\n（感觉就是将数据类型转变成为了张量。再传参一波，没做什么其他的感觉）\\n\\n三\\n开始训练了epoch\\n然后经典三部 forward + backward + optimize\\n  #神经网络中经常会有\\n  作用:output 是通过神经网络最后一层softmax 函数作用之后的输出。\\n  \\n  例如：假设我们在分类问题中共有4类。 分别是0123； 假如output.data 第一行【1，000】（属于第一个类别的概率是1\\n  不加_, :输出则是1， （其中1是tensor） 加了之后输出变成0\\n\\n  下划线+'，'的作用是：使预测返回的output.data行中最大数值所在位置代表的类别。\\n  _,predicted=torch.max(output.data,dim=1)\\n\\n  【另】\\n    torch.max()返回两个值，一个是具体的value ；用下划线表示。第二个值是 value对应的index（predicted）\\n    下划线_ 表示的就是具体的value，也就是输出的最大值（可用其他名词代替下划线）\\n    数字1其实可以写为dim=1，这里简写为1\\n    dim = 1 输出行的最大值。 dim = 0 输出列的最大值\\n    #https://blog.csdn.net/weixin_48249563/article/details/111387501?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=1328740.37292.16169815268198889&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\\n\\n\\n结论是损失和 训练准确度\\n\\n四：\\n预测\\n设置flag 去计算模型； 会 turn off ：dropout \\n将标志设置为评估模式，这将dropout退出。\\n\\n训练完train_datasets之后，model要来测试样本了。在model(test_datasets)之前，需要加上model.eval(). 否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有batch normalization层所带来的的性质。\\n在做one classification的时候，训练集和测试集的样本分布是不一样的，尤其需要注意这一点。\\n\\n[训练完数据要训练样本；为了让训练集和测试集的样本分开]（感觉更像是实现全连接的需要的感觉）\\n#https://blog.csdn.net/qq_38410428/article/details/101102075?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161698276116780271557000%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161698276116780271557000&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-101102075.first_rank_v2_pc_rank_v29&utm_term=model.eval\\n\\n先把预测值取出来。\\n然后循环起来\\n\\npytorch中GPU与CPU的相互转化\\n\\n深度学习中我们默认使用的是CPU，如果我们要使用GPU，需要使用.cuda将计算或者数据从CPU移动至GPU，\\n\\n如果当我们需要在CPU上进行运算时，比如使用plt可视化绘图, 我们可以使用.cpu将计算或者数据转移至CPU.\\n\\n然后开始拼接单词。\\n看拼出来的单词对不对\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyuJ9JTqKygW"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyq3VaAGK1ET",
        "outputId": "c28a4d2b-7bf7-408b-bd0a-d377ff4e84ea"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "#感觉固定住了\n",
        "\n",
        "class RNN_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RNN_Model, self).__init__()\n",
        "    self.rnn = nn.RNN(n_input, n_hidden, num_layers=2, batch_first=True, dropout=0.2)\n",
        "    self.linear = nn.Linear(n_hidden, n_class) #output的线性层\n",
        "\n",
        "  def forward(self, x):\n",
        "    rnn_output, h_n = self.rnn(x)\n",
        "    x_last = rnn_output[:,-1,:]\n",
        "    x = self.linear(x_last)\n",
        "    return x\n",
        "\n",
        "model = RNN_Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = optim.Adam(model.parameters(), lr= learning_rate)\n",
        "#模型建立好了\n",
        "#然后准备输入\n",
        "input_batch, target_batch = make_batch(seq_data)\n",
        "input_batch_torch = torch.from_numpy(np.array(input_batch)).float().to(device)  #把一个单词前三的字母的one-hot 张量形式放到一个list里面\n",
        "target_batch_torch = torch.from_numpy(np.array(target_batch)).view(-1).to(device) #把每个单元都整合成了长单元\n",
        "# to(device) 将输入转换为张量，并将其设置成为GPU \n",
        "# 参数-1 含义：自行计算行数或列数 \n",
        "\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "  model.train()  #将标志设置为训练模式；\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(input_batch_torch)    #output训练\n",
        "  loss = criterion(outputs, target_batch_torch)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  _, predicted = torch.max(outputs,1) #这个_代表的是什么\n",
        "\n",
        "  acc = accuracy_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy()) #50个数据 epoch\n",
        "  print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch+1, loss.item(),acc))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "##Prediction\n",
        "model.eval()\n",
        "outputs = model(input_batch_torch)\n",
        "_, predicted = torch.max(outputs, 1)    # same as predicted = torch.argmax(pred_outputs, 1)\n",
        "\n",
        "predict_words = []\n",
        "for i in range(len(predicted.cpu().numpy())):\n",
        "  ind = predicted.cpu().numpy()[i] #这步骤是让他变回数组而不是张量然后分别取出预测的每个值' index\n",
        "  predict_words.append(seq_data[i][:-1]+char_arr[ind])  #他是去你除了最后一位的单词组合，然后将你预测的index放到对应的字母表中。从字母表中找到真实值。再将两个拼接\n",
        "  print(predict_words)\n",
        "\n",
        "print('\\n=== Prediction Result ===')\n",
        "print('Input:', [w[:3] + ' ' for w in seq_data])\n",
        "print('Predicted:', predict_words)\n",
        "print('Accuracy: %.2f' %acc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 3.25724, train_acc: 0.00\n",
            "Epoch: 2, loss: 2.71709, train_acc: 0.50\n",
            "Epoch: 3, loss: 2.08581, train_acc: 0.50\n",
            "Epoch: 4, loss: 1.61668, train_acc: 0.50\n",
            "Epoch: 5, loss: 1.41686, train_acc: 0.50\n",
            "Epoch: 6, loss: 1.33283, train_acc: 0.50\n",
            "Epoch: 7, loss: 1.33529, train_acc: 0.50\n",
            "Epoch: 8, loss: 1.27455, train_acc: 0.60\n",
            "Epoch: 9, loss: 1.20393, train_acc: 0.60\n",
            "Epoch: 10, loss: 1.12294, train_acc: 0.50\n",
            "Epoch: 11, loss: 1.05021, train_acc: 0.60\n",
            "Epoch: 12, loss: 0.95618, train_acc: 0.70\n",
            "Epoch: 13, loss: 0.88508, train_acc: 0.80\n",
            "Epoch: 14, loss: 0.83438, train_acc: 0.80\n",
            "Epoch: 15, loss: 0.74400, train_acc: 0.70\n",
            "Epoch: 16, loss: 0.64337, train_acc: 0.80\n",
            "Epoch: 17, loss: 0.64427, train_acc: 0.80\n",
            "Epoch: 18, loss: 0.55463, train_acc: 0.80\n",
            "Epoch: 19, loss: 0.45344, train_acc: 0.90\n",
            "Epoch: 20, loss: 0.42318, train_acc: 0.90\n",
            "Epoch: 21, loss: 0.35303, train_acc: 0.90\n",
            "Epoch: 22, loss: 0.32012, train_acc: 0.90\n",
            "Epoch: 23, loss: 0.26987, train_acc: 0.80\n",
            "Epoch: 24, loss: 0.22863, train_acc: 0.90\n",
            "Epoch: 25, loss: 0.21186, train_acc: 1.00\n",
            "Epoch: 26, loss: 0.16598, train_acc: 1.00\n",
            "Epoch: 27, loss: 0.16142, train_acc: 1.00\n",
            "Epoch: 28, loss: 0.15020, train_acc: 1.00\n",
            "Epoch: 29, loss: 0.16007, train_acc: 1.00\n",
            "Epoch: 30, loss: 0.11434, train_acc: 1.00\n",
            "Epoch: 31, loss: 0.09836, train_acc: 1.00\n",
            "Epoch: 32, loss: 0.11447, train_acc: 1.00\n",
            "Epoch: 33, loss: 0.06179, train_acc: 1.00\n",
            "Epoch: 34, loss: 0.04500, train_acc: 1.00\n",
            "Epoch: 35, loss: 0.07634, train_acc: 1.00\n",
            "Epoch: 36, loss: 0.02949, train_acc: 1.00\n",
            "Epoch: 37, loss: 0.07471, train_acc: 1.00\n",
            "Epoch: 38, loss: 0.03746, train_acc: 1.00\n",
            "Epoch: 39, loss: 0.04838, train_acc: 1.00\n",
            "Epoch: 40, loss: 0.02428, train_acc: 1.00\n",
            "Epoch: 41, loss: 0.01659, train_acc: 1.00\n",
            "Epoch: 42, loss: 0.01046, train_acc: 1.00\n",
            "Epoch: 43, loss: 0.00863, train_acc: 1.00\n",
            "Epoch: 44, loss: 0.00733, train_acc: 1.00\n",
            "Epoch: 45, loss: 0.00970, train_acc: 1.00\n",
            "Epoch: 46, loss: 0.01493, train_acc: 1.00\n",
            "Epoch: 47, loss: 0.00779, train_acc: 1.00\n",
            "Epoch: 48, loss: 0.00643, train_acc: 1.00\n",
            "Epoch: 49, loss: 0.00654, train_acc: 1.00\n",
            "Epoch: 50, loss: 0.01066, train_acc: 1.00\n",
            "Finished Training\n",
            "['word']\n",
            "['word', 'wood']\n",
            "['word', 'wood', 'deep']\n",
            "['word', 'wood', 'deep', 'dive']\n",
            "['word', 'wood', 'deep', 'dive', 'cold']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss']\n",
            "['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
            "\n",
            "=== Prediction Result ===\n",
            "Input: ['wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n",
            "Predicted: ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
            "Accuracy: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97H71hv5K4Lj"
      },
      "source": [
        "#**Seq2Seq Model(N to M)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "MyY9ABm600ZK",
        "outputId": "5da1a280-39a6-4741-8adc-0898e2ef5442"
      },
      "source": [
        "'''\n",
        "将一个序列转换为另一个序列。用RNN或者常用LSTM 或者GRU去避免梯度消失的问题。每个项目的上下文是上一步的输出。主要组件是一个编码器和一个解码器网络。\n",
        "编码器将每个项目转换为包含该项目及其上下文的隐藏向量。\n",
        "解码器使用先前的输出作为上下文来逆转该过程。将向量转换为输出项\n",
        "'''"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n将一个序列转换为另一个序列。用RNN或者常用LSTM 或者GRU去避免梯度消失的问题。每个项目的上下文是上一步的输出。主要组件是一个编码器和一个解码器网络。\\n编码器将每个项目转换为包含该项目及其上下文的隐藏向量。\\n解码器使用先前的输出作为上下文来逆转该过程。将向量转换为输出项\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYHs3bzrblSZ"
      },
      "source": [
        "**要开始一个新的项目了，该模型将纸牌符号（Ace，Jack，Queen，King） 转换为其相关编号**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oQrvVGVIb6Ps",
        "outputId": "07ea9e93-355a-4a46-ff12-c0e01e1d1a44"
      },
      "source": [
        "'''\n",
        "其实就两个模型一个是RNN，一个是Seq2Seq\n",
        "1：处理数据。\n",
        "2分批次\n",
        "3模型\n",
        "4评估\n",
        "\n",
        "这个任务是\"ace\" 转变到\"01\" 将\"jack\"转变到\"11\"  【要求】老师\n",
        "'''"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n其实就两个模型一个是RNN，一个是Seq2Seq\\n1：处理数据。\\n2分批次\\n3模型\\n4评估\\n\\n这个任务是\"ace\" 转变到\"01\" 将\"jack\"转变到\"11\"  【要求】老师\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJdN7qsdcWxs"
      },
      "source": [
        "**Preprocess data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "9V96X1H6cekP",
        "outputId": "30ddb9de-55b5-4bc7-d325-5e5352587d0a"
      },
      "source": [
        "'''\n",
        "1调包\n",
        "2 序列数据 sequence data\n",
        "3 chars 字符  生成唯一的符号列表     tokens符号 \n",
        "  每一个都拆开 + 去掉重复项\n",
        "4 需要特殊的tokens \n",
        "    BEPU\n",
        "    要额外添加\n",
        "    B 序列开始\n",
        "    E 序列结束\n",
        "    P padding 填充（fill） 序列。 对于不同的输入大小\n",
        "    U 序列中不知道的元素。 对于不同的输入大小\n",
        "\n",
        "5 然后将字母和序号一一匹配上 ： n：i\n",
        "6 记录整个长度\n",
        "7 限定最大输入和输出的数量\n",
        "'''"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n1调包\\n2 序列数据 sequence data\\n3 chars 字符  生成唯一的符号列表     tokens符号 \\n  每一个都拆开 + 去掉重复项\\n4 需要特殊的tokens \\n    BEPU\\n    要额外添加\\n    B 序列开始\\n    E 序列结束\\n    P padding 填充（fill） 序列。 对于不同的输入大小\\n    U 序列中不知道的元素。 对于不同的输入大小\\n\\n5 然后将字母和序号一一匹配上 ： n：i\\n6 记录整个长度\\n7 限定最大输入和输出的数量\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51nQLK-cdH7"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pprint\n",
        "\n",
        "seq_data = [['ace', '01'],['jack','11'],\n",
        "            ['queen','12'],['king','13']]\n",
        "\n",
        "chars =[] \n",
        "for seq in seq_data:\n",
        "  chars += list(seq[0])\n",
        "  chars += list(seq[1])\n",
        "\n",
        "char_arr = list(set(chars)) #筛除重复的然后生成了列表 14\n",
        "\n",
        "char_arr.append('B')\n",
        "char_arr.append('E')\n",
        "char_arr.append('P')\n",
        "char_arr.append('U')    #18\n",
        "\n",
        "\n",
        "num_dic = {n:i for i,n in enumerate(char_arr)} #对应字母：index 因为有0所以17 enumerate 就是让字母和数字一一对应\n",
        "\n",
        "dic_len = len(num_dic)    #18\n",
        "\n",
        "max_input_words_amount = 5\n",
        "max_output_words_amount = 3"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rIDCWd1hTTg"
      },
      "source": [
        "**产生batch--generate batch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4p8wOeV57hB"
      },
      "source": [
        "'''\n",
        "1.padding (fill 补充) 添满如果单词比最长的单词要短\n",
        "2.产生一批数据，给训练和测试\n",
        "    创建空白列表；编码输入；解码输入； 目标批次\n",
        "    然后开始输入，将字典的中的word输入到input中\n",
        " 然后找到固定的每个单词对应的index列表 P就是16\n",
        "\n",
        "[5, 1, 0, 16, 16]\n",
        "[11, 5, 1, 4, 16]\n",
        "[8, 2, 0, 0, 3]\n",
        "[4, 7, 3, 6, 16]\n",
        "\n",
        "    左边的输入准备完了，然后要进入右边了，要先来个B  B + index\n",
        "[14, 13, 9]\n",
        "[14, 9, 9]\n",
        "[14, 9, 10]\n",
        "[14, 9, 12]\n",
        "\n",
        "    B将index也转换成列表了\n",
        "    但之后就取消了B，加了E 来让index1又转换成列表\n",
        "[13, 9, 15]\n",
        "[9, 9, 15]\n",
        "[9, 10, 15]\n",
        "[9, 12, 15]   \n",
        "  \n",
        "  所以右边是解码器；\n",
        "    解码器单元的输出（实际结果），在序列数据的末尾添加E\n",
        "    由于目标长度是固定的，但实际上我们  不需要在最后加E\n",
        "    但不确定的目标长度，E就很重要了。\n",
        "    因为在预测的过程中当涉及到E我们就要停\n",
        "\n",
        "   然后开始将准备好的编码和解码输入变成 one-hot (逃不掉的one-hot)\n",
        "\n",
        "3 这里输入的编码和解码（b） 都变成了one-hot存起来了\n",
        "只有target （e） 存的是index，并没有存one-hot\n",
        "'''\n",
        "\n",
        "#这里是把词表输入。然后呢处理他们，得到 解码编码-onehot ；和目标（可能就是真实）index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O9LFDDUhYfM"
      },
      "source": [
        "def add_paddings(word, max_num=5):    #padding (fill 补充) 添满如果单词比最长的单词要短\n",
        "  diff = max_num -len(word)\n",
        "  return word + 'P'*diff    #用P补全  看起来要不补一个要不补两个P\n",
        "\n",
        "def make_batch(seq_data):   #产生一批数据，给训练和测试\n",
        "  encoder_input_batch = []\n",
        "  decoder_input_batch = []\n",
        "  target_batch = []\n",
        "\n",
        "  for seq in seq_data:\n",
        "    input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "    en_input_data = [num_dic[n] for n in input_word]          #[5, 1, 0, 16, 16]\n",
        "    \n",
        "    de_input_data = [num_dic[n] for n in ('B' + seq[1])]  #B：14， 13：0； 9：1 它是把idnex也变成了列表\n",
        "\n",
        "    target = [num_dic[n] for n in (seq[1] + 'E')]       #   13:0      E:15\n",
        "\n",
        "    encoder_input_batch.append(np.eye(dic_len)) #就是五位。让他们在对应位置表1；  5；8；4；7；17 （还是需要减一，是从0开始；所以单独输出的还是King「 \n",
        "                                                #让他们input的word变成one-hot\n",
        "    decoder_input_batch.append(np.eye(dic_len)[de_input_data])    #np.eye(总单词长度)【实际你想要的变得单词index】\n",
        "                                                #还是包含B的index\n",
        "    target_batch.append(target)                 #包含E的,他是直接将输出的index存起来了，没做one-hot\n",
        "\n",
        "\n",
        "  return encoder_input_batch, decoder_input_batch, target_batch"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV1JzhXO8oMs"
      },
      "source": [
        "**Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DY23fK8D6hd",
        "outputId": "7673b0e9-784f-4bfe-f7ed-2e89f5d49fed"
      },
      "source": [
        "target_batch.append(target)\n",
        "target_batch"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 12, 15], [9, 12, 15]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57KG4MQZD0fW",
        "outputId": "c5b39acb-3745-4c70-cca2-5fa8d6a82362"
      },
      "source": [
        "#4.18\n",
        "target"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 12, 15]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlnjrhJFDV0y",
        "outputId": "c7a82189-c3a3-45cd-d9ba-28db7c23f77b"
      },
      "source": [
        "dic_len"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWVrYDKCDSjJ",
        "outputId": "741a69c7-ac4b-4133-f163-f9079fd9f8c9"
      },
      "source": [
        "np.eye(dic_len)[de_input_data]  #14, 9 ,12"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS3oRBgkCzXo",
        "outputId": "48e9f0ac-4c87-4807-8fde-c0bf9873b626"
      },
      "source": [
        "en_input_data"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 7, 3, 6, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFB6aOrJBiZ9",
        "outputId": "1ebb5478-b591-475c-da66-5628f16c9e38"
      },
      "source": [
        "#4.14\n",
        "np.eye(dic_len)[en_input_data] #kingP "
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_yYzT3zBej4",
        "outputId": "31e33611-15e3-489b-876e-3cf2b4090aad"
      },
      "source": [
        "#4.13\n",
        "np.eye(dic_len)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCojHtInAS4e",
        "outputId": "f4f44a09-dcc2-4804-9507-9d4c3b7bb023"
      },
      "source": [
        "#4.12\n",
        "encoder_input_batch = []\n",
        "decoder_input_batch = []\n",
        "target_batch = []\n",
        "\n",
        "for seq in seq_data:\n",
        "  input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "  en_input_data = [num_dic[n] for n in input_word]          #[5, 1, 0, 16, 16]\n",
        "  \n",
        "  de_input_data = [num_dic[n] for n in ('B' + seq[1])]  #B：14， 13：0； 9：1 它是把idnex也变成了列表\n",
        "\n",
        "  target = [num_dic[n] for n in (seq[1] + 'E')]\n",
        "  print(target)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13, 9, 15]\n",
            "[9, 9, 15]\n",
            "[9, 10, 15]\n",
            "[9, 12, 15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kJjjJBv-2Fq",
        "outputId": "04fe53fe-289e-4f00-e72f-1d4848501a42"
      },
      "source": [
        "#4.11\n",
        "seq"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king', '13']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc9KZB40-vf4",
        "outputId": "ee76d158-ca86-4e5a-ad12-dcb72d6c09af"
      },
      "source": [
        "#4.10\n",
        "encoder_input_batch = []\n",
        "decoder_input_batch = []\n",
        "target_batch = []\n",
        "\n",
        "for seq in seq_data:\n",
        "  input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "  en_input_data = [num_dic[n] for n in input_word]\n",
        "  de_input_data = [num_dic[n] for n in ('B' + seq[1])]\n",
        "  print(de_input_data)    "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14, 13, 9]\n",
            "[14, 9, 9]\n",
            "[14, 9, 10]\n",
            "[14, 9, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA42PJis9NV1",
        "outputId": "bb26e8bb-a66d-4f64-c709-0a36a2f48317"
      },
      "source": [
        "#4.9\n",
        "encoder_input_batch = []\n",
        "decoder_input_batch = []\n",
        "target_batch = []\n",
        "\n",
        "for seq in seq_data:\n",
        "  input_word = add_paddings(seq[0])     # 0 指前面的word 1 指后面的index  kingP\n",
        "  en_input_data = [num_dic[n] for n in input_word]\n",
        "  print(en_input_data)    \n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 1, 0, 16, 16]\n",
            "[11, 5, 1, 4, 16]\n",
            "[8, 2, 0, 0, 3]\n",
            "[4, 7, 3, 6, 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tWQZcDww9CgF",
        "outputId": "1cb7255f-c6cb-4f1c-e4a7-3a691be8d18d"
      },
      "source": [
        "#4.8 \n",
        "n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'U'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbkgFh6p88rj",
        "outputId": "7d545533-7697-4cd7-aff2-2d8552a53e9b"
      },
      "source": [
        "#4.7\n",
        "len(num_dic)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlJ9tfWN82Uo",
        "outputId": "53e016f9-3320-4938-9d52-7f7cf34207c9"
      },
      "source": [
        "#4.6\n",
        "num_dic[n]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHQ3J8Ja8xzV",
        "outputId": "d822793b-7230-4ca9-bbfd-70639efa243e"
      },
      "source": [
        "#4.5\n",
        "num_dic"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 13,\n",
              " '1': 9,\n",
              " '2': 10,\n",
              " '3': 12,\n",
              " 'B': 14,\n",
              " 'E': 15,\n",
              " 'P': 16,\n",
              " 'U': 17,\n",
              " 'a': 5,\n",
              " 'c': 1,\n",
              " 'e': 0,\n",
              " 'g': 6,\n",
              " 'i': 7,\n",
              " 'j': 11,\n",
              " 'k': 4,\n",
              " 'n': 3,\n",
              " 'q': 8,\n",
              " 'u': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CHCcxFBp7Ldv",
        "outputId": "5eaba3b7-cf69-4064-d62b-c6a3f0febb20"
      },
      "source": [
        "input_word = add_paddings(seq[0])\n",
        "input_word"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'kingP'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u4e3EnRP7CbF",
        "outputId": "4bd18acd-6c39-46b2-d98c-7b20fbafe0d9"
      },
      "source": [
        "seq[1]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'13'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GQm3jTGQ670-",
        "outputId": "7d75bf83-3eb0-4a39-92d0-025fdc786cbf"
      },
      "source": [
        "#4.2\n",
        "seq[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'king'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RQhpk5F6Q_U",
        "outputId": "0de7df8e-a523-4d09-e749-c84e0994d420"
      },
      "source": [
        "#4.1\n",
        "seq_data"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ace', '01'], ['jack', '11'], ['queen', '12'], ['king', '13']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "079-aKEFeNNi",
        "outputId": "9c0d1e14-23e7-4025-c5e9-06c1fddd3265"
      },
      "source": [
        "#3.1\n",
        "chars += list(seq[0])\n",
        "'''\n",
        "['a', 'c', 'e']\n",
        "['a', 'c', 'e', 'j', 'a', 'c', 'k']\n",
        "['a', 'c', 'e', 'j', 'a', 'c', 'k', 'q', 'u', 'e', 'e', 'n']\n",
        "['a', 'c', 'e', 'j', 'a', 'c', 'k', 'q', 'u', 'e', 'e', 'n', 'k', 'i', 'n', 'g']\n",
        "'''\n",
        "chars += list(seq[1])\n",
        "'''\n",
        "['a', 'c', 'e', '0', '1']\n",
        "['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1']\n",
        "['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2']\n",
        "['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2', 'k', 'i', 'n', 'g', '1', '3']\n",
        "\n",
        "'''"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n['a', 'c', 'e', '0', '1']\\n['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1']\\n['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2']\\n['a', 'c', 'e', '0', '1', 'j', 'a', 'c', 'k', '1', '1', 'q', 'u', 'e', 'e', 'n', '1', '2', 'k', 'i', 'n', 'g', '1', '3']\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KQD9RkMxGLS",
        "outputId": "e1acf81a-d98b-4b76-f38e-1253b7af5039"
      },
      "source": [
        "#2.17\n",
        "seq_data"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ace', '01'], ['jack', '11'], ['queen', '12'], ['king', '13']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K21ZQs_LwRgl",
        "outputId": "54d5b5be-d37a-4325-92f1-6e2334ee5a7a"
      },
      "source": [
        "#2.16\n",
        "char_arr"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e',\n",
              " 'c',\n",
              " 'u',\n",
              " 'n',\n",
              " 'k',\n",
              " 'a',\n",
              " 'g',\n",
              " 'i',\n",
              " 'q',\n",
              " '1',\n",
              " '2',\n",
              " 'j',\n",
              " '3',\n",
              " '0',\n",
              " 'B',\n",
              " 'E',\n",
              " 'P',\n",
              " 'U']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1R66YV-EwOrK",
        "outputId": "fb57e6e3-ecd9-41be-ad6e-01b2926563a9"
      },
      "source": [
        "#2.15\n",
        "char_arr[ind]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "AMSVcVsrv8ja",
        "outputId": "5b990e0c-e418-4773-e5b9-4fe485008ae7"
      },
      "source": [
        "#2.14\n",
        "'''\n",
        "['wor']\n",
        "['wor', 'woo']\n",
        "['wor', 'woo', 'dee']\n",
        "['wor', 'woo', 'dee', 'div']\n",
        "['wor', 'woo', 'dee', 'div', 'col']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis']\n",
        "['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis', 'kin']\n",
        "'''\n",
        "\n",
        "#seq_data[i][:-1]\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n['wor']\\n['wor', 'woo']\\n['wor', 'woo', 'dee']\\n['wor', 'woo', 'dee', 'div']\\n['wor', 'woo', 'dee', 'div', 'col']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis']\\n['wor', 'woo', 'dee', 'div', 'col', 'coo', 'loa', 'lov', 'kis', 'kin']\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUOTXvqvj6O",
        "outputId": "046fd97d-ae84-42f0-e4bc-ea3328e9e0b5"
      },
      "source": [
        "#2.13\n",
        "ind"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6jg502ctIyy",
        "outputId": "ad209c6d-c091-4e67-d70d-eb3528e720c0"
      },
      "source": [
        "#2.12\n",
        "predicted.cpu()[1]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d605TlHwp12o",
        "outputId": "6a27ed13-94ae-4b89-bc64-345efb6c6a85"
      },
      "source": [
        "#2.11\n",
        "predicted.cpu().numpy()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhtZxWM7pxWL",
        "outputId": "b88c36f6-28a7-47da-8647-43e491d83fea"
      },
      "source": [
        "#2.10\n",
        "predicted.cpu()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY-Ugp7lpt9l",
        "outputId": "87ea23f4-3166-48d8-9af8-354b259e7623"
      },
      "source": [
        "#2.9\n",
        "predicted"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki13GzewpjGJ",
        "outputId": "de677cfc-fc2f-4ebc-bb9a-09b48d5035cb"
      },
      "source": [
        "#2.8\n",
        "target_batch_torch.cpu().numpy()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a8eC7wkpfGJ",
        "outputId": "9b4c1ccc-519c-44d1-e9d8-9ea5180d7cf1"
      },
      "source": [
        "#2.7\n",
        "target_batch_torch"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3359uRUvpaGj",
        "outputId": "2b896bd0-2074-4854-d367-a1aa8145688a"
      },
      "source": [
        "#2.6\n",
        "print(target_batch_torch.cpu())#tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXrJ-ibplvKo"
      },
      "source": [
        "#2.5\n",
        "  #print(_)    #tensor([0.2457, 0.1858, 0.2913, 0.1972, 0.2256, 0.2471, 0.2616, 0.1699, 0.2519,\n",
        "              #0.2905], device='cuda:0', grad_fn=<MaxBackward0>)  [10]torch.Size([10]) 50+(不会是64吧）)\n",
        "  #print(len(_))\n",
        "  #print(predicted) #tensor([ 4,  4,  4,  4,  4,  4,  4,  4, 10,  4], device='cuda:0')\n",
        "  #print(predicted.shape) #torch.Size([10])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvFumYJCkxkX",
        "outputId": "9f417034-715f-4eed-fdb8-883dc6d7a236"
      },
      "source": [
        "#2.4\n",
        "target_batch_torch"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  3, 15,  4,  3, 11,  3,  4, 18,  3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgIsRMPKkuPx",
        "outputId": "bcf08429-a44a-4115-c208-36be398fb1b1"
      },
      "source": [
        "#2.3\n",
        "target_batch"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3], [3], [15], [4], [3], [11], [3], [4], [18], [3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6HWwjJpkr8S",
        "outputId": "74b77fb7-52dc-4c2f-e831-59bd10710524"
      },
      "source": [
        "#2.2\n",
        "model.train()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN_Model(\n",
              "  (rnn): RNN(26, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (linear): Linear(in_features=64, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPFvrCr3ZBCl",
        "outputId": "f2985213-4221-45c6-887b-e2d366ae41c3"
      },
      "source": [
        "#2.1\n",
        "input_batch_torch"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "su5l0yYpIUQH",
        "outputId": "5ca24fbf-5b1c-4333-bd59-5e01021b638e"
      },
      "source": [
        "#1.9\n",
        "'''\n",
        "target_batch = []\n",
        "for seq in seq_data:\n",
        "  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\n",
        "  target = num_dic[seq[-1]]\n",
        "\n",
        "  input_batch.append(np.eye(dic_len)[input_data])\n",
        "\n",
        "  target_batch.append([target])\n",
        "  print(target_batch)\n",
        "'''"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntarget_batch = []\\nfor seq in seq_data:\\n  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\\n  target = num_dic[seq[-1]]\\n\\n  input_batch.append(np.eye(dic_len)[input_data])\\n\\n  target_batch.append([target])\\n  print(target_batch)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "8bk2KjCTC6f7",
        "outputId": "c5ac8421-a861-47fc-c039-0361f194f298"
      },
      "source": [
        "#1.8\n",
        "'''\n",
        "import pprint\n",
        "input_batch = []\n",
        "for seq in seq_data:\n",
        "  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\n",
        "\n",
        "  input_batch.append(np.eye(dic_len)[input_data]) #2-3【0】【0】 还是个list；还没有形状0 0\n",
        "  \n",
        "\n",
        "'''"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport pprint\\ninput_batch = []\\nfor seq in seq_data:\\n  input_data = [num_dic[n] for n in seq[:-1]] ##不取最后一个，把前面的字母对应的index取出来\\n\\n  input_batch.append(np.eye(dic_len)[input_data]) #2-3【0】【0】 还是个list；还没有形状0 0\\n  \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcnEvNLxD2_h"
      },
      "source": [
        "#np.eye(dic_len)[input_data] #制作one-hot np.eye 批量制作。然后第一个是0.所以index+1的位置是1.代表了这个元素"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eNXUkvDD9Xb"
      },
      "source": [
        "#input_data #kid"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d2YzxQJDnFV"
      },
      "source": [
        "np.eye(dic_len)#弄了个对角线1其他都是0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "53CyT1-KB-Nl",
        "outputId": "2dbdf6ce-3ecd-489c-8525-dd9a0cd5fe52"
      },
      "source": [
        "#1.7\n",
        "'''\n",
        "for seq in seq_data:\n",
        "  target = num_dic[seq[-1]]\n",
        "  print(target)     #3 :d  \n",
        "  '''"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor seq in seq_data:\\n  target = num_dic[seq[-1]]\\n  print(target)     #3 :d  \\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "e5QsK7l4BQlm",
        "outputId": "247ac3ad-3d9a-4379-858e-8ed2fdf5450b"
      },
      "source": [
        "#1.6\n",
        "'''\n",
        "for seq in seq_data:\n",
        "    input_data = [num_dic[n] for n in seq[:-1]] #不取最后一个\n",
        "    print(input_data)\n",
        "    #w:22 o:14 r:17\n",
        "    '''"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor seq in seq_data:\\n    input_data = [num_dic[n] for n in seq[:-1]] #不取最后一个\\n    print(input_data)\\n    #w:22 o:14 r:17\\n    '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USwFA6d1AoTa",
        "outputId": "a93ed940-923d-447d-c8bd-5ce63fad1e98"
      },
      "source": [
        "#1.5\n",
        "seq_data\n",
        "len(seq_data)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt9G3Hjm_pEH",
        "outputId": "e4b0720a-912e-4400-e806-69077de52759"
      },
      "source": [
        "#1.4\n",
        "dic_len"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc1qGzRz_RIK",
        "outputId": "13400a40-dbcc-4a7a-e4f4-86bd3bf024f7"
      },
      "source": [
        "#1.3\n",
        "{n:i for i, n in enumerate(char_arr)} #   n: i == 'a': 0,单词： index 目前看起来只有字典可以这样"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 13,\n",
              " '1': 9,\n",
              " '2': 10,\n",
              " '3': 12,\n",
              " 'B': 14,\n",
              " 'E': 15,\n",
              " 'P': 16,\n",
              " 'U': 17,\n",
              " 'a': 5,\n",
              " 'c': 1,\n",
              " 'e': 0,\n",
              " 'g': 6,\n",
              " 'i': 7,\n",
              " 'j': 11,\n",
              " 'k': 4,\n",
              " 'n': 3,\n",
              " 'q': 8,\n",
              " 'u': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iGHoeOZ8w4C",
        "outputId": "f8e84b11-04be-477f-c482-c6382e35a529"
      },
      "source": [
        "#1.2\n",
        "for i,n in enumerate(char_arr):\n",
        "  #print(i,)    #index\n",
        "  #print(n)    #word\n",
        "  print(i,n)  #这样是一一对应（横向）"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 e\n",
            "1 c\n",
            "2 u\n",
            "3 n\n",
            "4 k\n",
            "5 a\n",
            "6 g\n",
            "7 i\n",
            "8 q\n",
            "9 1\n",
            "10 2\n",
            "11 j\n",
            "12 3\n",
            "13 0\n",
            "14 B\n",
            "15 E\n",
            "16 P\n",
            "17 U\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSKe8G808VK5",
        "outputId": "b331b947-222a-4658-b979-71d25c1481a2"
      },
      "source": [
        "#1.1\n",
        "list(enumerate(char_arr))#这没什么变化啊\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'e'),\n",
              " (1, 'c'),\n",
              " (2, 'u'),\n",
              " (3, 'n'),\n",
              " (4, 'k'),\n",
              " (5, 'a'),\n",
              " (6, 'g'),\n",
              " (7, 'i'),\n",
              " (8, 'q'),\n",
              " (9, '1'),\n",
              " (10, '2'),\n",
              " (11, 'j'),\n",
              " (12, '3'),\n",
              " (13, '0'),\n",
              " (14, 'B'),\n",
              " (15, 'E'),\n",
              " (16, 'P'),\n",
              " (17, 'U')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4SsWe_Y8XOy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}